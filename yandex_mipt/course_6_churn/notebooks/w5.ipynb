{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score, recall_score, precision_score, roc_curve, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, Imputer, LabelBinarizer\n",
    "import category_encoders\n",
    "\n",
    "import time \n",
    "import pickle\n",
    "\n",
    "from functools import partial \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def learning_curve_cv(X, y, model, train_size, cv=3):\n",
    "    \n",
    "    transform = partial(transform_custom, feature_names=list(X.columns))    \n",
    "    train_size = np.int32(train_size)\n",
    "    kf = StratifiedKFold(cv, random_state=42, shuffle=True)\n",
    "    \n",
    "    train_scores = np.zeros((len(train_size), cv), dtype=np.float32)\n",
    "    valid_scores = np.zeros((len(train_size), cv), dtype=np.float32)    \n",
    "    \n",
    "    X, y = np.array(X), np.array(y).reshape(-1)\n",
    "    \n",
    "    for j, num in enumerate(train_size):\n",
    "        print(j, num)\n",
    "        for i, (train_index, val_index) in enumerate(kf.split(X[:num, :], y[:num])):\n",
    "\n",
    "            print( \"Fold \", i)\n",
    "\n",
    "            y_train, y_val = y[train_index].copy(), y[val_index].copy()\n",
    "            X_train, X_val = X[train_index, :].copy(), X[val_index, :].copy()\n",
    "            \n",
    "            X_train, X_val = transform(X_train, X_val, y_train)\n",
    "            \n",
    "            fit_model = model.fit(X_train, y_train)\n",
    "            \n",
    "            train_proba = fit_model.predict_proba(X_train)[:, 1]\n",
    "            val_proba = fit_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "            train_scores[j, i] = roc_auc_score(y_train, train_proba)\n",
    "            valid_scores[j, i] = roc_auc_score(y_val, val_proba)\n",
    "        \n",
    "    return train_scores, valid_scores\n",
    "\n",
    "\n",
    "def cross_val(X, y, model, kf, preprocessing, verbose=False):\n",
    "    \n",
    "    X, y = np.array(X), np.array(y).reshape(-1)\n",
    "    cv_scores = []\n",
    "\n",
    "    for i, (train_index, val_index) in enumerate(kf.split(X, y)):\n",
    "\n",
    "        print( \"Fold \", i)\n",
    "\n",
    "        y_train, y_val = y[train_index].copy(), y[val_index].copy()\n",
    "        X_train, X_val = X[train_index, :].copy(), X[val_index, :].copy()\n",
    "        \n",
    "        X_train, X_val = preprocessing(X_train, X_val, y_train)\n",
    "        if verbose: print(X_train.shape)\n",
    "            \n",
    "        fit_model = model.fit(X_train, y_train)\n",
    "        pred = fit_model.predict_proba(X_val)[:, 1]\n",
    "        \n",
    "        cv_scores.append(roc_auc_score(y_val, pred))\n",
    "        \n",
    "    return cv_scores\n",
    "\n",
    "def cutoff_metrics(y_valid, predict_proba, cutoff):\n",
    "    for cut in cutoff:\n",
    "        print(\"f1: {:.3f}\\trecall: {:.3f}\\tprecision: {:.3f}\\tacc: {:.3f}\\tcutoff: {:.3f} \".format(\n",
    "            f1_score(y_valid, predict_proba > cut), \n",
    "            recall_score(y_valid, predict_proba > cut), \n",
    "            precision_score(y_valid, predict_proba > cut), \n",
    "            accuracy_score(y_valid, predict_proba>cut),\n",
    "            cut\n",
    "        ))\n",
    "\n",
    "def print_metrics(cv_scores):\n",
    "    metrics = ['f1', 'precision', 'recall', 'roc auc']\n",
    "    cvmean = cv_scores.mean(0)\n",
    "    for i in range(4):\n",
    "        print(\"{} = {:.5f}\".format(metrics[i], cvmean[i]))\n",
    "\n",
    "def transform(train, test, target, to_drop=False, \n",
    "              high_cardinality=\"smoothing\", hc_treshold = 10, hc_drop=False, # high cardinality categorical\n",
    "              eb_k=50, eb_f=10,  # parameters for hc smoothing function \n",
    "              encode=False,  # categorical \n",
    "              fill_num=-1, scaling=False,  # continuous \n",
    "              feature_names = False, feature_dtypes = False,\n",
    "              keep = False\n",
    "             ):\n",
    "    \n",
    "    \"\"\" \n",
    "    data preprocessing \n",
    "    \n",
    "    :train, test: pandas DataFrame\n",
    "    :high_cardinality: way to handle categorical features with high number of levels\n",
    "    :encode: category encoding, 'ohe' = one hot, 'bin' = binary\n",
    "    :fill_num: fill nan for continuous features, -1 = with -1, ('mean', 'median') = strategy\n",
    "    :scaling: 'standard' = StandartScaler\n",
    "    :feature_names: list, columns from dataframe\n",
    "    :feature_dtypes: pd.Series, dtypes from dataframe\n",
    "    \n",
    "    category features should have type 'object'\n",
    "    \"\"\"\n",
    "    \n",
    "    # checks \n",
    "    \n",
    "    feature_names = list(feature_names)\n",
    "    if (isinstance(train, np.ndarray) or isinstance(test, np.ndarray)) and not feature_names:\n",
    "        raise FeatureNamesError(\"Feature names had not defined for np.ndarray\")\n",
    "    \n",
    "    # np to pd \n",
    "    if isinstance(train, np.ndarray):\n",
    "        train=pd.DataFrame(train, columns=feature_names)\n",
    "        dt = feature_dtypes.to_dict()\n",
    "        for col in train.columns:\n",
    "            train[col] = train[col].astype(dt[col])        \n",
    "    if isinstance(test, np.ndarray):\n",
    "        test=pd.DataFrame(test, columns=feature_names)\n",
    "        dt = feature_dtypes.to_dict()\n",
    "        for col in train.columns:\n",
    "            test[col] = test[col].astype(dt[col])\n",
    "    \n",
    "    # remove duplicates \n",
    "    if to_drop:\n",
    "        train = train.drop(to_drop, axis=1)\n",
    "        test = test.drop(to_drop, axis=1)\n",
    "    \n",
    "    ######## categorical features \n",
    "    \n",
    "    cat_features = train.columns[train.dtypes=='object']\n",
    "    num_features = train.columns[train.dtypes!='object']      \n",
    "    \n",
    "    # factorize \n",
    "    le = LabelEncoder()\n",
    "    train[cat_features] = train[cat_features].fillna('-1')\n",
    "    test[cat_features] = test[cat_features].fillna('-1')\n",
    "    for c in cat_features:\n",
    "        data=train[c].append(test[c])\n",
    "        le.fit(data.values.tolist())  # nan = 0 level\n",
    "        train[c] = le.transform(train[c].values.tolist())\n",
    "        test[c] = le.transform(test[c].values.tolist())       \n",
    "    \n",
    "    # mark nan with -1, if encoding not necessary \n",
    "    if not encode:\n",
    "        train[cat_features] = train[cat_features].replace(0, -1)\n",
    "        test[cat_features] = test[cat_features].replace(0, -1)    \n",
    "        \n",
    "    ######## high cardinality\n",
    "    \n",
    "    if high_cardinality:\n",
    "\n",
    "        hc_features = train[cat_features].columns[train[cat_features].apply(lambda x: len(x.value_counts())) > hc_treshold]\n",
    "        target_mean = target.mean()\n",
    "        S = {}\n",
    "\n",
    "        for c in hc_features:\n",
    "\n",
    "            if high_cardinality == \"sr\":\n",
    "                # supervised ratio \n",
    "                group_means = pd.concat([train[c], pd.DataFrame(target, columns=['target'], index=train.index)], axis=1).groupby(c).mean()\n",
    "                group_means = group_means.target.to_dict()\n",
    "                for group in train[c].value_counts().index:\n",
    "                    S[group] = group_means[group]\n",
    "\n",
    "            if high_cardinality==\"woe\":\n",
    "                # weight of evidence\n",
    "                group_y1 = pd.concat([train[c], pd.DataFrame(target, columns=['target'], index=train.index)], axis=1).\\\n",
    "                groupby([c]).agg('sum')\n",
    "                group_y0 = pd.concat([train[c], pd.DataFrame(target, columns=['target'], index=train.index)], axis=1).\\\n",
    "                groupby([c]).agg('count') - group_y1\n",
    "                y1 = (target==1).sum()\n",
    "                y0 = (target==0).sum()\n",
    "                woe = np.log(((group_y1) / y1) / ((group_y0) / y0))\n",
    "                for i,v in zip(woe.index, np.where(np.isinf(woe), 0, woe)):\n",
    "                    S[i] = v[0]\n",
    "\n",
    "            if high_cardinality==\"smoothing\":\n",
    "                # empirical bayes (smoothing for small group)\n",
    "                group_means = pd.concat([train[c], pd.DataFrame(target, columns=['target'], index=train.index)], axis=1).groupby(c).mean()\n",
    "                group_means = group_means.target.to_dict()\n",
    "                group_counts = pd.concat([train[c], pd.DataFrame(target, columns=['target'], index=train.index)], axis=1).groupby(c).agg('count')\n",
    "                group_counts = group_counts.target.to_dict()\n",
    "\n",
    "                def smoothing_function(n, k, f):\n",
    "                    return 1 / (1 + np.exp(-(n-k)/f))\n",
    "\n",
    "                for group in train[c].value_counts().index:\n",
    "                    lam = smoothing_function(n=group_counts[group], k=eb_k, f=eb_f)\n",
    "                    S[group] = lam*group_means[group] + (1-lam)*target_mean\n",
    "\n",
    "            # transform train\n",
    "            train[c+'_avg'] = train[c].apply(lambda x: S[x]).copy()\n",
    "\n",
    "            # transform test\n",
    "            def hc_transform_test(x):\n",
    "                if x in S: \n",
    "                    return S[x]\n",
    "                else:\n",
    "                    return target_mean\n",
    "\n",
    "            test[c+'_avg'] = test[c].apply(hc_transform_test).copy()\n",
    "\n",
    "        # drop hc features \n",
    "        if hc_drop:\n",
    "            train.drop(hc_features, axis=1, inplace=True)\n",
    "            test.drop(hc_features, axis=1, inplace=True)\n",
    "\n",
    "        # update cat features \n",
    "        cat_features = sorted(list(set(cat_features).difference(hc_features)))\n",
    "\n",
    "    ######## for linear models \n",
    "#     print(train.shape)\n",
    "#     if True:\n",
    "#         return num_features, train\n",
    "    \n",
    "    # fill missings\n",
    "    if fill_num in ['mean', 'median']:\n",
    "        imputer = Imputer(strategy=fill_num)\n",
    "        train[num_features] = imputer.fit_transform(train[num_features])\n",
    "        test[num_features] = imputer.transform(test[num_features])\n",
    "    elif fill_num < 0:\n",
    "        train[num_features] = train[num_features].fillna(fill_num)\n",
    "        test[num_features] = test[num_features].fillna(fill_num)\n",
    "        \n",
    "    # scaling\n",
    "    if scaling=='standard':\n",
    "        scaler = StandardScaler()\n",
    "        train[num_features] = scaler.fit_transform(train[num_features])\n",
    "        test[num_features] = scaler.transform(test[num_features])\n",
    "    \n",
    "    ######## encoding \n",
    "    if encode=='ohe':\n",
    "        # one hot encoding, memory inefficient\n",
    "        oh = OneHotEncoder(sparse=False)\n",
    "        for c in cat_features:\n",
    "            data=train[c].append(test[c])\n",
    "            oh.fit(data.values.reshape(-1,1))            \n",
    "            train_temp = oh.transform(train[c].values.reshape(-1,1))\n",
    "            test_temp = oh.transform(test[c].values.reshape(-1,1))\n",
    "            train = pd.concat([train, pd.DataFrame(train_temp, \n",
    "                                                   columns=[(c+\"_\"+str(i)) for i in data.value_counts().index],\n",
    "                                                   index = train.index\n",
    "                                                  )], axis=1)\n",
    "            test = pd.concat([test, pd.DataFrame(test_temp, \n",
    "                                                 columns=[(c+\"_\"+str(i)) for i in data.value_counts().index],\n",
    "                                                 index = test.index\n",
    "                                                )], axis=1)\n",
    "            # drop column\n",
    "            train.drop(c, axis=1, inplace=True)\n",
    "            test.drop(c, axis=1, inplace=True)\n",
    "    \n",
    "    if encode=='bin':\n",
    "        # binary encoding \n",
    "        for c in cat_features:\n",
    "            data=pd.DataFrame(train[c].append(test[c]), columns=[c])\n",
    "            be = category_encoders.BinaryEncoder(cols=[c])\n",
    "            be.fit(data)\n",
    "            train_temp = be.transform(pd.DataFrame(train[c], columns=[c]))\n",
    "            test_temp = be.transform(pd.DataFrame(test[c], columns=[c]))\n",
    "            train = pd.concat([train, train_temp], axis=1)\n",
    "            test = pd.concat([test, test_temp], axis=1)\n",
    "            # drop column\n",
    "            train.drop(c, axis=1, inplace=True)\n",
    "            test.drop(c, axis=1, inplace=True)\n",
    "       \n",
    "    if keep:\n",
    "        train = train.loc[:, keep]\n",
    "        test = test.loc[:, keep]\n",
    "        \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load \n",
    "test = pd.read_csv('./input/orange_small_churn_test_data.csv')\n",
    "train, target = pd.read_csv('./input/orange_small_churn_data.train'), \\\n",
    "np.where(pd.read_csv('./input/orange_small_churn_labels.train', header=-1)==1, 1, 0).ravel()\n",
    "\n",
    "test_id= test['ID']\n",
    "test.drop(['ID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['Var8', 'Var15', 'Var20', 'Var31', 'Var32', 'Var39', 'Var42', 'Var48',\n",
    "       'Var52', 'Var55', 'Var79', 'Var141', 'Var167', 'Var169', 'Var175',\n",
    "       'Var185', 'Var209', 'Var230', 'Var214', 'Var220', 'Var222']\n",
    "\n",
    "kf = StratifiedKFold(3, random_state=1, shuffle=True)\n",
    "\n",
    "############################################################################################################\n",
    "# xgb baseline hyperparameters\n",
    "model = XGBClassifier(n_jobs=4, tree_method='gpu_hist', predictor = \"cpu_predictor\", objective=\"binary:logistic\",\n",
    "                      n_estimators=1000, \n",
    "                      learning_rate=0.05,\n",
    "                      max_depth=4,\n",
    "                      gamma=10, min_child_weight=2,\n",
    "                      subsample=.8, colsample_bytree=.8,\n",
    "#                       scale_pos_weight=1.5,\n",
    "                      reg_alpha=2,\n",
    "                      reg_lambda=1.3,\n",
    "                     )\n",
    "\n",
    "# model.n_estimators = 200 # optimal value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "MISS_THERSHOLD = 1\n",
    "ENCODE = False\n",
    "FILL_NUM = -1\n",
    "SCALING = False\n",
    "\n",
    "# high cardinality \n",
    "HC = \"smoothing\"\n",
    "HC_DROP = False\n",
    "HC_K = 50\n",
    "HC_F = 2\n",
    "\n",
    "transform_linear = partial(transform, encode='ohe', scaling=True, fill_num='mean', \n",
    "                           hc_drop=True, high_cardinality=HC, eb_k=HC_K, eb_f=HC_F,\n",
    "                           to_drop=to_drop)\n",
    "\n",
    "transform_xgb = partial(transform, encode=ENCODE, scaling=SCALING, fill_num=FILL_NUM, \n",
    "                           hc_drop=HC_DROP, high_cardinality=HC, eb_k=HC_K, eb_f=HC_F,\n",
    "                           to_drop=to_drop, feature_dtypes=train.dtypes, feature_names=train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35000, 226) (5000, 226)\n"
     ]
    }
   ],
   "source": [
    "# split data \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train, target, test_size=5000, random_state=42, stratify=target)\n",
    "X_train_, X_valid_, y_train_, y_valid_ = train_test_split(train, target, test_size=5000, random_state=42, stratify=target)\n",
    "# transform\n",
    "X_train, X_valid = transform_xgb(X_train, X_valid, y_train)\n",
    "print(X_train.shape, X_valid.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.669055\n",
      "Will train until validation_0-auc hasn't improved in 20 rounds.\n",
      "[20]\tvalidation_0-auc:0.684783\n",
      "[40]\tvalidation_0-auc:0.701271\n",
      "[60]\tvalidation_0-auc:0.705864\n",
      "[80]\tvalidation_0-auc:0.708978\n",
      "[100]\tvalidation_0-auc:0.710313\n",
      "[120]\tvalidation_0-auc:0.712787\n",
      "[140]\tvalidation_0-auc:0.714365\n",
      "[160]\tvalidation_0-auc:0.717236\n",
      "[180]\tvalidation_0-auc:0.717489\n",
      "[200]\tvalidation_0-auc:0.719732\n",
      "[220]\tvalidation_0-auc:0.718747\n",
      "Stopping. Best iteration:\n",
      "[204]\tvalidation_0-auc:0.71991\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, early_stopping_rounds=20, eval_metric=\"auc\", eval_set=[(X_valid, y_valid)], verbose=20)\n",
    "predict_valid = model.predict_proba(X_valid, ntree_limit=model.best_ntree_limit)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc score:0.7199099566918523\n"
     ]
    }
   ],
   "source": [
    "# baseline auc score \n",
    "print(\"auc score:{}\".format(roc_auc_score(y_valid, predict_valid)))\n",
    "# baseline binary metrics\n",
    "# cutoff_metrics(np.linspace(0.05, 0.3, 6), predict_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peer-graded Assignment: Эксперименты с моделью\n",
    "\n",
    "На прошлой неделе вы поучаствовали в соревновании на kaggle и, наверняка, большинство успешно справилось с прохождением baseline, а значит пора двигаться дальше - заняться оптимизацией модели, провести серию экспериментов и построить сильное финальное решения.\n",
    "\n",
    "В этом задании вам нужно провести ряд эскпериментов, оценить качество полученных в процессе экспериментирования моделей и выбрать лучшее решение. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание будет оцениваться на основании загруженного jupyther notebook и развернутых ответов на поставленные вопросы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инструкции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Начнем с простого. Давайте оценим как много объектов действительно нужно для построения качественной модели. Для обучения доступна достаточно большая выборка и может так оказаться, что начиная с некоторого момента рост размера обучающей выборки перестает влиять на качество модели. Постройте кривые обучения, обучая модель на выборках разного размера начиная с небольшого количество объектов в обучающей выборке и постепенно наращивая её размер с некоторым шагом. Обратите внимание на `sklearn.model_selection.learning_curve`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train, target, test_size=5000, random_state=42, stratify=target)\n",
    "model_fit = model.set_params(n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5000\n",
      "Fold  0\n",
      "Fold  1\n",
      "Fold  2\n",
      "1 10000\n",
      "Fold  0\n",
      "Fold  1\n",
      "Fold  2\n",
      "2 15000\n",
      "Fold  0\n",
      "Fold  1\n",
      "Fold  2\n",
      "3 20000\n",
      "Fold  0\n",
      "Fold  1\n",
      "Fold  2\n",
      "4 25000\n",
      "Fold  0\n",
      "Fold  1\n",
      "Fold  2\n",
      "5 30000\n",
      "Fold  0\n",
      "Fold  1\n",
      "Fold  2\n",
      "6 35000\n",
      "Fold  0\n",
      "Fold  1\n",
      "Fold  2\n"
     ]
    }
   ],
   "source": [
    "lc_train, lc_test = learning_curve_cv(X_train, y_train, model_fit, np.linspace(5000, 35000, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import learning_curve\n",
    "# lc_scores = learning_curve(cv=3, n_jobs=2, scoring='roc_auc', shuffle=True, verbose=1, train_sizes=np.linspace(0.1,1,10),\n",
    "#                            estimator=model_fit, X=X_train, y=y_train\n",
    "#               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLyKSYhT8IiIpRsEvIpJiFPwiIinm/wPtxwf2cHRqOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1afbbd79978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.linspace(5000, 35000, 7), lc_train.mean(1), label='train')\n",
    "plt.plot(np.linspace(5000, 35000, 7), lc_test.mean(1), label='validation')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "Выше используется кастомная кривая обучения, т.к. в процессе разбиения на фолды нужно применить препроцессинг (чтобы избежать переобучения).\n",
    "\n",
    "Кривая обучения свидетельствует о том, что с ростом количества объектов качество модели повышается.\n",
    "Однако, на лицо переобученность модели - т.к. разрыв между качеством на тренировочных и тестовых данных значителен.\n",
    "Это значит, что нужно упрощать модель, либо устранив кодирование по целевой переменной, либо исключив часть признаков, либо усилить регуляризацию, либо все вместе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Часто несбалансированные по классам выборки приводят к различным проблемам при обучении моделей. Давайте попробуем по-разному обработать выборку, поиграть с распределением объектов по классам и сделать выводы о том, как соотношение классов влияет на качество модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1\\. Задайте веса объектам так, чтобы соотношение классов с учетом весов объектов изменилось. Попробуйте не менее трёх различных вариантов весов. Меняются ли результаты классификации? Как это сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanced \n",
    "w1_train = np.float32(y_train*0+1)\n",
    "w1_train[y_train==0] = np.sum(y_train==1)/np.sum(y_train==0)\n",
    "# non churn to 0.25\n",
    "w2_train = np.float32(y_train*0+1)\n",
    "w2_train[y_train==0] = 0.25\n",
    "# non churn to 0.5\n",
    "w3_train = np.float32(y_train*0+1)\n",
    "w3_train[y_train==0] = 0.5\n",
    "# non churn to 0.75\n",
    "w4_train = np.float32(y_train*0+1)\n",
    "w4_train[y_train==0] = 0.75\n",
    "# non churn to 0.95\n",
    "w5_train = np.float32(y_train*0+1)\n",
    "w5_train[y_train==0] = 0.9\n",
    "# non churn to 1.5\n",
    "w7_train = np.float32(y_train*0+1)\n",
    "w7_train[y_train==0] = 1.5\n",
    "# random \n",
    "w6_train = np.random.rand(y_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71943743552569206"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid = transform_xgb(X_train, X_valid, y_train)\n",
    "fit_model = model.fit(X_train, y_train)\n",
    "roc_auc_score(y_valid, fit_model.predict_proba(X_valid)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71542550719788855"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_model = model.fit(X_train, y_train, sample_weight=w1_train)\n",
    "roc_auc_score(y_valid, fit_model.predict_proba(X_valid)[:, 1])\n",
    "\n",
    "# fit_model = model.fit(X_train, y_train, \n",
    "#                       early_stopping_rounds=20, eval_metric=\"auc\", eval_set=[(X_valid, y_valid)], verbose=50,\n",
    "#                       sample_weight=w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71713843272832034"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_model = model.fit(X_train, y_train, sample_weight=w2_train)\n",
    "roc_auc_score(y_valid, fit_model.predict_proba(X_valid)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72005720207061263"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_model = model.fit(X_train, y_train, sample_weight=w3_train)\n",
    "roc_auc_score(y_valid, fit_model.predict_proba(X_valid)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7213821200546463"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_model = model.fit(X_train, y_train, sample_weight=w4_train)\n",
    "roc_auc_score(y_valid, fit_model.predict_proba(X_valid)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71765480804081749"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_model = model.fit(X_train, y_train, sample_weight=w5_train)\n",
    "roc_auc_score(y_valid, fit_model.predict_proba(X_valid)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71300801107796397"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_model = model.fit(X_train, y_train, sample_weight=w6_train)\n",
    "roc_auc_score(y_valid, fit_model.predict_proba(X_valid)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71437300768580214"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_model = model.fit(X_train, y_train, sample_weight=w7_train)\n",
    "roc_auc_score(y_valid, fit_model.predict_proba(X_valid)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "Использование весов дает улучшение на доли процента."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2\\. Примените к выборке технологию undersampling: для этого нужно убрать из обучения некоторое количество объектов большего класса таким образом, чтобы соотношение классов изменилось. Попробуйте не менее трёх различных вариантов undersampling (варианты могут отличаться как по количество отфильтрованных объектов, так и по принципу выборка объектов для отсеивания из выборки). Меняются ли результаты классификации? Как это сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_linear = partial(transform, encode='ohe', scaling=True, fill_num='mean', \n",
    "                           hc_drop=True, high_cardinality=HC, eb_k=HC_K, eb_f=HC_F,\n",
    "                           to_drop=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train, target, test_size=5000, random_state=42, stratify=target)\n",
    "X_train, X_valid = transform_linear(X_train, X_valid, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks, NearMiss, InstanceHardnessThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TomekLinks\n",
    "tl = TomekLinks(return_indices=True, n_jobs=4)\n",
    "_, _, idx_resampled = tl.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=3, learning_rate=0.05, max_delta_step=0,\n",
       "       max_depth=4, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=4, nthread=None, objective='binary:logistic',\n",
       "       predictor='cpu_predictor', random_state=0, reg_alpha=2,\n",
       "       reg_lambda=1.3, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=0.95, tree_method='gpu_hist')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_model = model\n",
    "fit_model.set_params(gamma=3, min_child_weight=1, reg_alpha=2, subsample=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.664109\n",
      "Will train until validation_0-auc hasn't improved in 20 rounds.\n",
      "[20]\tvalidation_0-auc:0.686229\n",
      "[40]\tvalidation_0-auc:0.700331\n",
      "[60]\tvalidation_0-auc:0.706095\n",
      "[80]\tvalidation_0-auc:0.708308\n",
      "[100]\tvalidation_0-auc:0.712377\n",
      "[120]\tvalidation_0-auc:0.715045\n",
      "[140]\tvalidation_0-auc:0.716919\n",
      "[160]\tvalidation_0-auc:0.717881\n",
      "[180]\tvalidation_0-auc:0.719823\n",
      "[200]\tvalidation_0-auc:0.720312\n",
      "Stopping. Best iteration:\n",
      "[193]\tvalidation_0-auc:0.721287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train, target, test_size=5000, random_state=42, stratify=target)\n",
    "X_train, X_valid = transform_xgb(X_train.iloc[idx_resampled, :], X_valid, y_train[idx_resampled])\n",
    "fit_model = fit_model.fit(X_train, y_train[idx_resampled], early_stopping_rounds=20, eval_metric=\"auc\", \n",
    "                      eval_set=[(X_valid, y_valid)], verbose=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# near miss \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train, target, test_size=5000, random_state=42, stratify=target)\n",
    "X_train, X_valid = transform_linear(X_train, X_valid, y_train)\n",
    "\n",
    "nm = NearMiss(version=2, return_indices=True, n_jobs=4)\n",
    "_, _, idx_resampled = nm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5208, 262), (5208,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[idx_resampled, :].shape, y_train[idx_resampled].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.49777\n",
      "Will train until validation_0-auc hasn't improved in 20 rounds.\n",
      "[20]\tvalidation_0-auc:0.482872\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-auc:0.498145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train, target, test_size=5000, random_state=42, stratify=target)\n",
    "X_train, X_valid = transform_xgb(X_train.iloc[idx_resampled, :], X_valid, y_train[idx_resampled])\n",
    "fit_model = model.fit(X_train, y_train[idx_resampled], early_stopping_rounds=20, eval_metric=\"auc\", \n",
    "                      eval_set=[(X_valid, y_valid)], verbose=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster centroids\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train, target, test_size=5000, random_state=42, stratify=target)\n",
    "X_train, X_valid = transform_linear(X_train, X_valid, y_train)\n",
    "\n",
    "cx = InstanceHardnessThreshold(return_indices=True, n_jobs=4)\n",
    "_, _, idx_resampled = cx.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18863,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=3, learning_rate=0.05, max_delta_step=0,\n",
       "       max_depth=4, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=4, nthread=None, objective='binary:logistic',\n",
       "       predictor='cpu_predictor', random_state=0, reg_alpha=3,\n",
       "       reg_lambda=1.3, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=0.9, tree_method='gpu_hist')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_model = model\n",
    "fit_model.set_params(gamma=3, min_child_weight=1, reg_alpha=3, subsample=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.671297\n",
      "Will train until validation_0-auc hasn't improved in 20 rounds.\n",
      "[20]\tvalidation_0-auc:0.682956\n",
      "[40]\tvalidation_0-auc:0.699372\n",
      "[60]\tvalidation_0-auc:0.701242\n",
      "[80]\tvalidation_0-auc:0.703414\n",
      "[100]\tvalidation_0-auc:0.704921\n",
      "[120]\tvalidation_0-auc:0.705794\n",
      "[140]\tvalidation_0-auc:0.707154\n",
      "[160]\tvalidation_0-auc:0.708016\n",
      "[180]\tvalidation_0-auc:0.708301\n",
      "[200]\tvalidation_0-auc:0.709302\n",
      "[220]\tvalidation_0-auc:0.711541\n",
      "[240]\tvalidation_0-auc:0.710642\n",
      "Stopping. Best iteration:\n",
      "[220]\tvalidation_0-auc:0.711541\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train, target, test_size=5000, random_state=42, stratify=target)\n",
    "X_train, X_valid = transform_xgb(X_train.iloc[idx_resampled, :], X_valid, y_train[idx_resampled])\n",
    "fit_model = fit_model.fit(X_train, y_train[idx_resampled], early_stopping_rounds=20, eval_metric=\"auc\", \n",
    "                      eval_set=[(X_valid, y_valid)], verbose=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "Были испробованы 3 стратегии under-sampling'а:\n",
    "Tomek links, NearMiss и Instance Hardness Threshold.\n",
    "Неплохо себя проявил метод Tomek links. При переподборе гиперпараметров (особенно повышении subsample) они дал небольшое улучшение на отложенной выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Теперь перейдем к работе с признаками. Ранее вы реализовали несколько стратегий для обработки пропущенных значений. Сравните эти стратегии между собой с помощью оценки качества моделей кросс-валидации, построенных на датасетах с использованием различных стратегий. Как обработка пропущенных значений сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.n_estimators = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  0\n",
      "Fold  1\n",
      "Fold  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.69168834942408386"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -1 (default)\n",
    "np.mean(cross_val(X_train_, y_train_, model, kf, transform_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71943743552569206"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid = transform_xgb(X_train_, X_valid_, y_train_)\n",
    "model.fit(X_train, y_train)\n",
    "roc_auc_score(y_valid_, model.predict_proba(X_valid)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  0\n",
      "Fold  1\n",
      "Fold  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.70310256049977393"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean \n",
    "transform_fill = partial(transform_xgb, fill_num='mean')\n",
    "np.mean(cross_val(X_train_, y_train_, model, kf, transform_fill))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71791444782111691"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid = transform_fill(X_train_, X_valid_, y_train_)\n",
    "model.fit(X_train, y_train)\n",
    "roc_auc_score(y_valid_, model.predict_proba(X_valid)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  0\n",
      "Fold  1\n",
      "Fold  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.69504775091586757"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# median \n",
    "transform_fill = partial(transform_xgb, fill_num='median')\n",
    "np.mean(cross_val(X_train_, y_train_, model, kf, transform_fill))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71378170277227915"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid = transform_fill(X_train_, X_valid_, y_train_)\n",
    "model.fit(X_train, y_train)\n",
    "roc_auc_score(y_valid_, model.predict_proba(X_valid)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "Были испробованы 3 стратегии заполнения средних: отрицательным значением, средней и медианой.\n",
    "Результаты на отложенной выборке и кросс-валидации разделились:\n",
    "на большой выборке лучше себя показало заполнение минус единицей, на кросс-валидации средней.\n",
    "Значит, стоит их проверить после отбора признаков и оптимизации гипермараметров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Также вы уже реализовали несколько стратегий для обработки категориальных признаков. Сравните эти стратегии между собой с помощью оценки качества моделей по кросс-валидации, построенных на датасетах с использованием различных стратегий. Как обработка категориальных признаков сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  0\n",
      "Fold  1\n",
      "Fold  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.703119365533309"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encoding \n",
    "transform_fill = partial(transform_xgb, encode='ohe')\n",
    "np.mean(cross_val(X_train_, y_train_, model, kf, transform_fill))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71851388462932508"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid = transform_fill(X_train_, X_valid_, y_train_)\n",
    "model.fit(X_train, y_train)\n",
    "roc_auc_score(y_valid_, model.predict_proba(X_valid)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  0\n",
      "Fold  1\n",
      "Fold  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.70162243304387051"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# binary encoding \n",
    "transform_fill = partial(transform_xgb, encode='bin')\n",
    "np.mean(cross_val(X_train_, y_train_, model, kf, transform_fill))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71943743552569206"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid = transform_fill(X_train_, X_valid_, y_train_)\n",
    "model.fit(X_train, y_train)\n",
    "roc_auc_score(y_valid_, model.predict_proba(X_valid)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  0\n",
      "Fold  1\n",
      "Fold  2\n",
      "0.730193382815\n",
      "0.720143167814\n"
     ]
    }
   ],
   "source": [
    "# no nan preprocessing\n",
    "model.missing = -1\n",
    "print(np.mean(cross_val(X_train_, y_train_, model, kf, transform_fill)))\n",
    "X_train, X_valid = transform_xgb(X_train_, X_valid_, y_train_)\n",
    "model.fit(X_train, y_train)\n",
    "print(roc_auc_score(y_valid_, model.predict_proba(X_valid)[:, 1]))\n",
    "model.missing = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  0\n",
      "Fold  1\n",
      "Fold  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.57577614454687343"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# high cardinality supervised ratio\n",
    "transform_fill = partial(transform_xgb, hc_drop=False, high_cardinality=\"sr\", eb_k=50, eb_f=2)\n",
    "np.mean(cross_val(X_train_, y_train_, model, kf, transform_fill))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59234811944126908"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid = transform_fill(X_train_, X_valid_, y_train_)\n",
    "model.fit(X_train, y_train)\n",
    "roc_auc_score(y_valid_, model.predict_proba(X_valid)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:161: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:161: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:161: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.62600482734647489"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# high cardinality weight of evidence \n",
    "transform_fill = partial(transform_xgb, hc_drop=False, high_cardinality=\"woe\", eb_k=50, eb_f=2)\n",
    "np.mean(cross_val(X_train_, y_train_, model, kf, transform_fill))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:161: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.64210456919545356"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid = transform_fill(X_train_, X_valid_, y_train_)\n",
    "model.fit(X_train, y_train)\n",
    "roc_auc_score(y_valid_, model.predict_proba(X_valid)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  0\n",
      "Fold  1\n",
      "Fold  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.59966963683474073"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# high cardinality smoothing k=30, f=5\n",
    "transform_fill = partial(transform_xgb, hc_drop=False, high_cardinality=\"smoothing\", eb_k=30, eb_f=5)\n",
    "np.mean(cross_val(X_train_, y_train_, model, kf, transform_fill))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60638260796832744"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid = transform_fill(X_train_, X_valid_, y_train_)\n",
    "model.fit(X_train, y_train)\n",
    "roc_auc_score(y_valid_, model.predict_proba(X_valid)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  0\n",
      "Fold  1\n",
      "Fold  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.72110511720579307"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# high cardinality smoothing k=80, f=2\n",
    "transform_fill = partial(transform_xgb, hc_drop=False, high_cardinality=\"smoothing\", eb_k=80, eb_f=2)\n",
    "np.mean(cross_val(X_train_, y_train_, model, kf, transform_fill))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73462026375219569"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid = transform_fill(X_train_, X_valid_, y_train_)\n",
    "model.fit(X_train, y_train)\n",
    "roc_auc_score(y_valid_, model.predict_proba(X_valid)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  0\n",
      "Fold  1\n",
      "Fold  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.59679721085142301"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# high cardinality smoothing k=80, f=5\n",
    "transform_fill = partial(transform_xgb, hc_drop=False, high_cardinality=\"smoothing\", eb_k=80, eb_f=5)\n",
    "np.mean(cross_val(X_train_, y_train_, model, kf, transform_fill))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60427296214719195"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid = transform_fill(X_train_, X_valid_, y_train_)\n",
    "model.fit(X_train, y_train)\n",
    "roc_auc_score(y_valid_, model.predict_proba(X_valid)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:173: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH3raifut6HC6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cc8dce0978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = np.linspace(0.1, 1, 10)\n",
    "auc_scores = []\n",
    "for f in params:\n",
    "    transform_fill = partial(transform_xgb, hc_drop=False, high_cardinality=\"smoothing\", eb_k=80, eb_f=f)\n",
    "    X_train, X_valid = transform_fill(X_train_, X_valid_, y_train_)\n",
    "    model.fit(X_train, y_train)\n",
    "    auc_scores.append(roc_auc_score(y_valid_, model.predict_proba(X_valid)[:, 1]))\n",
    "    \n",
    "plt.plot(params, auc_scores);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  0\n",
      "Fold  1\n",
      "Fold  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.72249520678078272"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_fill = partial(transform_xgb, hc_drop=False, high_cardinality=\"smoothing\", eb_k=80, eb_f=0.5)\n",
    "np.mean(cross_val(X_train_, y_train_, model, kf, transform_fill))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  0\n",
      "Fold  1\n",
      "Fold  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.72189215633046067"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_fill = partial(transform_xgb, hc_drop=False, high_cardinality=\"smoothing\", eb_k=80, eb_f=1)\n",
    "np.mean(cross_val(X_train_, y_train_, model, kf, transform_fill))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  0\n",
      "Fold  1\n",
      "Fold  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.72110511720579307"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_fill = partial(transform_xgb, hc_drop=False, high_cardinality=\"smoothing\", eb_k=80, eb_f=2)\n",
    "np.mean(cross_val(X_train_, y_train_, model, kf, transform_fill))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ccae1e4898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# K \n",
    "params = np.linspace(60, 90, 6)\n",
    "auc_scores = []\n",
    "for k in params:\n",
    "    transform_fill = partial(transform_xgb, hc_drop=False, high_cardinality=\"smoothing\", eb_k=k, eb_f=0.5)\n",
    "    X_train, X_valid = transform_fill(X_train_, X_valid_, y_train_)\n",
    "    model.fit(X_train, y_train)\n",
    "    auc_scores.append(roc_auc_score(y_valid_, model.predict_proba(X_valid)[:, 1]))\n",
    "    \n",
    "plt.plot(params, auc_scores);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "Для обработки пустых значений категориальных признаков использовалась перекодировка в отдельный уровень(-1) и отках от кодирования (XGBoost способен обрабатывать пустые значения самостоятельно). \n",
    "Лучший результат показало стандартное кодирование в -1 в сочетании с передачей его в XGBoost в качестве пустого значения.\n",
    "Т.е. это по сути отказ как от заполнения пустых значений как категориальных, так и числовых переменных.\n",
    "\n",
    "Для преобразования категориальных переменных сравнивались one hot и binary кодирование. Binary кодирование показало себя лучше, на таком же уровне как и отказ от кодирования. \n",
    "\n",
    "Также были опробованы разные варианты кодирования категориальных значения с большим числом уроней (high cardinality).\n",
    "Здесь лучшим оказался метод замены уровней на соответствующие средние предсказываемых классов (со сглаживанием).\n",
    "Лучшие параметры: k=78, f=0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Все ли признаки оказались полезными для построения моделей? Проведите процедуру отбора признаков, попробуйте разные варианты отбора (обратите внимание на модуль `sklearn.feature_selection`). Например, можно выбрасывать случайные признаки или строить отбор на основе l1-регуляризации - отфильтровать из обучения признаки, которые получат нулевой вес при построении регрессии с l1-регуляризацией (`sklearn.linear_model.Lasso`). И всегда можно придумать что-то своё=) Попробуйте как минимум 2 различные стратегии, сравните результаты. Помог ли отбор признаков улучшить качество модели? Поясните свой ответ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оптимальный препроцессинг \n",
    "opt_transform = partial(transform_xgb, eb_k=80, eb_f=0.5,\n",
    "                        feature_dtypes=X_train_.dtypes, \n",
    "                        feature_names=X_train_.columns)\n",
    "# оптимальная модель\n",
    "opt_model = model.set_params(missing=-1, n_estimators=200)\n",
    "X_train, X_valid = opt_transform(X_train_, X_valid_, y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74204874954693745"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before\n",
    "opt_model.fit(X_train, y_train_)\n",
    "roc_auc_score(y_valid_, opt_model.predict_proba(X_valid)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  0\n",
      "Fold  1\n",
      "Fold  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.72464587328326413"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val(X_train_, y_train_, opt_model, kf, opt_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFEClass():\n",
    "    \n",
    "    def __init__(self, model, scorer=roc_auc_score, step=1, min_features=20):\n",
    "        \n",
    "        self.model = model\n",
    "        self.step = step\n",
    "        self.scorer = scorer\n",
    "        self.min_features = min_features\n",
    "        \n",
    "    def fit(self, X_train, X_valid, y_train, y_valid):\n",
    "        \n",
    "        # init vars\n",
    "        self.X_train_ = X_train\n",
    "        self.X_valid_ = X_valid\n",
    "        self.y_train_ = y_train\n",
    "        self.y_valid_ = y_valid        \n",
    "        \n",
    "        n_features = []\n",
    "        scores = []\n",
    "        support = np.full(X_train.shape[1], 1)\n",
    "        dropped = []\n",
    "        keep = []\n",
    "                \n",
    "        # fit \n",
    "        \n",
    "        while self.X_train_.shape[1] > self.min_features:\n",
    "            \n",
    "            self.model.fit(self.X_train_, self.y_train_)\n",
    "            \n",
    "            n_features.append(self.X_train_.shape[1])\n",
    "            print(n_features[-1]) \n",
    "            scores.append(self.scorer(self.y_valid_, \n",
    "                                      self.model.predict_proba(self.X_valid_)[:, 1]\n",
    "                                     ))\n",
    "            \n",
    "            coef = self.model.feature_importances_\n",
    "            \n",
    "            if np.sum(coef==coef.min()) > self.step:\n",
    "                to_drop = np.random.choice(np.where(coef==coef.min())[0], self.step)\n",
    "            else:\n",
    "                to_drop = np.argsort(coef)[:self.step]\n",
    "\n",
    "            drop_cols = self.X_train_.columns[to_drop]    \n",
    "            drop_vec = np.isin(self.X_train_.columns, drop_cols)\n",
    "            support += np.int32(np.isin(X_train.columns, drop_cols))\n",
    "            keep.append(support.copy())\n",
    "            \n",
    "            # update X\n",
    "            self.X_train_ = self.X_train_.loc[:, ~drop_vec]\n",
    "            self.X_valid_ = self.X_valid_.loc[:, ~drop_vec]                            \n",
    "            \n",
    "            # filter zero importances\n",
    "            \n",
    "#             self.X_train_ = X_train.loc[:, coef!=0]\n",
    "#             self.X_valid_ = X_valid.loc[:, coef!=0]\n",
    "        \n",
    "        # assign results\n",
    "        self.n_features_ = n_features\n",
    "        self.scores_ = scores \n",
    "        self.support_ = support\n",
    "        self.keep_ = keep\n",
    "        \n",
    "        return self \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226\n",
      "221\n",
      "216\n",
      "211\n",
      "206\n",
      "201\n",
      "196\n",
      "191\n",
      "186\n",
      "181\n",
      "176\n",
      "171\n",
      "166\n",
      "161\n",
      "156\n",
      "151\n",
      "147\n",
      "142\n",
      "138\n",
      "133\n",
      "128\n",
      "124\n",
      "120\n",
      "115\n",
      "111\n",
      "106\n",
      "101\n",
      "96\n",
      "91\n",
      "86\n",
      "81\n",
      "76\n",
      "71\n",
      "66\n",
      "61\n",
      "56\n",
      "51\n",
      "46\n",
      "41\n",
      "36\n",
      "31\n",
      "26\n",
      "21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.RFEClass at 0x1c723329a58>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe = RFEClass(opt_model, step=5)\n",
    "rfe.fit(X_train, X_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c755fcc828>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl4W+d1J/7vwUZwAbgTpEhKJCVR1GbJtqzFsmPHsh07\ncex4pk3sbM7SOE6TTJqnk048nWem7S/tpONOmzTx/PxzHddJ3SZ1mqTxL3HiRV7iRbutjYskipTE\nBQQJgMRGYn/nD9wLgSCWCxAreT7Po0cicAFeQiDOfd9z3vOSEAKMMcaYqtgnwBhjrDRwQGCMMQaA\nAwJjjDEJBwTGGGMAOCAwxhiTcEBgjDEGgAMCY4wxCQcExhhjADggMMYYk2iKfQKZaGpqEl1dXcU+\nDcYYKysnTpywCiGa0x2nKCAQ0V0AvgtADeApIcS34+7/BoBPxDznZgDNQgi7dL8awHEAE0KIe+Ie\n+8cA/kY63prqPLq6unD8+HElp8wYY0xCRJeVHJd2ykj6MH8cwN0AtgB4kIi2xB4jhHhMCLFTCLET\nwKMA3pCDgeRrAAYTPHcngDsBXFFysowxxvJHSQ5hN4BhIcSIEMIP4CcA7ktx/IMAfix/QUQdAD4E\n4KkEx/4dgD8BwB32GGOsyJQEhHYAYzFfj0u3LUFEVQDuAvCzmJu/g8iHfjju2PsQmUI6lckJM8YY\ny49cVxl9GMDbMbmDewBMCyFOxB4kBY7/CuC/p3tCInqYiI4T0fGZmZkcny5jjDGZkoAwAaAz5usO\n6bZEHkDMdBGA/QDuJaJLiEw13UZEzwJYD6AbwCnpvg4A7xJRa/wTCiGeFELsEkLsam5OmyRnjDGW\nJSUB4RiAjUTUTUQ6RD70n48/iIhqAdwC4JfybUKIR4UQHUKILulxrwohPimEOCOEaBFCdEn3jQO4\nTggxtfwfiTHGWDbSlp0KIYJE9BUALyJSdvq0EKKfiB6R7n9COvR+AC8JITx5O1vGGGN5Q+W0heau\nXbsEr0Ngq8U7w1a0GPXY0FJT7FNhZY6ITgghdqU7jltXMFai/uhfT+Lx14aLfRpsFeGAwFgJCoTC\nmHH7MDvvL/apsFWEAwJjJWjG5YMQgHMhUOxTYasIBwTGStCU0wsAcHBAYAXEAYGxEjQdDQjBIp8J\nW004IDBWgqYckYDg9PIIgRUOBwTGSpDF5QMA+INheAOhIp8NWy04IDBWgizSCAHgPAIrHA4IjJUg\nOakMcEBghcMBgbESZHF6YdBHOstw6SkrFA4IjJUgi9OHXpMBAI8QWOFwQGCsxLh9Qbh9QfSaIj2M\nOCCwQuGAwFiJsUj5g40tkRECTxllbsrhRTk17iwVHBAYKzFyhdHG6AiBF6dlYtTqwb5vH8Rbw9Zi\nn0rZ4YDAWImRK4za6ypRU6HhKaMMnbe4IARwdsJZ7FMpOxwQGCsxFmdkUZrJqIdRzwEhU2P2eQDA\nJSvv1ZUpDgiMlRiL0wtDhQbVFRoYK7XcviJD47MLAIBRGweETHFAYKzEWJxemGr1AIDaSi2PEDI0\nPssjhGxxQGCsxEw5vWg1Xg0IXGWUmTF7ZIQw7fLB4+OEfCY4IDBWYiwOL1qMFQAQmTLigKCYEALj\ns/PRgHqJp40ywgGBsRISDgtMu3yLRgg8ZaTc7HwAHn8IN29sAgBcss4X+YzKCwcExkqIzeNHMCzQ\nGpND8PhDCITCRT6z8iBXGN0kBwQeIWSEAwJjJURepdxiiAQEIze4y4hcYbSxxQCTsQIjMxwQMsEB\ngbESIgeE6AihSgsAcHo5OarEmFRh1NFQia7Gah4hZIgDAmMlRF6lHJtDALjBnVLjs/OordTCqNei\np7maS08zxAGBsThmx0LR5uwtDi9UBDTV6ACs7IAghMj59qBj9gV0NlQCALoaq2Hz+HlhXwY4IDAW\nY8EfwoH//Qae/N1IUb6/xelDU00FNOrIr6ZRL00ZrcCA8NPj49j5Fy/hnYu5a0I3NjuPzvoqAEBX\nUzUAXqCWCQ4IjMUYnnZj3h/Ca0PTRfn+U04vTNJ0EbCyRwgv9k/BGwjj4R+dwNkJx7KfTwiBidkF\ndNRHRgjdUkAY5YCgGAcExmKcs7gAACfH5oqyytUSFxCMKzQghMICRy/ZcfvmFhj1GnzmH48u+4N7\nxuWDLxhGZ0NkhLC2oQpEvBYhExwQisTpDeDoqL3Yp8HinJcCQlD6wCo0i9OL1tqK6Nd6rRo6jWrF\nTRkNmp1weYP48I41+NHn9yAUFvjUD45Eq6yyMSaVnMojBL1WjTW1lVxplAEOCEXyT4cu42NPHlrW\nLwDLvfMWF3qaqqFTq/BOgTdY8QZCmJ0PwGTQL7q9dgV2PD08YgMA7OluxIaWGjzz2d2we/x46Omj\ncMxn97PKTe3kHAIAdDVV8ZRRBjggFMn47DyEuPqLUShTDi+mOQgldX7KhWs6anHt2jq8PVzY/5sZ\nl7QPQu3SgLDSpoyOjNqxrrEqut5iR2cdnvzULlyccePzPzyGBX/m1Ufj0RFCTEDgtQgZ4YBQJJNz\nkQ/lQxcL+6Hz2WeO4dNPH+X9ZhNweQOYdHjR22rA/g1NGDA7Yff4C/b949cgyFbaJjnhsMCxS3bs\n6W5YdPtNG5vwnY9dixNXZvGVf3k349LfMfs8mmp0qNSpo7d1N1Vjbj6A2QL+P5YzDghFYnZErmYO\nFXCEcNnmwaDZiaEpF+83m8B5ixsAsMlkwP4NjQAKG7CnpL2UTcYEU0YraF/lcxYX5uYD2NvTuOS+\nD13Thr+4bxsODk3jmz87g3BY+YXL2Oz8otEBEBkhALxZjlIcEIrE7PBCr1Xhsm0ek3MLBfmeLw9Y\nAESuOJ96c7Qg37OcyAnlXpMB13TUoVqnxts5rJFPx5JkhLDSpoyi+YMEAQEAPrV3Hb5+ey9+9u44\nfnpiTPHzjseUnMp4LUJmOCAUgdsXhMsbxF1bWwEU7ir0pX4L+loN+MLNPXjj/Ez0A5BFnLe4UKVT\no72uElq1Cnt6Ggs6QrA4IxcJxkrNottXWkA4MmJHR30l2usqkx7znw5sQKtRj3cUvv6hsMDk3EK0\n5FS2tqEKKuKAoJSigEBEdxHROSIaJqJvJrj/G0R0UvpzlohCRNQQc7+aiN4jol/F3PYYEQ0R0Wki\n+gUR1eXmRyp9ZmlEcOumFtRXaQsybWRz+3D8sh13bjHhE3vXQa9V4em3VvYowbEQwMCkU/Hx5y0u\nbGypgUpFAIAb1zdi1Oop2AjO4vTBZNSDiBbdbqzUwuUNZDR9UqrCUjnvnu7EowMZEWF7Ry3OKFyw\nZnF6EQiJRRVGAKDTqNBRX4VRG69FUCJtQCAiNYDHAdwNYAuAB4loS+wxQojHhBA7hRA7ATwK4A0h\nRGwR99cADMY99csAtgkhrgFwXnrcqjApzRWvqavEXukqNN9J3oND0wgL4M6trWio1uE/XteBn783\nEa1sWSl8wRB+e9aMR/7pBG741iv44N+/ieFpZSOhc1Nu9JoM0a/3b4j01H+7QPmW+FXKstpKLcIC\ncPvLP49wYdoNu8ePvT0NaY/d3l6LUasHbgULBOV9EOKnjIDItFG5jxBy3fMpGSUjhN0AhoUQI0II\nP4CfALgvxfEPAvix/AURdQD4EICnYg8SQrwkhJD/pw8D6MjkxMvZlJRQbqvVY9/6RkzMLUT3gc2X\nlwcsWFOrx9Y1RgDA527qhj8YxrOHL+f1+xZCOCxweMSGR39+Gjd86xU88uy7OH55Fr+/K/KWerHf\nkvY57B4/rG4fNrVeDQibTAY0VusUT1sslyVmL+VY0dXKWdbnl5Ijo5HXMlFCOd729loIAfQrGCXI\ni9Lip4wAoLuxCpesnrKsrHN6A/jewQvY+z8P4sz48tt7pKNJfwjaAcRmdsYB7El0IBFVAbgLwFdi\nbv4OgD8BYEj0GMnnAPyrgnNZESbnvCCKVJPsk34xDo1YsbZxbV6+34I/hDcvzOBjuzqj0xHrm2tw\noK8Fzx6+jC/duh56rTrNs5SmX56cwF//ZgiTDi+qdGp8YGsrPnJtO/avb4RGrcLZSSde6p/Cl9+/\nIeXzyPmUjTEjBJWKsG99I94etkIIsWQqJ5eEEFLbiool98kN7hwLAXTm7QwK48iIHWtq9Qmv5ONt\na68FAJyZcCRNQMvGZ+dBBKypWxpQu5qq4fIFYfP40VSz9PUtRXPzfjz91ij+8Z1LcHmDONDXAr02\n/ynfXH+HDwN4W54uIqJ7AEwLIU4kewAR/SmAIIB/TnL/w0R0nIiOz8zM5Ph0i8PsWEBTTQV0GhU2\ntNSgqaYir8nLNy/MwBsI404piS37/M3dsHn8+Pf3JvL2vfPtr14YRHWFBt99YCeO/7fb8Xcf24lb\nepuj3ULv3GLCqXFHtKQzmQtSQNhkWnzdcuP6Jky7fLg4487PDyBxLgThDYSTThkBKPvVykIIHBm1\nYU9Po6Lg2myoQKtRryiPMGZfgMmgR4Vm6YVNOVUa2dw+/PVvh7D/26/i718dxv71TfjVV2/CDz5z\nw6KLlXxREhAmgEUXJh3SbYk8gJjpIgD7AdxLRJcQmWq6jYiele8kos8AuAfAJ0SS8ZwQ4kkhxC4h\nxK7m5mYFp1v6zA4v1kgrNIkIe3sacGgkf3mElwYsMOo12B23EGhfTyO2tBnx1FujZZmwtLp9sDh9\n+NgNnbhvZzuqdEsHvHduMQEAXh5MPW10zuKCQa9ZcoUur0fI96pleVFayoBQ5pVGF2fcsLqV5Q9k\nShPL47Pz0X0Q4nU3ln7X07l5P/7qhUHc9Nev4Yk3LuL9fS347R/djCc+dX10pFQISgLCMQAbiaib\niHSIfOg/H38QEdUCuAXAL+XbhBCPCiE6hBBd0uNeFUJ8Ujr+LkSmku4VQqyqEgCzwxtdsg8A+9Y3\nwuL05eUNGwyFcXDQgtv6WqBVL/7vJiJ84X3dGJ52440L5Tf66pcqiLZIeZFENrTUoKuxKroGI5nz\nU25sMhmWXLmubahCe11l3hPL8VtnxpK30Sz30tPDI5E6k3QVRrGUJpYjaxCW5g+ASKJZo6KSbmHx\nrV8P4qk3R/CBrSa8/PX34fsfvw59rcnf1/mSNiBIid+vAHgRkUqh54QQ/UT0CBE9EnPo/QBeEkIo\nfdW/j0he4WWpXPWJDM+9LAkhYJ5bQFvt1auZq3mE3F+Fnrg8i9n5AO7Y0prw/g9tXwOTsQI/KMOF\nanJJ6da25FdQRIQ7t7bi0EVr0ikXIQTOT7vQ27p0SE5E2L+hEYdHbAjlcRSVrG0FEFlICKDsVysf\nGbXDZKzAusbEH9yJKEksB0JhmB0L6EySl9CoVehsKO0mdyfH5nBbnwnfeeBabGjJ/9RQMopyCEKI\nF4QQvUKI9UKIv5Rue0II8UTMMc8IIR5I8RyvCyHuifl6gxCiUy5XFUI8kuyxK4nTG4THH1qU/Opu\nqkarUZ+XPMLLAxbo1CrcsinxdJtOo8JDN3bhrWErBs3Ka/ZLQf+kA+11ldEr6GTu2GJCICTwxrnE\no6AZlw9z8wH0ttQkvH//hiY4vUH0T+avysMi5TiaDUuTnjUVGqhVVNYjBCEilWB7upXlD2SxieVk\nzHNehAXQkaDCSNbVWIXREt0XwRcMYdTqQV+CC5JC45XKBSYnN2NHCESRapbDI/ac5hGEEHhpwIIb\nNzSipiJ5QdnHd69FpVZddu0sBiad0TLaVK5bW4/Gah1eSjJtJG+Kk2iEAESm9ID85hEsLi/qq7QJ\nq72IqOwb3I1aPZhx+bAng/wBoCyxPDabfA2CrKupGpdtpVl6OjztRigsFpU8FwsHhAKbjFmDEGtf\nTyOsbh+Gp3NXzXLe4sYV+zzuTDJdJKur0uGjuzrw/KmJsmmN7fEFMWrzYOua9Ak3tYpwYHMLXh+a\nhj+4tIOm3NSuN0kVR4tBj15TTU73/o035fAlTCjLjGXevuKItBmUkvUH8ba1p04sJ9oHIV5PUzXm\n/SFMl+BCzHNTkQsSHiGsQmap7XVbXB8X+So0l4ugXuqfAgDcvrkl7bGf3d+NYFjgR4fKY6Ha0JQT\nQqROKMe6Y0srXL5gdGFUrPNTLjRW61LWqN+4vgnHLtnhC+Znxei0K/EqZdlyN8m5ZPXg3SuzWT9+\nuY6M2NBUU4EeqQQ0E9d0pE4sj9kXoFbRkousWF0lvL/yuSkXdGpV9ByLiQNCgZkdC1ARYIqbK+6U\nqllymUd4edCCa9fWoSXFB42sq6kad2w24dkjl7PanKTQogllhQHh5o1NqNSq8VKCVcvnLK6kowPZ\n/g1N8AbCePfyXOYnq8CUI/EqZVm2De7CYYGn3hzBnd/5HT711JG8JsaTieQP7NjT05DV4r50ieWx\n2Xm01eqja08Skdtgl+JahKEpFza01CypAiyG4p/BKmN2eNFiSPzm3be+EYdHbTlZE2B2LOD0uAN3\nSHX4Snx0Vyfm5gOKG4oVU/+kE3VV2pRXhbH0WjVu3tiElwcsi+aRhRC4YHGh15Q4oSzb09MAFSEv\n00bBUBhWt2/JTmmxspkyGrPP44F/OIxv/XoQLYYKePyh6PRKIV2xz2PK6cXe7szyB7J0ieXx2YWU\n00VApG+YTq0qyX0Rzk25SmK6COCAUHBmx0LCWnMgkkeYmw9gaGr5balfkRKo6fIHseRfvKGp0q82\n6pcSyplccd65tRVTTu+iD5aJuQV4/KGkCWWZUa/F9o66vPQ1srr9CAskbFsR+/2Vlp0KIfDjo1dw\n13d+h8FJJx77vWvwvQevBXB1vrqQjoxknz8A0ieWx+zzaVthqFWEtVJPo1IyN+/HlNNbEgllgANC\nwZnnvAn7rQBX8wi5WI/w0oAFPU3V2JCklDIRk7ECdVXaki8/DYTCOGdxKUoox7qtrwUqwqJFahfS\nJJRj7V/fiFNjc4q6b2Yi1RoEWWTXtEDaKplZjx+fe+YYHv35GezorMNvv/4+/P6uzmjbgws5LFpQ\n6vCoDY3Vuozei/GSJZa9gUiiOFFTu3hdjdW4VGKlp/LFHweEVUgIAbPDu6jkNNaaukqsa6xadh7B\nsRDAoYs23LFV+XQREClv7Gs1YNBc2hvnXJxxwx8MY0tbZis5G6p1uKGrYVEeIVpyqmAx0P4NTQiG\nBY4mSEwvR7KtM2PVVmrhD4XhDaTeZ/iJ313Emxes+LMPb8Gzn98T3YSmpkKD9rrKomyKdGTEjt3d\n2eUPZMkSyxPSXhVKmuV1N1Xhks1TUm1arlYYFX5VciIcEArIsRDAQiCUct57X08jjowub1Xs6+em\nEQyLaB+fTGxuM+LclKukfmni9U9kllCOdccWE85ZXLgszSWfn3Kh1ahPu7gNAK5fVw+dRpXz9QjT\nrvQBQd5FLV0e4cy4A1vXGPGZ/d3RjX5kvaaagk8ZjdnnMTG3gD1Z5g9kyRLL4ynaXsfraqqGLxiO\njshKwdCUC7WV2pTThYXEAaGAJueWLkqLt299I1zeYEY7fcV7ecCCppoK7Oysz/ixm1uNWAiEcNle\nWkPrWANmJ/RaFXqaM5+CkHMq8rTR+WkXNqZJKMv0WjV2ravHWxdym1iecnihUREaq3VJj1HS8VQI\ngf5JJ7YkmUrrbTVgZMaDYCj1KCOX5PUH6dpXp5MssSxvjJMuqQyUZpO7c1NObGpd2kOrWDggFJBZ\nXpSWJIcAYNH+CNnwBUN4/dwMbt/cArUq8zdZX1tk6mSohPMI/ZMObGo1ZvXzrW2sQl+rAS8NWBAK\nC1ywuJe0vE7lTmmEcWosd+WnU04vWgwVS67oY8kBIdUIYWJuAY6FQNKRU2+LAf5QuKDB/vCIDXVV\n2oxe40TkxPLZ+IAwOw+dWoWWBC0/4pXaWgQhBM5b3CVTYQRwQCgos7x1ZooRQotRj/XN1VlXsxy/\nNAu3L4jbN2c+XQREkqsqAgaLUI2ihBBCccuKZO7cYsLxS3acHJuDLxhWlFCW/YfrO1ClU+d0Ad+0\nM3XJKRCzSU6KXdP606zNkH/O8xn+3z7+2jAee3Eoo8fIjozasLurIWWwU2pbey1OJ5gyaq+vVPT8\nrUY9KjSqkqk0Gp9dgNsXLJn8AcABoaDMjsiKykQNzGLtW9+IY6N2BLIY2r81bIVG2ukrG3qtGt1N\n1SVbaTQ+uwCnN7isgHDHllaEBfDEGxcBJO9hlIhRr8X917bj/z89CbvHn/U5xJpKsnVmLCVTRv2T\nTqgoeYJyQ0sNiK626lDqX45cwTNvX8r4/Thmn8eYfSHr92K8RK2wxxWUnMpUKkJ3U3XJtME+V2IV\nRgAHhIIyz3lhMlSknerY19MEjz+U1QKxt4etuG5tPapTNLNLp6/NWLJrEaJ7IGRYYRRrW7sRbbX6\naB5hY4blkJ/e1wV/MIznjo+lP1iByNaZygJCqimjgUkHepprUKlLvB1qpU6NtQ1VGVUaWd2+6FqN\n0xnu6SuXT9+4vimjxyVzTcfSxHKqfRAS6WqsLpkpI7nCjQPCKmV2eJf0MEpE3lHq7QyTl7MeP85M\nOLB/w/J+Abe0GTFmX4CrBLdsHDCnvgpWgoiiK7g76iszDp6bWg3Y092AZw9fXnYriHl/EC5vMG1A\nMOjTVxn1K5hK29hiyCggnB6/mis5lOEq7UMXI+sP0q0CVyo+seyR9klOtlNaIl1N1RizLxSlhUe8\noSkXOuorU3YiLjQOCAVkdiwoarXQWFOBHR21ODg0ndHzR7bhBG7auLwhupzkKsaq1nQGJh1Yn+Iq\nWCm52ijbZOen93VhfHYBr2X4fxRPXoPQWpt6GlGjVqGmInkLbLvHD7PDmzYgbGqtwajVk7DrayIn\nxxxQUaRbaCbltkIIvHPRin3rM9v/IJX4xLJccprJCKG7qQr+UBiT0vqFYhoyO0sqoQxwQCiYq4vS\nlPXeObDZhFPjc5jJoF3vW8NW1FRosKOjLtvTBBCZMgJKM7EcKatcfhJuT08D2mr12NWVXX38nVtN\nMBkr8KPDy0suW5yR/1+TIf37IrJaOfEq6avN/lKv3u41GRAMC8XTJqfG5tBrMuC2vhacuDILb0BZ\n48MRqwcWpy9n00Wy2BXLV9teZzBCKJHSU18whBGrp6SmiwAOCAVj9/jhC4ZTrkGIdWBzC4RARleg\nbw9bsbenMWXXRyXW1Oph1GtKLrGs9CpYCa1ahde/cSu++L6erB//8d3r8LvzM8v6cJH3Uk5XZQSk\nbnAn7+amZMoIgKJpIyEETo3PYWdnHW7c0Ah/MIx3LytroS1Xyd2Yo4SybHt7LUakxLK8BiGzEYLU\n9bTIieWL0x5pU5zSqTACOCAUTLTkNMUahFhb2oxYU6vHK4OpN4eXjdnncdk2j5s2LP8XkIgiieUS\nCwhKr4KVqtCol1UO+eDuTmhUhH9aRgmqvGo2XQ4BiOyt7EwaEJxor6tEXVXyxW0A0NNcDbWKcEFB\nQLhin8fcfAA7OutwQ1cD1CrC2wrzCIcuWrGmVp/R/slKbO8wRhPL47MLqNSq0VST+meO1WyoQLVO\nnXUQ//K/vIsnf3cxq8fGOmeJvJd5ymiVMifYOjMVIsJtm1vw5gWromH6W8ORX9SbNuZmiL6lBFtY\nDJgjV8HLqTDKpRajHndta8VPT4xh3p9dwzuL04uaCo2ixGKqTXL6Jx3YrOB10WvVWNdYFa1wSeWk\ntPjumo5aGPRa7OioVbQ+JhwWOHTRhr05zB/IYhPLY7ORktNMvgcRYV1jNS7OZB4Qpp1e/Pq0GX/1\nwhBeP7e83NGQtClOdwlsihOLA0KBmJNsnZnKgc0mLARCirqfvjVshclYgfVZtHNIpK/VAI8/FN2v\nthT0TzqxplaP+hQtHgrtoRu74PIG8cuTk1k9PlJyqqyPTbJNcub9QYxYPYqn0npbDNEur6mcGnNA\nr1VFF7TduL4Jp8cdaavPhqZcmJ0P5Dx/AES2M5UTy2P2BcVrEGLt6KzFe1dmM640kttwNBsq8PV/\nPRltrJeNc1MurC+RTXFildbZrGBmhxdaNaXcpjHevp5GVOnUOJhm2igcFnhn2Ir9G5pydkUWTSyX\nUOfTXCWUc2nXunr0tRrww3cuZbWB+5TDm3R/jHjJAsKg2QUhlDf762014JLNk3bkeXp8DtvW1EY/\ntG7c0IhQWOCo9MGYjHwBk6sFafHkxPL47Lyipnbx9vZk1y/s6Kgd1To1fvyFPQiEBL78z+8qrtaK\nV0qb4sTigFAg5rkFmIz6jOas9Vo1btrQhFcHp1N+2AyYnZidD+DmHE0XAZFyTKLS2SxnwR/CyIw7\naeO2YiEifHpfF4amXDiuMOEay+L0KaowAiJJ5Xl/aMmK4QEp17O1Xdlr02uqQVhE2ognEwiFcXbS\ngR2dVyvWrlsb6faabtro0EUruhqroq23c217ey0uznjg9AazGiHszbJf2JFRG67vasCGFgMe+71r\ncHJsDn/1wmDG398xH4DZUTqb4sTigFAgkxmUnMa6fbMJkw5v9Jc+kbel/MH+HA7RK3VqdDeWTguL\noSknwhlcBRfSR65dA4Nek3F/o3BYYNrlVVRhBMS0r4gbJQxMOlBXpcUahc8jTwGlmjY6b3HBGwgv\nCghyt1f5/ZZIMBTGkRE79uVhuki2vePqe0BJl9N4JqMePU3VODySeqQTy+7x47zFHW3jfff2Nnz+\npm48884l/Op0ZtOF8kUWB4RVLLIoLfOrmff3tYAIODiYPIn11rAVvaYatCioVMlEX5shJ9t55kIu\nWlbkS5VOg3uuWYPXhqYzmpeenfcjEBJp+xjJkrWvyHQ70a7GamjVlDKxfGosksDfGbemZf+GJgxN\nuWBzJ14fc3bSCZcvmPNy01jbYkZC2UwZAcDe9Y04OmpX3ApcniaL3dfhm3f34fp19fgv/3Y65Wgr\nnvy685TRKhUOC1gcvpRtr5NpNlRgR0dd0jyCNxDC0VH7sttVJLK51YjLtnl4crxlZDYGzE7UVmqz\nmiIohL09DXD7ghmNqK6WnCrLKyXaJCcQCmNoKrPtRHWaSHVLqtLTU2NzqK/SLmkLIecFkl1dvyOV\npWa7f7IScmIZULZTWiJ7exrh9gWjFxrpHBm1oUKjwvaOq6+zVq3C9z9+LSq0anzp2ROKK82Gplww\n6jWKLwRt0p1JAAAgAElEQVQKiQNCAdg8fvhD4ZRtr1O5fXMLTo07MJ1gp6d3L8/CFwzjpjwEBDmx\nXAqjhP5JJ7a0Kb8KLjR5xfPxS8qnIS7bIhVcrQrfF1c7nl794Ml2O9GNJkPKrqenxuewo7Nuyet9\nTXstaio0SdcjHLpowyaTIW1H3+Xa1l4LQ4Um+ppkSu4XpnT/8qOjdly3th4VmsUtU9pqK/HdB3bi\nwrQb/+0XZxUVFkQSyqX5XuaAUAByyanSapJ4B6S9DV5NsGpZbne93B2pEpGHtMVOLAdDYQyZS6/C\nKFZ7XSXa6ypx7JLyxPIrAxbUVWkV50USTRllu53oJpMBV+zzCa9q5/1BnLe4cE2CFigatQp7uhsS\n7vvtC4Zw7JI9b9VFsb52YCP+8j9sz/pDtcUQ2XfksIKA4FgIYMDsxJ6exG1Obt7YjK8d2IifvzeB\nnxxL3QFXCIHzU66SzB8AHBAKQsnGOKn0tRrQXleJVxLkEd4etuLatXV56ZjYUV8JQ4UGQ0UuPR21\neuALhksyoRxrV1c9jl6yK7pK9AVDeHnQgju3mBTXokc3yYkNCJPZbScqdyAdnl46Sjg7EUng7+xM\nPA21b30jRq2eJQ3iTl6ZgzcQzmv+QLa9oxb37lizrOdQuu/I8Ut2CAHsTrEv9Fdv24ibNzbhfzzf\nj+Hp5L8vE3MLcPmC0Z0JSw0HhAIwz6XfOjMVIsKBzS14a3hmUe24Yz6A0zlod53q+/a1GYpeadSf\n45YV+XJDVwNmXD5cUbBF5TvDNri8Qdy9vU3x8xsTVBn1TzrQl8V2onKlUaKOtqeiK5QTN0mU32/x\n5aeHRmwgAvZ05z8g5MLenkZ4/KEl23LGOzpqh1ZNuG5t8j3K1SrC3350J6p1avzxT08nTVbLr3cp\nJpQBDggFYXZ4oVOrUm6ins6BzSZ4A+Fo0g6IJPCEQF7yB7K+ViOGplxZLbrKlQGzEzqNCj3NpbXM\nP94NUh4h3cItAHjhjBkGvSajUmG9Vo0KjSoaEIQQGDBnt53ousZq6DQqXEgwQjg5PoeO+sqkiyg3\nmQxoqNYtei8CkQCxbU0taquym9cvtKvrEVJPGx0etWNHRx302tQt15sNFfiL+7bh1NgcnnxzJOEx\ncj4uk21bC4kDQgFMSqtRl5NE2tvTgGqdetG00VvDVlTr1ItqxXNtc5sRbl8w2nu+GCJXwYaSW+Yf\nb2NLDWortTieJo8QCIXx0oAFd2wxQafJ7GeKXa08PrsAlzeY1chJrSKsb65J2PX01NhcyveUStqi\n9Z1hW/RCYcEfwntXZgsyXZQrTTUV6DXVpFyP4PEFcXbCkTR/EO+ea9rwwe2t+M7LFxK+tkNTLrTX\nVcKgL82gWdq/YSvElMKNcVKp0Khx88bmRauW5XbX+fyglOc6izVtJIRQtBNYKVCpCLvW1eNYmkqj\nQxdtcCwE8MFtyqeLZLEtsJW2vE5mk6kG5+OmjKxuH8ZnF5asP4h34/pGTDm90a6hxy/bEQiJgiSU\nc2lvTyOOX0qeRzhxOdLzSOk0GBHh/7lvGwx6Df74uVNLnvfcVOltihOLA0IBTM55sSYHy/gPbG7B\nlNOL/kknxuzzuGSbz1v+QHa1hUVxEstmhxdz84GSXJCWyA3dDRixemBNsnALAH5z1oyaCk1WnWlj\nO572TzqhVlHWFSsbTQZMOryLmtXJW2amG3XKjevkPMI7F23QqCg6bVYu9vU0Yj7FftFHR+1QqwjX\nrUueP4jXWFOBb31kG85MOPD/vXG1VbY/GMbITOltihOLA0KehcICFmd2bSviyauWXxm0ROdvc9m/\nKJHqCg3WNVQVrfRUnuMu1TnXeDekWY8QDIXxYr8FBza3pJ2TTqR20QjBifXN1Vk9DxDTwiImjyBv\nmbmtPXUA7mqswppaffR9+M5FG3Z21mW8P3WxyeXaycpPj4zasE1ae5GJu7e34cM71uC7By9ER9cX\nZ9wIhgUHhNXM5vYhGBY5CQhNNRW4trMOBwen8eYFK1oMFdjQkpt216n0tRrTdj31B/OzT628TeLa\nHG+0ki/b22tRoVElXY9wdNQOu8ePu7OYLgIim+TEThktp/JK3k86dtro9Hhky8wqXeoPQCLCvvVN\nkemv+QDOjM+VVf5A1lCtQ1+rIWFA8AZCODXmWNSuIhN/ce9W1FbqolNHVyuMSne0ywEhzyYz3Bgn\nnQObTTgz4cDr52ZwUw7bXaeyuc2ISzZP0qX5gVAYn3vmGN7/N69HP8BzZXx2AVo1oUVhR9Bi02lU\n2NlZlzSP8MJZM6p0aty6qTmr55f3Vba6fbA4fcvKrXTUV6JSq46uWBZCRBLKCvfk3r+hEbPzAfzo\n0CWEBfLa0C6fInmE2SWtrN+7Mgd/KJx1QKiv1uEv79+GAbMTj782jKEpF7RqKulqOUUBgYjuIqJz\nRDRMRN9McP83iOik9OcsEYWIqCHmfjURvUdEv4q5rYGIXiaiC9Lfyifpyshy1yDEu11atez2BfOe\nP5D1tRkgBBK2OhBC4E9/cQZvDVsRDAs8/trytxeMNT67gDV1lRnX2RfTDV0N6J90LukBFQoL/Pas\nBe/vy266CLiaQ5Br55ezelulImxouVppNGZfwKy0ZaYScgL5yTdHUKFR4dq1+at2y6e9PY1YCISi\n+RPZkdHIuopdy8iLfGBrKz6ycw2+/+owXhqYwvrm0tsUJ1baMyMiNYDHAdwNYAuAB4loS+wxQojH\nhBA7hRA7ATwK4A0hROwl0tcAxDcO/yaAg0KIjQAOSl+vOLkeIfSaaqINvQoVEDa3ypvlLM0j/J/X\nL+K54+P4T7dtwCf2rMVPj49FNz/PhfHZ+axaHBfTDd0NCIUF3ruy+APm+CU7rG5fVtVFMmOlFkJc\nXeuwtW15i/V6TYZoQDgZTSgre8622kr0NFXD5Q1iV1d91kGu2PZ0N4AIS9pxHB21Y3OrMet+SbI/\nu3cr6qt1GJnxlHSFEaBshLAbwLAQYkQI4QfwEwD3pTj+QQA/lr8gog4AHwLwVNxx9wH4ofTvHwL4\niNKTLidTjgVUaFSoz9FiHSLCJ/asw+2bW7LujZSpjvpK1FRoMBQXEH55cgKPvXgOH9m5Bl+/oxd/\neOsGqFSE7786nLPvne02icV03do6qAg4Gjdt9JuzU9BrVVlPFwFXVyu/c9GG9rrKZS8C6zXVYNrl\nw9y8H6fG5hZtmanEjRsio4R9eexumm/11Tr0tRpxePRqQPAHw3j3yqzi9Qep1FXp8D/v3w6g9Ffb\nKwkI7QBiOzaNS7ctQURVAO4C8LOYm78D4E8AxBf6moQQZunfUwBMSZ7zYSI6TkTHZ2ZmFJxuaZl0\nREpOcznX/6Vb1+Oph27I2fOlo5JKGwdjko/HLtnxjZ+exu7uBvz1710DIkJrrR4f370W//buOC7b\nMt/EPJ43EILV7Su7gGDQa7G5zbio0igcFvjNWTNu6W1eViWOfLV6ZsKRk7UZ8of/eYsbp8YWb5mp\nxK29LQCAW6S/y9U+KY/gC0Zaw5wej/RlyjZ/EO/2LSb82yP78PE9a3PyfPmS68msDwN4W54uIqJ7\nAEwLIU6kepCIrLRK2BtBCPGkEGKXEGJXc3P2V1bFYp5b/qK0UtDXGulpJITAqNWDh390HB31lXjy\nU9cvagn8h7euh0ZF+F4ORgny6uiOMpsyAiJ5hPeuzEUXJr03NguL04cPZtC7KBE5IITCIidXm72t\nVxcexm+ZqcSBzS14/T/fumifgHK0t6cBvmA4ujHQEWlKLpfrKnZ1NZR8Wa6SgDABoDPm6w7ptkQe\nQMx0EYD9AO4lokuITDXdRkTPSvdZiKgNAKS/k28JVsbMGWyiXso2txnh8kY2FPncM8dARPjHz96A\nuqrF/ZlajHp8Ys86/OK9CVyyLm+UIFcsldsIAYh8kCwEQtHGfC+cmYJOrcJtfcu7kjbGtDzIxQhh\nTa0eNRUa/Pq0ecmWmUoQEbqaSrdqRqk93Y2L8ghHRu3Y2FKDxiT9nFYqJQHhGICNRNRNRDpEPvSf\njz+IiGoB3ALgl/JtQohHhRAdQogu6XGvCiE+Kd39PICHpH8/FPu4lSIYCmPa5cu67XUp2Sy1sPjM\nPx7FxNwC/uHT12NdY+IPgkdu7YFWTfj7Vy8s63vKI4Rst0ksphu6IkVzx0Yj7bB/c8aM9/U2LbuH\nTWzOYGuaxWNKEEUqjeR8x44yv9LPVm2VFlvajDg8YkMwFMaJS/ac5A/KTdqAIIQIAvgKgBcRqRR6\nTgjRT0SPENEjMYfeD+AlIYTSy8JvA7iDiC4AuF36ekWZcfsQCouclZwW0yap0sjq9uNvP7oD169L\n/svSYtDjU3vX4d/fm8hor9l4Y7Pz0KlVaC7Dq7QWox7rGqtw7JIdp8YdmHR4s16MFkueMmqo1uVs\nC0Z5gVpdlRZryzD45sq+nkacuDKL98bm4PGHyqaNdy4pyiEIIV4QQvQKIdYLIf5Suu0JIcQTMcc8\nI4R4IMVzvC6EuCfma5sQ4oAQYqMQ4va4MtUVYXJueRvjlJKaCg1+7/oO/Pm9W3HPNek3JvniLetR\noVHjewezHyWMzy6gvb4SqjJagxBr17oGHL88ixfOmKFVU3QNyXJU69RQqwhb1+RuC8aN0mY5OzqW\nbpm5muztaYQ/GMYTr0fW0uQqoVxOSneFxAowJa1BWAk5BAD4m9/fgYdu7FJ0bFNNBT594zo8f2oy\n5Q5SqYzPll/Jaazd3fWwe/z48ZEr2L+hKSf7BBARrl9Xv+xcRCy50iifbdTLwQ3dDVARcHBoGt1N\n1WjJ0QisnHBAyCN5L+WVMELIxhfftx56rRrfPZhdxdHE7HxZBwS5QsXlCy5rMVq85764D5/d352z\n59u5tg7Xra3DXVtbc/ac5ai2Uhut3NpdZl1bc4UDQh5NznlRpVPDWFnapWb50lCtw0M3duFXpycT\nbhaSyoI/BKvbX5Ylp7Lupmo01eigVhHu2LL86aJ8Meq1+Pkf7l9WG4yVQm7HsRoTygAHhLwySxvj\nrOZ52Ydv7kGVVo3vZphLKOeSUxkR4f5r2/Efr2tH/TK2T2WF86HtbehuqsbNG8tvzVMurM5L1wIx\nO7w562FUruqrdfjs/m58/7VhfPU2p+LWv+W8KC3Wn35oS/qDWMnY0VmH1/7zrcU+jaLhEUIeTa2Q\nRWnL9fmbukEEvHjWovgx8gihs4xHCIyVGw4IeSKEgM3jQ7Oh/Groc62+Woe1DVU4Z1G+69r47AJ0\nGhWaynANAmPligNCnji9QQRCAo08dwwgsvgpk32Z5ZLTcl2DwFg54oCQJzZpk3W+wo3oazXgktUD\nbyCk6Pjx2fmyzx8wVm44IOSJzeMHADTW8AgBAPrajAgL4EKCXdcSGSvzRWmMlSMOCHkijxAaq3mE\nAACbpDbLQ1Pp8wgeXxB2j58DAmMFxgEhT6zuyAihiUcIAICuxmpUaFQ4pyCPMDG3MkpOGSs3HBDy\nxCYFBF6QFKFWETaaanBOwYrllbAojbFyxAEhT2weH+qqtBltR7jSbTIZMWhWEhCkfRB4hMBYQfGn\nVZ7Y3H4uOY2zuc0Aq9sXza8kM2afR4VGxdNtjBUYB4Q8sbp9q277vXTkxHK6PIK8BmE194BirBg4\nIOSJzePnK9w4VyuNlAQEni5irNA4IOSJze3jktM4zTUVaKjWKRghlPc+CIyVKw4IeRAMhTE7H+BF\naXGISGphkXwtgtsXxOx8AJ2reG9fxoqFA0Ie2KOrlHmEEK+vzYDzFjfCYZHwfi45Zax4OCDkQXRR\nGlcZLdHXasBCIIQr9vmE94/beVEaY8XCASEPbB6pbQWPEJbYJG2QkyyxzCMExoqHA0IeyKuUOYew\nVK+pBkTJS0/HZxdQqVXzGg7GioADQh5Y5dbXXGW0RJVOg3UNVUkTy7wGgbHi4YCQBzaPHxoVwVjJ\nW1YnsqnVkHSEMMYlp4wVDQeEPLC5fWis0fFVbhKbWo24ZEu8WQ4vSmOseDgg5EGkjxFPFyXT12pI\nuFmO0xuAYyHAIwTGioQDQh5YPX5OKKeQbLOciVkuOWWsmDgg5IHN7eO9lFOQN8uJLz2Ntr1u4BEC\nY8XAASEPuPV1amoVode0NLE8ZpfXIPAIgbFi4ICQY/P+IBYCIV6UlsamVkPCEUKVTo36Km2Rzoqx\n1Y0DQo7xojRl+lqXbpYjdznl6izGioMDQo5FF6VxQEipT2phETttxCWnjBUXB4Qci44QuOw0JbnS\naHBRQJhHJ5ecMlY0HBBy7GpjOx4hpNJsqEBjtQ7npNJTx0IATm+QRwiMFREHhByz8ghBsdgWFtzl\nlLHiUxQQiOguIjpHRMNE9M0E93+DiE5Kf84SUYiIGohIT0RHiegUEfUT0Z/HPGYnER2WHnOciHbn\n8gcrFpvbj2qdGpU6dbFPpeRtar26Wc44L0pjrOjSBgQiUgN4HMDdALYAeJCItsQeI4R4TAixUwix\nE8CjAN4QQtgB+ADcJoTYAWAngLuIaK/0sP8F4M+lx/x36euyZ/P4uORUoc2txuhmOVcDAo8QGCsW\nJSOE3QCGhRAjQgg/gJ8AuC/F8Q8C+DEAiAi5YY1W+iPvnSgAGKV/1wKYzPDcS5LNzW0rlIptYTE+\nO4+aCg3qeA0CY0WjpD9zO4CxmK/HAexJdCARVQG4C8BXYm5TAzgBYAOAx4UQR6S7/gjAi0T0N4gE\nphszPvsSZHX7eNpDoV6TAUSR3dPG7LwPAmPFluuk8ocBvC1NFwEAhBAhaVqoA8BuItom3fUlAF8X\nQnQC+DqAHyR6QiJ6WMoxHJ+Zmcnx6eaezePnNQgKVerUWNdQhXNTruiiNMZY8SgJCBMAOmO+7pBu\nS+QBSNNF8YQQcwBeQ2QEAQAPAfi59O+fIjI1lehxTwohdgkhdjU3Nys43eIJhwXsHj83tstAX6sR\n56ZcmOBFaYwVnZKAcAzARiLqJiIdIh/6z8cfRES1AG4B8MuY25qJqE76dyWAOwAMSXdPSscDwG0A\nLmT7Q5QKx0IAobDgHEIGNrUaMGL1wOUL8giBsSJLm0MQQgSJ6CsAXgSgBvC0EKKfiB6R7n9COvR+\nAC8JITwxD28D8EMpj6AC8JwQ4lfSfV8A8F0i0gDwAng4Jz9REV1dlMYjBKX6pMQywCWnjBWbok1/\nhRAvAHgh7rYn4r5+BsAzcbedBnBtkud8C8D1yk+19MmL0pq49bVimxYFBB4hMFZMvFI5h652OuUR\nglLrGquh10behp08QmCsqDgg5BD3McqcvFmOoUIDY6WiAStjLE/4NzCHrG4/iID6Kg4ImfjA1lZc\nsLh4DQJjRcYBIYdsbh8aqnRQq/iDLRNffv+GYp8CYww8ZZRT3LaCMVbOOCDkkM3j47bXjLGyxQEh\nh3iEwBgrZxwQcsjq9nHbCsZY2eKAkCP+YBhObxCNvCiNMVamOCDkiN3Di9IYY+WNA0KOWN28KI0x\nVt44IOSITRoh8F4IjLFyxQEhR2zyCIHLThljZYoDQo7wlBFjrNxxQMgRm9sPnUaFmgruBsIYK08c\nEHLE6vajqVrHDdoYY2WLA0KO2Dw+LjlljJU1Dgg5wm0rGGPlbtUHBLcviD/44TGMWj3pD07B5ubG\ndoyx8rbqA8KJy7N4ZXAarwxYsn4OIQSsHj+vQWCMlbVVHxAGJp0AgKEpV9bP4fYF4Q+GecqIMVbW\nOCCYIwHhvCX7gGBzS32MeMqIMVbGVn1AGJQCwoVpF0JhkdVz2Dy8KI0xVv5WdUDwBkIYmXGjva4S\n3kAYY/b5rJ7H6pb7GPEIgTFWvlZ1QDg35UJYAPfuXBP5Ostpo+iUEY8QGGNlbFUHBDl/cJ8UEM5n\nmViWG9s18OY4jLEytroDwqQThgoNNpkM6GyoxFC2IwSPHwa9BhUadY7PkDHGCmdVB4RBsxOb24wg\nImwyGbIeIfBeyoyxlWDVBoRwWGDQ7MSWNUYAwKZWA0atHviCoYyfy+b2817KjLGyt2oDwhX7PDz+\nEDa3GQAAvSYDgmGRVQuLSGM7DgiMsfK2agOCvP5gS1stgMgIAYhUHmUq0tiOp4wYY+Vt1QaEAbMT\nahVho6kGANDTVAONijIOCKGwgH0+shcCY4yVs1UbEAbNTqxvroZeG6kM0mlU6GmuzriFxey8H0KA\nRwiMsbK3agPCwGSkwihWr8mQ8eI0XpTGGFspVmVAmJv3Y9LhxZa4gLDJZMCYfQEeX1Dxc8mL0rix\nHWOs3K3KgCCvUJZLTmW9UmL5wrRb8XNZPXIfIx4hMMbKm6KAQER3EdE5Ihomom8muP8bRHRS+nOW\niEJE1EBEeiI6SkSniKifiP487nFfJaIh6b7/lasfKh15D4T4KaO+aKWRU/FzRUcInENgjJU5TboD\niEgN4HEAdwAYB3CMiJ4XQgzIxwghHgPwmHT8hwF8XQhhJyICcJsQwk1EWgBvEdFvhBCHiej9AO4D\nsEMI4SOiltz/eIkNmJ1oMVQsWV3cWV8FvVaFc1PKRwg2tx8qAuoqtbk+TcYYKyglI4TdAIaFECNC\nCD+AnyDyQZ7MgwB+DAAiQv501Up/5E0HvgTg20IIn3TsdBbnn5VBs2vJ6AAAVCpCr8mQUaWRzeND\nQ3UFVCrK5SkyxljBKQkI7QDGYr4el25bgoiqANwF4Gcxt6mJ6CSAaQAvCyGOSHf1AriZiI4Q0RtE\ndEM2P0Cm/MEwhqddS/IHskwrjaxu3kuZMbYy5Dqp/GEAbwsh7PINQoiQEGIngA4Au4lom3SXBkAD\ngL0AvgHgOWmKaREiepiIjhPR8ZmZmWWf4PC0G4GQWFJhJNtkMmDG5YNdShanY3Nz2wrG2MqgJCBM\nAOiM+bpDui2RByBNF8UTQswBeA2REQQQGWn8XJpWOgogDKApweOeFELsEkLsam5uVnC6qckVRomm\njIDMW1jYPH4uOWWMrQhKAsIxABuJqJuIdIh86D8ffxAR1QK4BcAvY25rJqI66d+ViCSmh6S7/x3A\n+6X7egHoAFiz/1GUGZh0Qq9VobupOuH9ckBQmkeI9DHiEQJjrPylrTISQgSJ6CsAXgSgBvC0EKKf\niB6R7n9COvR+AC8JIWLbhbYB+KFUqaQC8JwQ4lfSfU8DeJqIzgLwA3hICJHdLvcZGDQ7sanVCHWS\nJHCLoQK1lVpFeQRvIAS3L8h7ITDGVoS0AQEAhBAvAHgh7rYn4r5+BsAzcbedBnBtkuf0A/ik8lNd\nPiEEBsxOfHB7W9JjMtksxyblGXgvBMbYSrCqVipPOrxwLASSVhjJNrVGKo3SDVh4URpjbCVZVQFh\ncFLeA8GQ8rjeVgNc3iDMDm/K4yZmFwBwYzvG2MqwqgLCgNkJImBTa5oRgkmqNEqTR/jRoctoNlQk\nLWFljLFysqoCwqDZiXUNVaipSJ06kQNCqjzC0VE7Do3Y8MX39UT3VGCMsXK2qgLCgNmZNn8AALVV\nWrQa9SlHCN979QKaanT4xJ51uTxFxhgrmlUTEFzeAC7b5hVP7/S2Ju9p9O6VWbx5wYov3NyDSh2P\nDhhjK8OqCQjyyuNkK5TjbTLV4ILFjVB4aaXR9w5eQH2VFp/cy6MDxtjKsWoCQrJNcZLpNRngC4Zx\n2eZZdPvp8Tm8dm4Gf3BzD6rT5CIYY6ycrJ6AMOlEnZQbUKJPqkSKnzb6+4PDMOo1+PQ+Hh0wxlaW\nVRMQBs1ObGkzIkFD1YQ2tNSACIs2y+mfdOCVQQs+f1MPDHreEIcxtrKsioAQDIUxNOXKaL1ApU6N\ndQ1Vi0YI3391GIYKDT6zvysPZ8kYY8W1KgLCJZsHvmBYcUJZFrtZzrkpF35zdgqf3d+FWt4ukzG2\nAq2KgNA/mVlCWbap1YBRqwe+YAjfe/UCqnVqfO6m7nycImOMFd2qCAgDZie0asL65pqMHrep1YBQ\nWOClfgt+fcaMT9/Yhboq7lvEGFuZVkVA2LqmFp+5sQs6TWY/rtzC4s+e74deo8Yf8OiAMbaCrYpC\n+nt3rMG9O9Zk/Liupmpo1QSbx4+H39fDba4ZYyvaqhghZEurVmF9cw0qNCp84eaeYp8OY4zl1aoY\nISzH1w5shDcYQrOBRweMsZWNA0Iad6fYbpMxxlYSnjJijDEGgAMCY4wxCQcExhhjADggMMYYk3BA\nYIwxBoADAmOMMQkHBMYYYwA4IDDGGJOQEEs3kS9VRDQD4HKxz6MAmgBYi30SZYBfJ+X4tVJmpb5O\n64QQzekOKquAsFoQ0XEhxK5in0ep49dJOX6tlFntrxNPGTHGGAPAAYExxpiEA0JperLYJ1Am+HVS\njl8rZVb168Q5BMYYYwB4hMAYY0zCAaEEENElIjpDRCeJ6Lh0WwMRvUxEF6S/64t9noVGRE8T0TQR\nnY25LenrQkSPEtEwEZ0jog8U56wLL8nr9GdENCG9p04S0Qdj7lutr1MnEb1GRANE1E9EX5Nu5/eU\nhANC6Xi/EGJnTMnbNwEcFEJsBHBQ+nq1eQbAXXG3JXxdiGgLgAcAbJUe83+ISF24Uy2qZ7D0dQKA\nv5PeUzuFEC8Aq/51CgL4YyHEFgB7AXxZej34PSXhgFC67gPwQ+nfPwTwkSKeS1EIIX4HwB53c7LX\n5T4APxFC+IQQowCGAewuyIkWWZLXKZnV/DqZhRDvSv92ARgE0A5+T0VxQCgNAsArRHSCiB6WbjMJ\nIczSv6cAmIpzaiUn2evSDmAs5rhx6bbV7KtEdFqaUpKnQfh1AkBEXQCuBXAE/J6K4oBQGm4SQuwE\ncDciw9j3xd4pIqVgXA4Wh1+XlP5fAD0AdgIwA/jfxT2d0kFENQB+BuCPhBDO2PtW+3uKA0IJEEJM\nSH9PA/gFIsNSCxG1AYD093TxzrCkJHtdJgB0xhzXId22KgkhLEKIkBAiDOAfcHWqY1W/TkSkRSQY\n/LMQ4ufSzfyeknBAKDIiqiYig/xvAHcCOAvgeQAPSYc9BOCXxTnDkpPsdXkewANEVEFE3QA2Ajha\nhDeemXwAAADKSURBVPMrCfIHnOR+RN5TwCp+nYiIAPwAwKAQ4m9j7uL3lERT7BNgMAH4ReS9Cg2A\nfxFC/JaIjgF4jog+j0iH148W8RyLgoh+DOBWAE1ENA7gfwD4NhK8LkKIfiJ6DsAAItUkXxZChIpy\n4gWW5HW6lYh2IjL9cQnAF4HV/ToB2A/gUwDOENFJ6bb/Cn5PRfFKZcYYYwB4yogxxpiEAwJjjDEA\nHBAYY4xJOCAwxhgDwAGBMcaYhAMCY4wxABwQGGOMSTggMMYYAwD8X1TDEF1EIqNsAAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c723329940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rfe.n_features_, rfe.scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.isin(np.arange(len(rfe.scores_)), np.argsort(np.array(rfe.scores_))[-5:])\n",
    "best_features = np.array(rfe.keep_)[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  0\n",
      "Fold  1\n",
      "Fold  2\n",
      "0.72526391581\n",
      "Fold  0\n",
      "Fold  1\n",
      "Fold  2\n",
      "0.724724032418\n",
      "Fold  0\n",
      "Fold  1\n",
      "Fold  2\n",
      "0.725985231666\n",
      "Fold  0\n",
      "Fold  1\n",
      "Fold  2\n",
      "0.72558657798\n",
      "Fold  0\n",
      "Fold  1\n",
      "Fold  2\n",
      "0.725414923546\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    cv_transform = partial(opt_transform, keep=list(X_train.columns[best_features[i]==1]))\n",
    "    print(np.mean(cross_val(X_train_, y_train_, opt_model, kf, cv_transform)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_best = list(X_train.columns[best_features[2]==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_dump(obj, file_name):\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "pickle_dump(rfe_best, \"rfe_best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boruta \n",
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=4, class_weight='balanced', max_depth=7)\n",
    "boruta_selector = BorutaPy(rf, n_estimators='auto', verbose=2, max_iter=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 150\n",
      "Confirmed: \t0\n",
      "Tentative: \t226\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 150\n",
      "Confirmed: \t0\n",
      "Tentative: \t226\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 150\n",
      "Confirmed: \t0\n",
      "Tentative: \t226\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 150\n",
      "Confirmed: \t0\n",
      "Tentative: \t226\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 150\n",
      "Confirmed: \t0\n",
      "Tentative: \t226\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 150\n",
      "Confirmed: \t0\n",
      "Tentative: \t226\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 150\n",
      "Confirmed: \t0\n",
      "Tentative: \t226\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 150\n",
      "Confirmed: \t28\n",
      "Tentative: \t22\n",
      "Rejected: \t176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t9 / 150\n",
      "Confirmed: \t28\n",
      "Tentative: \t22\n",
      "Rejected: \t176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t10 / 150\n",
      "Confirmed: \t28\n",
      "Tentative: \t22\n",
      "Rejected: \t176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t11 / 150\n",
      "Confirmed: \t28\n",
      "Tentative: \t22\n",
      "Rejected: \t176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t12 / 150\n",
      "Confirmed: \t28\n",
      "Tentative: \t15\n",
      "Rejected: \t183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t13 / 150\n",
      "Confirmed: \t28\n",
      "Tentative: \t15\n",
      "Rejected: \t183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t14 / 150\n",
      "Confirmed: \t28\n",
      "Tentative: \t15\n",
      "Rejected: \t183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t15 / 150\n",
      "Confirmed: \t28\n",
      "Tentative: \t15\n",
      "Rejected: \t183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t16 / 150\n",
      "Confirmed: \t28\n",
      "Tentative: \t15\n",
      "Rejected: \t183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t17 / 150\n",
      "Confirmed: \t28\n",
      "Tentative: \t15\n",
      "Rejected: \t183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t18 / 150\n",
      "Confirmed: \t28\n",
      "Tentative: \t14\n",
      "Rejected: \t184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t19 / 150\n",
      "Confirmed: \t29\n",
      "Tentative: \t13\n",
      "Rejected: \t184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t20 / 150\n",
      "Confirmed: \t29\n",
      "Tentative: \t13\n",
      "Rejected: \t184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t21 / 150\n",
      "Confirmed: \t29\n",
      "Tentative: \t12\n",
      "Rejected: \t185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t22 / 150\n",
      "Confirmed: \t29\n",
      "Tentative: \t9\n",
      "Rejected: \t188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t23 / 150\n",
      "Confirmed: \t29\n",
      "Tentative: \t9\n",
      "Rejected: \t188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t24 / 150\n",
      "Confirmed: \t29\n",
      "Tentative: \t9\n",
      "Rejected: \t188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t25 / 150\n",
      "Confirmed: \t29\n",
      "Tentative: \t9\n",
      "Rejected: \t188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t26 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t8\n",
      "Rejected: \t188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t27 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t8\n",
      "Rejected: \t188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t28 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t8\n",
      "Rejected: \t188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t29 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t6\n",
      "Rejected: \t190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t30 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t6\n",
      "Rejected: \t190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t31 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t6\n",
      "Rejected: \t190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t32 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t4\n",
      "Rejected: \t192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t33 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t4\n",
      "Rejected: \t192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t34 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t3\n",
      "Rejected: \t193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t35 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t3\n",
      "Rejected: \t193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t36 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t3\n",
      "Rejected: \t193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t37 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t3\n",
      "Rejected: \t193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t38 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t3\n",
      "Rejected: \t193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t39 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t3\n",
      "Rejected: \t193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t40 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t3\n",
      "Rejected: \t193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t41 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t3\n",
      "Rejected: \t193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t42 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t3\n",
      "Rejected: \t193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t43 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t3\n",
      "Rejected: \t193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t44 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t3\n",
      "Rejected: \t193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t45 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t3\n",
      "Rejected: \t193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t46 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t3\n",
      "Rejected: \t193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t47 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t3\n",
      "Rejected: \t193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t48 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t3\n",
      "Rejected: \t193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t49 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t3\n",
      "Rejected: \t193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t50 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t3\n",
      "Rejected: \t193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t51 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t3\n",
      "Rejected: \t193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t52 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t3\n",
      "Rejected: \t193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t53 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t3\n",
      "Rejected: \t193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t54 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t3\n",
      "Rejected: \t193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t55 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t3\n",
      "Rejected: \t193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t56 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t3\n",
      "Rejected: \t193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t57 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t3\n",
      "Rejected: \t193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t58 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t3\n",
      "Rejected: \t193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t59 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t2\n",
      "Rejected: \t194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t60 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t2\n",
      "Rejected: \t194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t61 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t2\n",
      "Rejected: \t194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t62 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t2\n",
      "Rejected: \t194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t63 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t2\n",
      "Rejected: \t194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t64 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t2\n",
      "Rejected: \t194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t65 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t2\n",
      "Rejected: \t194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t66 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t2\n",
      "Rejected: \t194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t67 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t2\n",
      "Rejected: \t194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t68 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t2\n",
      "Rejected: \t194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t69 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t2\n",
      "Rejected: \t194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t70 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t2\n",
      "Rejected: \t194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t71 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t2\n",
      "Rejected: \t194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t72 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t2\n",
      "Rejected: \t194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t73 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t2\n",
      "Rejected: \t194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t74 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t2\n",
      "Rejected: \t194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t75 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t2\n",
      "Rejected: \t194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t76 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t2\n",
      "Rejected: \t194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t77 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t2\n",
      "Rejected: \t194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t78 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t2\n",
      "Rejected: \t194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t79 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t2\n",
      "Rejected: \t194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t80 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t2\n",
      "Rejected: \t194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t81 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t2\n",
      "Rejected: \t194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t82 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t2\n",
      "Rejected: \t194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t83 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t2\n",
      "Rejected: \t194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t84 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t2\n",
      "Rejected: \t194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t85 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t2\n",
      "Rejected: \t194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t86 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t2\n",
      "Rejected: \t194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t87 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t2\n",
      "Rejected: \t194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t88 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t2\n",
      "Rejected: \t194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t89 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t2\n",
      "Rejected: \t194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t90 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t91 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t92 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t93 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t94 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t95 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t96 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t97 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t98 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t99 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t100 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t101 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t102 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t103 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t104 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t105 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t106 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t107 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t108 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t109 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t110 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t111 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t112 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t113 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t114 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t115 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t116 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t117 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t118 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t119 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t120 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t121 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t122 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t123 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t124 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t125 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t126 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t127 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t128 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t129 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t130 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t131 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t132 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t133 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t134 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t135 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t136 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t137 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t138 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t139 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t140 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t141 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t142 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t143 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t144 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t145 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t146 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t147 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t148 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n",
      "Iteration: \t149 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t1\n",
      "Rejected: \t195\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t150 / 150\n",
      "Confirmed: \t30\n",
      "Tentative: \t0\n",
      "Rejected: \t195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py:418: RuntimeWarning: invalid value encountered in greater\n",
      "  hits = np.where(cur_imp[0] > imp_sha_max)[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BorutaPy(alpha=0.05,\n",
       "     estimator=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=7, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=112, n_jobs=4, oob_score=False,\n",
       "            random_state=<mtrand.RandomState object at 0x000001C71EE67708>,\n",
       "            verbose=0, warm_start=False),\n",
       "     max_iter=150, n_estimators='auto', perc=100,\n",
       "     random_state=<mtrand.RandomState object at 0x000001C71EE67708>,\n",
       "     two_step=True, verbose=2)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boruta_selector.fit(np.array(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  0\n",
      "Fold  1\n",
      "Fold  2\n",
      "0.725882694533\n"
     ]
    }
   ],
   "source": [
    "boruta_best = list(X_train.columns[boruta_selector.support_])\n",
    "cv_transform = partial(opt_transform, keep=boruta_best)\n",
    "print(np.mean(cross_val(X_train_, y_train_, opt_model, kf, cv_transform)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_dump(obj, file_name):\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "pickle_dump(boruta_best, \"boruta_best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.intersect1d(boruta_best, rfe_best).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "Были испробованы методы RFE и Boruta.\n",
    "Оптимальное число переменных равно 133 и 30 соответственно.\n",
    "Оба варианта хороши и повышают качество модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Подберите оптимальные параметры модели. Обратите внимание, что в зависимости от того, как вы обработали исходные данные, сделали ли балансировку классов, сколько объектов оставили в обучающей выборке и др. оптимальные значения параметров могут меняться. Возьмите наилучшее из ваших решений на текущий момент и проведите процедуру подбора параметров модели (обратите внимание на `sklearn.model_selection.GridSearchCV`) Как подбор параметров повлиял на качество модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.loc[:, rfe_best]\n",
    "X_valid = X_valid.loc[:, rfe_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperopt_model = XGBClassifier(n_jobs=4, tree_method='gpu_hist', predictor = \"cpu_predictor\", objective=\"binary:logistic\",\n",
    "                      missing=-1, \n",
    "                      n_estimators=200, learning_rate=0.05,\n",
    "                      max_depth=4, gamma=10, min_child_weight=2, reg_alpha=2, reg_lambda=1.3,\n",
    "                      subsample=.8, colsample_bytree=.8,\n",
    "                      scale_pos_weight=1\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_transform = partial(opt_transform, keep=rfe_best)\n",
    "pickle_dump(cv_transform, \"opt_transform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_load(file_name):\n",
    "    with open(file_name, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "best_hp = pickle_load('best')\n",
    "trials_hp = pickle_load('trials')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.7004848702899348, gamma=4,\n",
       "       learning_rate=0.043937376458117156, max_delta_step=0, max_depth=4,\n",
       "       min_child_weight=2.3606387519121763, missing=-1, n_estimators=170,\n",
       "       n_jobs=4, nthread=None, objective='binary:logistic',\n",
       "       predictor='cpu_predictor', random_state=0,\n",
       "       reg_alpha=1.362192488318045, reg_lambda=1.2675794323196827,\n",
       "       scale_pos_weight=0.6121411226959748, seed=None, silent=True,\n",
       "       subsample=0.7637859900410551, tree_method='gpu_hist')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert space to params \n",
    "\n",
    "from hyperopt import space_eval, hp\n",
    "space = {}\n",
    "space['n_estimators'] = hp.randint('n_estimators', 20)*10 + 100\n",
    "space['max_depth'] = hp.choice('max_depth', [3,4,5,6])\n",
    "space['learning_rate'] = hp.uniform('learning_rate', 0.01, 0.1)\n",
    "space['gamma'] = hp.randint('gamma', 5)*2\n",
    "space['min_child_weight'] = hp.uniform('min_child_weight', 1.5, 2.5)\n",
    "space['scale_pos_weight'] = hp.uniform('scale_pos_weight', 0.5, 1.5)\n",
    "space['subsample'] = hp.uniform('subsample', 0.7, 0.9)\n",
    "space['colsample_bytree'] = hp.uniform('colsample_bytree', 0.7, 0.9)\n",
    "space['reg_alpha'] = hp.uniform('reg_alpha', 1, 3)\n",
    "space['reg_lambda'] = hp.uniform('reg_lambda', 1, 2)\n",
    "\n",
    "opt_params = space_eval(space, best_hp)\n",
    "hyperopt_model.set_params(**opt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_transform = partial(opt_transform, keep=boruta_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  0\n",
      "Fold  1\n",
      "Fold  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.73684591485627049"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val(train, target, hyperopt_model, kf, cv_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  0\n",
      "Fold  1\n",
      "Fold  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.73351175865337426"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val(train, target, opt_model, kf, cv_transform))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "Для подбора гиперпараметров был использован hyperopt, на кросс-валидации по полной тренировочной выборке.\n",
    "Использование оптимальных параметров повысило AUC на 0.3 процента.\n",
    "Скрипт с кодом в можно найти в приложении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Предложите методику оценки того, какие признаки внесли наибольший вклад в модель (например, это могут быть веса в случае регрессии, а также большое количество моделей реализуют метод `feature_importances_` - оценка важности признаков). На основе предложенной методики проанализируйте, какие признаки внесли больший вклад в модель, а какие меньший?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid = cv_transform(X_train_, X_valid_, y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.7004848702899348, gamma=4,\n",
       "       learning_rate=0.043937376458117156, max_delta_step=0, max_depth=4,\n",
       "       min_child_weight=2.3606387519121763, missing=-1, n_estimators=170,\n",
       "       n_jobs=4, nthread=None, objective='binary:logistic',\n",
       "       predictor='cpu_predictor', random_state=0,\n",
       "       reg_alpha=1.362192488318045, reg_lambda=1.2675794323196827,\n",
       "       scale_pos_weight=0.6121411226959748, seed=None, silent=True,\n",
       "       subsample=0.7637859900410551, tree_method='gpu_hist')"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperopt_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c704e9e6a0>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAK4CAYAAAAhjGnGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c704ebd550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "fe = pd.DataFrame(sorted(list(zip(X_train.columns, hyperopt_model.feature_importances_)), key = lambda x: x[1], reverse=True))\n",
    "\n",
    "plt.figure(figsize=(6,12))\n",
    "sns.barplot(fe.loc[:, 1], fe.loc[:, 0], color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наиболее важные фичи:\n",
    "* Var126\n",
    "* Var192_avg\n",
    "* Var199_avg\n",
    "* Var113\n",
    "* Var189\n",
    "\n",
    "'avg' означает, что это категориальный признак, уровни которого перекодированы по целевой переменной"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. Напоследок давайте посмотрим на объекты. На каких объектах достигается наибольшая ошибка классификации? Есть ли межу этими объектами что-то общее? Видны ли какие-либо закономерности? Предположите, почему наибольшая ошибка достигается именно на этих объектах. В данном случае \"наибольшую\" ошибку можно понимать как отнесение объекта с чужому классу с большой долей уверенности (с высокой вероятностью)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, _ = cv_transform(train, test, target)\n",
    "hyperopt_model.fit(X, target)\n",
    "pred_proba = hyperopt_model.predict_proba(X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80193760360905098"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(target, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.277\trecall: 0.736\tprecision: 0.171\tacc: 0.714\tcutoff: 0.050 \n",
      "f1: 0.301\trecall: 0.664\tprecision: 0.195\tacc: 0.771\tcutoff: 0.060 \n",
      "f1: 0.317\trecall: 0.589\tprecision: 0.217\tacc: 0.811\tcutoff: 0.070 \n",
      "f1: 0.327\trecall: 0.521\tprecision: 0.238\tacc: 0.840\tcutoff: 0.080 \n",
      "f1: 0.334\trecall: 0.463\tprecision: 0.261\tacc: 0.863\tcutoff: 0.090 \n",
      "f1: 0.341\trecall: 0.419\tprecision: 0.288\tacc: 0.880\tcutoff: 0.100 \n",
      "f1: 0.344\trecall: 0.380\tprecision: 0.314\tacc: 0.892\tcutoff: 0.110 \n",
      "f1: 0.340\trecall: 0.345\tprecision: 0.335\tacc: 0.900\tcutoff: 0.120 \n",
      "f1: 0.332\trecall: 0.310\tprecision: 0.357\tacc: 0.907\tcutoff: 0.130 \n",
      "f1: 0.320\trecall: 0.279\tprecision: 0.376\tacc: 0.912\tcutoff: 0.140 \n",
      "f1: 0.313\trecall: 0.256\tprecision: 0.403\tacc: 0.916\tcutoff: 0.150 \n"
     ]
    }
   ],
   "source": [
    "cutoff_metrics(target, pred_proba, np.linspace(0.05, 0.15, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.int32(pred_proba > 0.11)\n",
    "FN = np.where(np.logical_and(pred != target, target==1), pred_proba, -1)\n",
    "FP = np.where(np.logical_and(pred != target, target==0), pred_proba, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var13</th>\n",
       "      <th>Var28</th>\n",
       "      <th>Var57</th>\n",
       "      <th>Var73</th>\n",
       "      <th>Var74</th>\n",
       "      <th>Var81</th>\n",
       "      <th>Var113</th>\n",
       "      <th>Var125</th>\n",
       "      <th>Var126</th>\n",
       "      <th>Var140</th>\n",
       "      <th>Var189</th>\n",
       "      <th>Var205</th>\n",
       "      <th>Var212</th>\n",
       "      <th>Var217</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>672.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>253.52</td>\n",
       "      <td>2.077761</td>\n",
       "      <td>30</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>176606.40</td>\n",
       "      <td>79187.60</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>5367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>833.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>253.52</td>\n",
       "      <td>4.548173</td>\n",
       "      <td>76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>210234.90</td>\n",
       "      <td>333704.80</td>\n",
       "      <td>18792.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3152</th>\n",
       "      <td>1253.0</td>\n",
       "      <td>1304.0</td>\n",
       "      <td>166.56</td>\n",
       "      <td>0.622089</td>\n",
       "      <td>58</td>\n",
       "      <td>161.0</td>\n",
       "      <td>4513.29</td>\n",
       "      <td>13988.16</td>\n",
       "      <td>81045.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>9620.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>13785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3224</th>\n",
       "      <td>1750.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>271.20</td>\n",
       "      <td>2.964110</td>\n",
       "      <td>160</td>\n",
       "      <td>63.0</td>\n",
       "      <td>20975.91</td>\n",
       "      <td>51163.20</td>\n",
       "      <td>18621.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4135</th>\n",
       "      <td>4879.0</td>\n",
       "      <td>1684.0</td>\n",
       "      <td>186.64</td>\n",
       "      <td>4.771630</td>\n",
       "      <td>228</td>\n",
       "      <td>70.0</td>\n",
       "      <td>24744.03</td>\n",
       "      <td>-685864.00</td>\n",
       "      <td>3753.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>12442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4309</th>\n",
       "      <td>1246.0</td>\n",
       "      <td>4712.0</td>\n",
       "      <td>176.56</td>\n",
       "      <td>2.390088</td>\n",
       "      <td>164</td>\n",
       "      <td>175.0</td>\n",
       "      <td>20317.98</td>\n",
       "      <td>53568.00</td>\n",
       "      <td>45621.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>1855.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>13816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7761</th>\n",
       "      <td>7476.0</td>\n",
       "      <td>9136.0</td>\n",
       "      <td>166.56</td>\n",
       "      <td>2.076266</td>\n",
       "      <td>208</td>\n",
       "      <td>826.0</td>\n",
       "      <td>12274.53</td>\n",
       "      <td>-502196.00</td>\n",
       "      <td>86445.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>63</td>\n",
       "      <td>13665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9757</th>\n",
       "      <td>1239.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>200.00</td>\n",
       "      <td>2.738731</td>\n",
       "      <td>34</td>\n",
       "      <td>294.0</td>\n",
       "      <td>43230.30</td>\n",
       "      <td>-1050248.00</td>\n",
       "      <td>17523.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>2495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15693</th>\n",
       "      <td>3409.0</td>\n",
       "      <td>2352.0</td>\n",
       "      <td>120.40</td>\n",
       "      <td>3.392651</td>\n",
       "      <td>106</td>\n",
       "      <td>189.0</td>\n",
       "      <td>42474.30</td>\n",
       "      <td>-27879.00</td>\n",
       "      <td>63243.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>10076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19207</th>\n",
       "      <td>840.0</td>\n",
       "      <td>2556.0</td>\n",
       "      <td>289.20</td>\n",
       "      <td>3.208502</td>\n",
       "      <td>174</td>\n",
       "      <td>56.0</td>\n",
       "      <td>182039.10</td>\n",
       "      <td>287952.40</td>\n",
       "      <td>49032.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>2255.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>2177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21429</th>\n",
       "      <td>854.0</td>\n",
       "      <td>4752.0</td>\n",
       "      <td>200.00</td>\n",
       "      <td>5.640034</td>\n",
       "      <td>166</td>\n",
       "      <td>868.0</td>\n",
       "      <td>66982.80</td>\n",
       "      <td>-70255.20</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>5215.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>10142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24234</th>\n",
       "      <td>637.0</td>\n",
       "      <td>10292.0</td>\n",
       "      <td>245.68</td>\n",
       "      <td>6.453749</td>\n",
       "      <td>264</td>\n",
       "      <td>399.0</td>\n",
       "      <td>204955.80</td>\n",
       "      <td>-296489.60</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>11886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31222</th>\n",
       "      <td>910.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>253.52</td>\n",
       "      <td>2.763085</td>\n",
       "      <td>34</td>\n",
       "      <td>133.0</td>\n",
       "      <td>142853.10</td>\n",
       "      <td>176128.00</td>\n",
       "      <td>26172.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>4995.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>5519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32802</th>\n",
       "      <td>644.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>220.08</td>\n",
       "      <td>0.937407</td>\n",
       "      <td>32</td>\n",
       "      <td>168.0</td>\n",
       "      <td>223373.40</td>\n",
       "      <td>166198.40</td>\n",
       "      <td>41094.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35229</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>6.175390</td>\n",
       "      <td>10</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-477576.00</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>8911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Var6    Var13   Var28     Var57  Var73  Var74      Var81      Var113  \\\n",
       "784     672.0     -1.0  253.52  2.077761     30   -1.0  176606.40    79187.60   \n",
       "2040    833.0    112.0  253.52  4.548173     76    0.0  210234.90   333704.80   \n",
       "3152   1253.0   1304.0  166.56  0.622089     58  161.0    4513.29    13988.16   \n",
       "3224   1750.0    228.0  271.20  2.964110    160   63.0   20975.91    51163.20   \n",
       "4135   4879.0   1684.0  186.64  4.771630    228   70.0   24744.03  -685864.00   \n",
       "4309   1246.0   4712.0  176.56  2.390088    164  175.0   20317.98    53568.00   \n",
       "7761   7476.0   9136.0  166.56  2.076266    208  826.0   12274.53  -502196.00   \n",
       "9757   1239.0    660.0  200.00  2.738731     34  294.0   43230.30 -1050248.00   \n",
       "15693  3409.0   2352.0  120.40  3.392651    106  189.0   42474.30   -27879.00   \n",
       "19207   840.0   2556.0  289.20  3.208502    174   56.0  182039.10   287952.40   \n",
       "21429   854.0   4752.0  200.00  5.640034    166  868.0   66982.80   -70255.20   \n",
       "24234   637.0  10292.0  245.68  6.453749    264  399.0  204955.80  -296489.60   \n",
       "31222   910.0    244.0  253.52  2.763085     34  133.0  142853.10   176128.00   \n",
       "32802   644.0    140.0  220.08  0.937407     32  168.0  223373.40   166198.40   \n",
       "35229    -1.0     -1.0   -1.00  6.175390     10   -1.0      -1.00  -477576.00   \n",
       "\n",
       "        Var125  Var126  Var140  Var189  Var205  Var212  Var217  \n",
       "784       -1.0   -30.0    -1.0    -1.0       2      33    5367  \n",
       "2040   18792.0   -28.0    20.0   336.0       2      33    1004  \n",
       "3152   81045.0   -30.0  9620.0   294.0       3      44   13785  \n",
       "3224   18621.0   -26.0   490.0    -1.0       1       5    5698  \n",
       "4135    3753.0   -22.0   620.0   336.0       2      48   12442  \n",
       "4309   45621.0   -30.0  1855.0    -1.0       1      27   13816  \n",
       "7761   86445.0   -20.0  1610.0    -1.0       2      63   13665  \n",
       "9757   17523.0   -20.0   535.0    -1.0       2      33    2495  \n",
       "15693  63243.0   -24.0   505.0    -1.0       2      27   10076  \n",
       "19207  49032.0   -24.0  2255.0    -1.0       2      43    2177  \n",
       "21429   1485.0   -28.0  5215.0    -1.0       1      20   10142  \n",
       "24234   2295.0   -20.0   565.0   366.0       2      30   11886  \n",
       "31222  26172.0   -28.0  4995.0    -1.0       2      18    5519  \n",
       "32802  41094.0   -18.0    75.0   306.0       2      33    1320  \n",
       "35229     -1.0   -26.0    -1.0   312.0       2      33    8911  "
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FN с наименьшей вероятностью\n",
    "X[np.logical_and(FN != -1, FN < 0.012)].iloc[:, :15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var13</th>\n",
       "      <th>Var28</th>\n",
       "      <th>Var57</th>\n",
       "      <th>Var73</th>\n",
       "      <th>Var74</th>\n",
       "      <th>Var81</th>\n",
       "      <th>Var113</th>\n",
       "      <th>Var125</th>\n",
       "      <th>Var126</th>\n",
       "      <th>...</th>\n",
       "      <th>Var198_avg</th>\n",
       "      <th>Var199_avg</th>\n",
       "      <th>Var204_avg</th>\n",
       "      <th>Var206_avg</th>\n",
       "      <th>Var207_avg</th>\n",
       "      <th>Var212_avg</th>\n",
       "      <th>Var216_avg</th>\n",
       "      <th>Var217_avg</th>\n",
       "      <th>Var226_avg</th>\n",
       "      <th>Var228_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>105.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>255.68</td>\n",
       "      <td>4.262551</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270448.20</td>\n",
       "      <td>326182.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.090847</td>\n",
       "      <td>0.100563</td>\n",
       "      <td>0.083217</td>\n",
       "      <td>0.090769</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.159574</td>\n",
       "      <td>0.094799</td>\n",
       "      <td>0.086605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6984</th>\n",
       "      <td>280.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.08</td>\n",
       "      <td>6.951719</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40493.70</td>\n",
       "      <td>-103952.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.089623</td>\n",
       "      <td>0.091598</td>\n",
       "      <td>0.083217</td>\n",
       "      <td>0.090769</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.276786</td>\n",
       "      <td>0.094799</td>\n",
       "      <td>0.086605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9276</th>\n",
       "      <td>574.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.52</td>\n",
       "      <td>0.134373</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149919.60</td>\n",
       "      <td>50550.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.105327</td>\n",
       "      <td>0.100563</td>\n",
       "      <td>0.083217</td>\n",
       "      <td>0.090769</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.276786</td>\n",
       "      <td>0.094799</td>\n",
       "      <td>0.086605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11688</th>\n",
       "      <td>4620.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166.56</td>\n",
       "      <td>2.747063</td>\n",
       "      <td>48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53759.70</td>\n",
       "      <td>15804.44</td>\n",
       "      <td>4428.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073409</td>\n",
       "      <td>0.141593</td>\n",
       "      <td>0.059197</td>\n",
       "      <td>0.091598</td>\n",
       "      <td>0.075130</td>\n",
       "      <td>0.069747</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.276786</td>\n",
       "      <td>0.064721</td>\n",
       "      <td>0.074400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12899</th>\n",
       "      <td>105.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>264.80</td>\n",
       "      <td>0.090365</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>207157.80</td>\n",
       "      <td>363336.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.126582</td>\n",
       "      <td>0.085020</td>\n",
       "      <td>0.091598</td>\n",
       "      <td>0.083217</td>\n",
       "      <td>0.090769</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.276786</td>\n",
       "      <td>0.089236</td>\n",
       "      <td>0.086605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14138</th>\n",
       "      <td>147.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>266.40</td>\n",
       "      <td>1.129460</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>237746.70</td>\n",
       "      <td>80322.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.175824</td>\n",
       "      <td>0.084239</td>\n",
       "      <td>0.091598</td>\n",
       "      <td>0.083217</td>\n",
       "      <td>0.090769</td>\n",
       "      <td>0.080169</td>\n",
       "      <td>0.144444</td>\n",
       "      <td>0.090164</td>\n",
       "      <td>0.086605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16831</th>\n",
       "      <td>105.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>230.56</td>\n",
       "      <td>3.529160</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>409815.00</td>\n",
       "      <td>-25587.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.077035</td>\n",
       "      <td>0.091598</td>\n",
       "      <td>0.083217</td>\n",
       "      <td>0.090769</td>\n",
       "      <td>0.146832</td>\n",
       "      <td>0.140845</td>\n",
       "      <td>0.073546</td>\n",
       "      <td>0.086605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21633</th>\n",
       "      <td>784.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>389.60</td>\n",
       "      <td>2.498398</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122172.00</td>\n",
       "      <td>97558.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.077185</td>\n",
       "      <td>0.069571</td>\n",
       "      <td>0.083217</td>\n",
       "      <td>0.090769</td>\n",
       "      <td>0.192708</td>\n",
       "      <td>0.276786</td>\n",
       "      <td>0.073243</td>\n",
       "      <td>0.086605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22061</th>\n",
       "      <td>714.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>31.44</td>\n",
       "      <td>4.084811</td>\n",
       "      <td>34</td>\n",
       "      <td>7.0</td>\n",
       "      <td>220342.20</td>\n",
       "      <td>119772.00</td>\n",
       "      <td>15075.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.080189</td>\n",
       "      <td>0.100563</td>\n",
       "      <td>0.083217</td>\n",
       "      <td>0.090769</td>\n",
       "      <td>0.192708</td>\n",
       "      <td>0.276786</td>\n",
       "      <td>0.078963</td>\n",
       "      <td>0.086605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28807</th>\n",
       "      <td>707.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>589.60</td>\n",
       "      <td>5.622303</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199304.10</td>\n",
       "      <td>5844040.00</td>\n",
       "      <td>396.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.134357</td>\n",
       "      <td>0.100563</td>\n",
       "      <td>0.083217</td>\n",
       "      <td>0.090769</td>\n",
       "      <td>0.088751</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.094799</td>\n",
       "      <td>0.086605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35601</th>\n",
       "      <td>343.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166.56</td>\n",
       "      <td>4.011536</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22332.39</td>\n",
       "      <td>-96118.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116505</td>\n",
       "      <td>0.046771</td>\n",
       "      <td>0.089623</td>\n",
       "      <td>0.091598</td>\n",
       "      <td>0.044336</td>\n",
       "      <td>0.090769</td>\n",
       "      <td>0.092395</td>\n",
       "      <td>0.276786</td>\n",
       "      <td>0.094799</td>\n",
       "      <td>0.082474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37549</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.560137</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-4003160.00</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.079918</td>\n",
       "      <td>0.048929</td>\n",
       "      <td>0.083217</td>\n",
       "      <td>0.090769</td>\n",
       "      <td>0.146832</td>\n",
       "      <td>0.276786</td>\n",
       "      <td>0.078014</td>\n",
       "      <td>0.086605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Var6  Var13   Var28     Var57  Var73  Var74      Var81      Var113  \\\n",
       "6063    105.0    0.0  255.68  4.262551     16    0.0  270448.20   326182.80   \n",
       "6984    280.0    0.0   20.08  6.951719     14    0.0   40493.70  -103952.00   \n",
       "9276    574.0    0.0  199.52  0.134373     22    0.0  149919.60    50550.80   \n",
       "11688  4620.0    0.0  166.56  2.747063     48    0.0   53759.70    15804.44   \n",
       "12899   105.0    0.0  264.80  0.090365     14    0.0  207157.80   363336.00   \n",
       "14138   147.0    0.0  266.40  1.129460     18    0.0  237746.70    80322.00   \n",
       "16831   105.0    0.0  230.56  3.529160     18    0.0  409815.00   -25587.84   \n",
       "21633   784.0    0.0  389.60  2.498398     26    0.0  122172.00    97558.40   \n",
       "22061   714.0  312.0   31.44  4.084811     34    7.0  220342.20   119772.00   \n",
       "28807   707.0    4.0  589.60  5.622303     42    0.0  199304.10  5844040.00   \n",
       "35601   343.0    0.0  166.56  4.011536     16    0.0   22332.39   -96118.80   \n",
       "37549    -1.0   -1.0   -1.00  1.560137      6   -1.0      -1.00 -4003160.00   \n",
       "\n",
       "        Var125  Var126     ...      Var198_avg  Var199_avg  Var204_avg  \\\n",
       "6063       0.0    -8.0     ...        0.074400    0.074400    0.090847   \n",
       "6984       0.0   -10.0     ...        0.074400    0.074400    0.089623   \n",
       "9276       0.0    -1.0     ...        0.074400    0.074400    0.105327   \n",
       "11688   4428.0    24.0     ...        0.073409    0.141593    0.059197   \n",
       "12899      0.0   -10.0     ...        0.074400    0.126582    0.085020   \n",
       "14138      0.0    -8.0     ...        0.074400    0.175824    0.084239   \n",
       "16831      0.0    -8.0     ...        0.074400    0.074400    0.077035   \n",
       "21633      0.0    -1.0     ...        0.074400    0.074400    0.077185   \n",
       "22061  15075.0    -1.0     ...        0.074400    0.138889    0.080189   \n",
       "28807    396.0    -1.0     ...        0.074400    0.074400    0.134357   \n",
       "35601      0.0     4.0     ...        0.116505    0.046771    0.089623   \n",
       "37549     -1.0    -8.0     ...        0.074400    0.074400    0.079918   \n",
       "\n",
       "       Var206_avg  Var207_avg  Var212_avg  Var216_avg  Var217_avg  Var226_avg  \\\n",
       "6063     0.100563    0.083217    0.090769    0.074400    0.159574    0.094799   \n",
       "6984     0.091598    0.083217    0.090769    0.230769    0.276786    0.094799   \n",
       "9276     0.100563    0.083217    0.090769    0.074400    0.276786    0.094799   \n",
       "11688    0.091598    0.075130    0.069747    0.074400    0.276786    0.064721   \n",
       "12899    0.091598    0.083217    0.090769    0.074400    0.276786    0.089236   \n",
       "14138    0.091598    0.083217    0.090769    0.080169    0.144444    0.090164   \n",
       "16831    0.091598    0.083217    0.090769    0.146832    0.140845    0.073546   \n",
       "21633    0.069571    0.083217    0.090769    0.192708    0.276786    0.073243   \n",
       "22061    0.100563    0.083217    0.090769    0.192708    0.276786    0.078963   \n",
       "28807    0.100563    0.083217    0.090769    0.088751    0.074400    0.094799   \n",
       "35601    0.091598    0.044336    0.090769    0.092395    0.276786    0.094799   \n",
       "37549    0.048929    0.083217    0.090769    0.146832    0.276786    0.078014   \n",
       "\n",
       "       Var228_avg  \n",
       "6063     0.086605  \n",
       "6984     0.086605  \n",
       "9276     0.086605  \n",
       "11688    0.074400  \n",
       "12899    0.086605  \n",
       "14138    0.086605  \n",
       "16831    0.086605  \n",
       "21633    0.086605  \n",
       "22061    0.086605  \n",
       "28807    0.086605  \n",
       "35601    0.082474  \n",
       "37549    0.086605  \n",
       "\n",
       "[12 rows x 30 columns]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FP с наибольшей вероятностью\n",
    "X[FP >0.4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "На примерах объектов, дающих наибольшую ошибку в классификации видно, что причиной этого являются аномальные значения признаков, Var81, Var113, Var28. Это наталкивает на идею логарифмировать некоторые из числовых признаков, чтобы нормализовать их распределение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9\\. По итогам проведенных экспериментов постройте финальную решение - модель с наилучшим качеством. Укажите, какие преобразования данных, параметры и пр. вы выбрали для построения финальной модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Препроцессинг**: \n",
    "* преобразование пустых значений в -1\n",
    "* переводировка категориальных признаков с числом категорий больше 10 при помощи таргет-кодирования со сглаживанием, с параметрами K = 80, F = 0.5, новые признаки называются как старые, но с добавлением постфикса '_avg'\n",
    "* отбор признаков алгоритмом Boruta, следующие 30 признаков:\n",
    "\n",
    "Var6, Var13, Var28, Var57, Var73, Var74, Var81, Var113, Var125, Var126, Var140, Var189, Var205, Var212, Var217, Var218, Var229, Var192_avg, Var193_avg, Var197_avg, Var198_avg, Var199_avg, Var204_avg, Var206_avg, Var207_avg, Var212_avg, Var216_avg, Var217_avg, Var226_avg, Var228_avg\n",
    "\n",
    "**Модель**: XGBoost c гиперпараметрами:\n",
    "\n",
    "* objective='binary:logistic'\n",
    "* max_depth=4, learning_rate=0.044, n_estimators=170 \n",
    "* colsample_bytree=0.7, subsample=0.76\n",
    "* gamma=4, min_child_weight=2.36, reg_alpha=1.36, reg_lambda=1.27\n",
    "* missing=-1, scale_pos_weight=0.61\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10\\. Подумайте, можно ли еще улучшить модель? Что для этого можно сделать? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. Закодировать пустые ответы не в -1 а в еще меньшее значение, т.к. оказалось, что есть числовые признаки с отрицательными значениями\n",
    "2. Использовать ансамбли моделей \n",
    "3. Преобразовать числовые признаки к нормальному распределению\n",
    "4. Создать новые признаки (Feature Engineering) при помощи комбинации старых с наибольшей важностью, затем заново отобрать лучшие признаки"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
