{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle \n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D\n",
    "from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_rank(array):\n",
    "    ranks = np.empty_like(array)\n",
    "    for i in np.arange(array.shape[1]):\n",
    "        temp = array[:, i].argsort()\n",
    "        ranks[temp, i] = np.arange(len(array))\n",
    "    return ranks\n",
    "\n",
    "def save_oof(train_oof, test_oof, name, sample_submission):\n",
    "    # oof test\n",
    "    submission = pd.concat([sample_submission.iloc[:, 0], pd.DataFrame(test_oof)], axis=1)\n",
    "    submission.columns = sample_submission.columns\n",
    "    # submission.to_csv(\"../output/cnn_conv1D_emb_num_5epochs.csv.gz\", compression=\"gzip\", index=False)\n",
    "    submission.to_csv(\"../output/test/{}.csv\".format(name), index=False)\n",
    "\n",
    "    # oof train\n",
    "    submission_train = pd.concat([sample_submission.iloc[:, 0], pd.DataFrame(train_oof)], axis=1)\n",
    "    submission_train.columns = sample_submission.columns\n",
    "    submission_train.to_csv(\"../output/train/{}.csv\".format(name), index=False)\n",
    "    \n",
    "def oof(X_train, X_test, y, num_folds, seed):\n",
    "    \n",
    "    scores = []\n",
    "    train_predict = np.zeros((X_train.shape[0],6))\n",
    "    test_predict = np.zeros((X_test.shape[0],6))\n",
    "    \n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
    "    \n",
    "    for train_idx, val_idx in kf.split(X_train):\n",
    "\n",
    "        x_train = X_train[train_idx]\n",
    "        x_val = X_train[val_idx]\n",
    "        y_train = y[train_idx]\n",
    "        y_val = y[val_idx]\n",
    "        \n",
    "        # fit model \n",
    "        model = get_model()\n",
    "        RocAuc = RocAucEvaluation(validation_data=(x_val, y_val), interval=1)\n",
    "        model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, \n",
    "                  validation_data=(x_val, y_val), callbacks=[RocAuc], verbose=2)\n",
    "        \n",
    "        # predict\n",
    "        train_predict[val_idx] = model.predict(x_val, batch_size=batch_size)\n",
    "        test_predict += np_rank(model.predict(X_test, batch_size=batch_size))\n",
    "        \n",
    "        # save scores \n",
    "        cv_score = roc_auc_score(y_val, train_predict[val_idx])\n",
    "        scores.append(cv_score)\n",
    "        \n",
    "        # release memory\n",
    "        del model\n",
    "        gc.collect()\n",
    "        K.clear_session()\n",
    "        \n",
    "    test_predict /= (num_folds*test_predict.shape[0])\n",
    "    return scores, train_predict, test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMBEDDING_FILE = '../input/crawl-300d-2M.vec'\n",
    "\n",
    "\n",
    "# X_train = train[\"comment_text\"].fillna(\"fillna\").values\n",
    "# y_train = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].values\n",
    "# X_test = test[\"comment_text\"].fillna(\"fillna\").values\n",
    "\n",
    "\n",
    "# tokenizer = text.Tokenizer(num_words=max_features)\n",
    "# tokenizer.fit_on_texts(list(X_train) + list(X_test))\n",
    "# X_train = tokenizer.texts_to_sequences(X_train)\n",
    "# X_test = tokenizer.texts_to_sequences(X_test)\n",
    "# x_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "# x_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "# def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
    "# embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE, encoding=\"utf-8\"))\n",
    "\n",
    "# word_index = tokenizer.word_index\n",
    "# nb_words = min(max_features, len(word_index))\n",
    "# embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "# for word, i in word_index.items():\n",
    "#     if i >= max_features: continue\n",
    "#     embedding_vector = embeddings_index.get(word)\n",
    "#     if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "sample_submission = pd.read_csv('../input/sample_submission.csv')\n",
    "max_features = 100000\n",
    "maxlen = 200\n",
    "embed_size = 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../dumps/cnn_2d_conv.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(obj=(x_train, x_test, y_train, embedding_matrix), file=f)\n",
    "    \n",
    "with open(\"../dumps/cnn_2d_conv.pkl\", \"rb\") as f:\n",
    "    x_train, x_test, y_train, embedding_matrix = pickle.load(file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():   \n",
    "    \n",
    "    filter_sizes = [1,2,3,5]\n",
    "    num_filters = 32    \n",
    "    \n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "    x = SpatialDropout1D(0.4)(x)\n",
    "    x = Reshape((maxlen, embed_size, 1))(x)\n",
    "    \n",
    "    conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], embed_size), kernel_initializer='normal',\n",
    "                                                                                    activation='elu')(x)\n",
    "    conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], embed_size), kernel_initializer='normal',\n",
    "                                                                                    activation='elu')(x)\n",
    "    conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], embed_size), kernel_initializer='normal',\n",
    "                                                                                    activation='elu')(x)\n",
    "    conv_3 = Conv2D(num_filters, kernel_size=(filter_sizes[3], embed_size), kernel_initializer='normal',\n",
    "                                                                                    activation='elu')(x)\n",
    "    \n",
    "    maxpool_0 = MaxPool2D(pool_size=(maxlen - filter_sizes[0] + 1, 1))(conv_0)\n",
    "    maxpool_1 = MaxPool2D(pool_size=(maxlen - filter_sizes[1] + 1, 1))(conv_1)\n",
    "    maxpool_2 = MaxPool2D(pool_size=(maxlen - filter_sizes[2] + 1, 1))(conv_2)\n",
    "    maxpool_3 = MaxPool2D(pool_size=(maxlen - filter_sizes[3] + 1, 1))(conv_3)\n",
    "        \n",
    "    z = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2, maxpool_3])   \n",
    "    z = Flatten()(z)\n",
    "    z = Dropout(0.1)(z)\n",
    "        \n",
    "    outp = Dense(6, activation=\"sigmoid\")(z)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/3\n",
      " - 61s - loss: 0.0703 - acc: 0.9762 - val_loss: 0.0440 - val_acc: 0.9836\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.984316 \n",
      "\n",
      "Epoch 2/3\n",
      " - 58s - loss: 0.0453 - acc: 0.9830 - val_loss: 0.0415 - val_acc: 0.9840\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.988257 \n",
      "\n",
      "Epoch 3/3\n",
      " - 58s - loss: 0.0396 - acc: 0.9847 - val_loss: 0.0413 - val_acc: 0.9841\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.988847 \n",
      "\n",
      "Train on 143614 samples, validate on 15957 samples\n",
      "Epoch 1/3\n",
      " - 59s - loss: 0.0689 - acc: 0.9772 - val_loss: 0.0468 - val_acc: 0.9825\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.982520 \n",
      "\n",
      "Epoch 2/3\n",
      " - 58s - loss: 0.0447 - acc: 0.9832 - val_loss: 0.0447 - val_acc: 0.9829\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.986644 \n",
      "\n",
      "Epoch 3/3\n",
      " - 59s - loss: 0.0394 - acc: 0.9848 - val_loss: 0.0442 - val_acc: 0.9832\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.987079 \n",
      "\n",
      "Train on 143614 samples, validate on 15957 samples\n",
      "Epoch 1/3\n",
      " - 59s - loss: 0.0737 - acc: 0.9748 - val_loss: 0.0461 - val_acc: 0.9830\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.980540 \n",
      "\n",
      "Epoch 2/3\n",
      " - 58s - loss: 0.0451 - acc: 0.9831 - val_loss: 0.0442 - val_acc: 0.9834\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.986022 \n",
      "\n",
      "Epoch 3/3\n",
      " - 59s - loss: 0.0396 - acc: 0.9848 - val_loss: 0.0431 - val_acc: 0.9837\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.986660 \n",
      "\n",
      "Train on 143614 samples, validate on 15957 samples\n",
      "Epoch 1/3\n",
      " - 59s - loss: 0.0686 - acc: 0.9777 - val_loss: 0.0471 - val_acc: 0.9820\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.983551 \n",
      "\n",
      "Epoch 2/3\n",
      " - 59s - loss: 0.0446 - acc: 0.9833 - val_loss: 0.0446 - val_acc: 0.9826\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.987482 \n",
      "\n",
      "Epoch 3/3\n",
      " - 59s - loss: 0.0392 - acc: 0.9849 - val_loss: 0.0443 - val_acc: 0.9827\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.988312 \n",
      "\n",
      "Train on 143614 samples, validate on 15957 samples\n",
      "Epoch 1/3\n",
      " - 60s - loss: 0.0727 - acc: 0.9758 - val_loss: 0.0453 - val_acc: 0.9833\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.975436 \n",
      "\n",
      "Epoch 2/3\n",
      " - 60s - loss: 0.0449 - acc: 0.9832 - val_loss: 0.0428 - val_acc: 0.9841\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.983742 \n",
      "\n",
      "Epoch 3/3\n",
      " - 58s - loss: 0.0396 - acc: 0.9847 - val_loss: 0.0418 - val_acc: 0.9841\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.985025 \n",
      "\n",
      "Train on 143614 samples, validate on 15957 samples\n",
      "Epoch 1/3\n",
      " - 59s - loss: 0.0700 - acc: 0.9763 - val_loss: 0.0436 - val_acc: 0.9835\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.987046 \n",
      "\n",
      "Epoch 2/3\n",
      " - 58s - loss: 0.0452 - acc: 0.9830 - val_loss: 0.0405 - val_acc: 0.9842\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.988916 \n",
      "\n",
      "Epoch 3/3\n",
      " - 58s - loss: 0.0398 - acc: 0.9847 - val_loss: 0.0403 - val_acc: 0.9843\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.989286 \n",
      "\n",
      "Train on 143614 samples, validate on 15957 samples\n",
      "Epoch 1/3\n",
      " - 59s - loss: 0.0666 - acc: 0.9781 - val_loss: 0.0477 - val_acc: 0.9821\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.986121 \n",
      "\n",
      "Epoch 2/3\n",
      " - 58s - loss: 0.0444 - acc: 0.9833 - val_loss: 0.0440 - val_acc: 0.9833\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.988759 \n",
      "\n",
      "Epoch 3/3\n",
      " - 59s - loss: 0.0389 - acc: 0.9850 - val_loss: 0.0437 - val_acc: 0.9829\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.989560 \n",
      "\n",
      "Train on 143614 samples, validate on 15957 samples\n",
      "Epoch 1/3\n",
      " - 60s - loss: 0.0661 - acc: 0.9787 - val_loss: 0.0445 - val_acc: 0.9836\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.982060 \n",
      "\n",
      "Epoch 2/3\n",
      " - 60s - loss: 0.0447 - acc: 0.9832 - val_loss: 0.0422 - val_acc: 0.9843\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.986590 \n",
      "\n",
      "Epoch 3/3\n",
      " - 60s - loss: 0.0395 - acc: 0.9848 - val_loss: 0.0430 - val_acc: 0.9834\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.986367 \n",
      "\n",
      "Train on 143614 samples, validate on 15957 samples\n",
      "Epoch 1/3\n",
      " - 60s - loss: 0.0686 - acc: 0.9772 - val_loss: 0.0456 - val_acc: 0.9831\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.981384 \n",
      "\n",
      "Epoch 2/3\n",
      " - 59s - loss: 0.0448 - acc: 0.9831 - val_loss: 0.0429 - val_acc: 0.9834\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.986367 \n",
      "\n",
      "Epoch 3/3\n",
      " - 60s - loss: 0.0397 - acc: 0.9848 - val_loss: 0.0421 - val_acc: 0.9840\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.987230 \n",
      "\n",
      "Train on 143614 samples, validate on 15957 samples\n",
      "Epoch 1/3\n",
      " - 61s - loss: 0.0714 - acc: 0.9761 - val_loss: 0.0465 - val_acc: 0.9823\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.983723 \n",
      "\n",
      "Epoch 2/3\n",
      " - 59s - loss: 0.0449 - acc: 0.9832 - val_loss: 0.0447 - val_acc: 0.9827\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.986274 \n",
      "\n",
      "Epoch 3/3\n",
      " - 58s - loss: 0.0394 - acc: 0.9849 - val_loss: 0.0446 - val_acc: 0.9828\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.986432 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "seed = 42\n",
    "num_folds = 10\n",
    "batch_size = 256\n",
    "epochs = 3\n",
    "\n",
    "scores, train_oof, test_oof = oof(x_train, x_test, y_train, num_folds, seed)\n",
    "# X_tra, X_val, y_tra, y_val = train_test_split(x_train, y_train, train_size=0.95, random_state=233)\n",
    "# RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)\n",
    "\n",
    "# hist = model.fit(X_tra, y_tra, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val),\n",
    "#                  callbacks=[RocAuc], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.9888470165856411,\n",
       "  0.9870793465331994,\n",
       "  0.9866598214732089,\n",
       "  0.9883117905906973,\n",
       "  0.9850254046232223,\n",
       "  0.989285635295953,\n",
       "  0.9895597299706501,\n",
       "  0.9863667879085236,\n",
       "  0.9872301940172491,\n",
       "  0.986432482352526],\n",
       " 0.9870951951564217)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores, roc_auc_score(y_train, train_oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_oof(train_oof, test_oof, \"cnn_2d_conv\", sample_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
