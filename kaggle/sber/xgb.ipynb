{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "os.chdir(\"./sber/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From here: https://www.kaggle.com/robertoruiz/sberbank-russian-housing-market/dealing-with-multicollinearity/notebook\n",
    "macro_vif = [\"balance_trade\", \"balance_trade_growth\", \"eurrub\", \"average_provision_of_build_contract\",\n",
    "\"micex_rgbi_tr\", \"micex_cbi_tr\", \"deposits_rate\", \"mortgage_value\", \"mortgage_rate\",\n",
    "\"income_per_cap\", \"rent_price_4+room_bus\", \"museum_visitis_per_100_cap\", \"apartment_build\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load\n",
    "df_train = pd.read_csv(\"train.csv\", parse_dates=['timestamp'])\n",
    "df_test = pd.read_csv(\"test.csv\", parse_dates=['timestamp'])\n",
    "df_macro = pd.read_csv(\"macro.csv\", parse_dates=['timestamp'], usecols=['timestamp'] + macro_vif)\n",
    "df_fix = pd.read_csv(\"BAD_ADDRESS_FIX.csv\", sep=\",\")\n",
    "\n",
    "id_test = df_test['id']\n",
    "id_train = df_train['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix\n",
    "df_all = pd.concat([df_train, df_test])\n",
    "\n",
    "fix_cols = df_fix.columns[1:].values\n",
    "fix_ids = df_fix.iloc[:, 0]\n",
    "\n",
    "df_all.set_index('id', inplace=True)\n",
    "df_fix.set_index('id', inplace=True)\n",
    "\n",
    "def replace_col_value_by_ids(col, df_fix):\n",
    "    return df_fix.loc[:, col.name]\n",
    "\n",
    "df_all.loc[fix_ids, fix_cols] = df_all.loc[fix_ids, fix_cols].apply(replace_col_value_by_ids, df_fix=df_fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_train = len(df_train)\n",
    "y = np.log1p(df_train['price_doc'].values)  # log(y + 1)\n",
    "df_all.drop('price_doc', axis=1, inplace=True)\n",
    "df_all = pd.merge_ordered(df_all, df_macro, on='timestamp', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add month-year counts\n",
    "month_year = (df_all.timestamp.dt.month + df_all.timestamp.dt.year * 100)\n",
    "month_year_cnt_map = month_year.value_counts().to_dict()\n",
    "df_all['month_year_cnt'] = month_year.map(month_year_cnt_map)\n",
    "\n",
    "# Add week-year count\n",
    "week_year = (df_all.timestamp.dt.weekofyear + df_all.timestamp.dt.year * 100)\n",
    "week_year_cnt_map = week_year.value_counts().to_dict()\n",
    "df_all['week_year_cnt'] = week_year.map(week_year_cnt_map)\n",
    "\n",
    "# Add month and day-of-week\n",
    "df_all['month'] = df_all.timestamp.dt.month\n",
    "df_all['dow'] = df_all.timestamp.dt.dayofweek\n",
    "\n",
    "# Relative squares and floor\n",
    "df_all['rel_floor'] = df_all['floor'] / df_all['max_floor'].astype(float)\n",
    "df_all['rel_kitch_sq'] = df_all['kitch_sq'] / df_all['full_sq'].astype(float)\n",
    "\n",
    "# feature macro selection (VIF)\n",
    "s = set(df_macro.columns)\n",
    "macro_columns = list(s.difference(macro_vif))\n",
    "df_all.drop(macro_columns, axis=1, inplace=True)\n",
    "\n",
    "# df_all.drop(['timestamp'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Deal with categorical values\n",
    "df_numeric = df_all.select_dtypes(exclude=['object'])\n",
    "df_obj = df_all.select_dtypes(include=['object']).copy()\n",
    "\n",
    "for c in df_obj:\n",
    "    df_obj[c] = pd.factorize(df_obj[c])[0]\n",
    "\n",
    "df_values = pd.concat([df_numeric, df_obj], axis=1)\n",
    "df_columns = df_values.columns\n",
    "X_all = df_values.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split \n",
    "\n",
    "# Create a validation set, with last 20% of data\n",
    "num_val = int(num_train * 0.2)\n",
    "\n",
    "X_train_all = X_all[:num_train]\n",
    "X_train = X_all[:num_train-num_val]\n",
    "X_val = X_all[num_train-num_val:num_train]\n",
    "y_train = y[:-num_val]\n",
    "y_val = y[-num_val:]\n",
    "\n",
    "X_test = X_all[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:14.4748\n",
      "Will train until validation_0-rmse hasn't improved in 20 rounds.\n",
      "[100]\tvalidation_0-rmse:0.454533\n",
      "[200]\tvalidation_0-rmse:0.4225\n",
      "Stopping. Best iteration:\n",
      "[268]\tvalidation_0-rmse:0.421698\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "default_params = {\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'gamma': 0,\n",
    "    'objective': 'reg:linear',\n",
    "    'silent': 1,\n",
    "    #'updater': 'grow_gpu',\n",
    "    'n_estimators': 2000\n",
    "}\n",
    "\n",
    "# get best n estimators  \n",
    "model = XGBRegressor(**default_params)\n",
    "model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=20, verbose=100)\n",
    "model.n_estimators = model.best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.7,\n",
       "       gamma=0, learning_rate=0.05, max_delta_step=0, max_depth=5,\n",
       "       min_child_weight=1, missing=None, n_estimators=269, nthread=-1,\n",
       "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=1, subsample=1)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_all, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0023172704156614833"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = model.predict(X_train_all)\n",
    "\n",
    "err = np.sqrt(mean_squared_error(y, y_pred) / y.shape[0])\n",
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from xgboost import XGBRegressor\n",
    "\n",
    "# default_params = {\n",
    "#     'learning_rate': 0.075,\n",
    "#     'max_depth': 5,\n",
    "#     'subsample': 1.0,\n",
    "#     'colsample_bytree': 0.7,\n",
    "#     'objective': 'reg:linear',\n",
    "#     'eval_metric': 'rmse',\n",
    "#     'silent': 1,\n",
    "#     'n_estimators': 1000,\n",
    "#     'updater': 'grow_gpu',\n",
    "# }\n",
    "\n",
    "# xgb_model = XGBRegressor(**default_params)\n",
    "\n",
    "# fit_params = {\n",
    "#     'eval_set': [(X_val, y_val)], \n",
    "#     'early_stopping_rounds': 20, \n",
    "#     'verbose': 50\n",
    "# }\n",
    "\n",
    "# params = dict(learning_rate = [0.05],\n",
    "#               max_depth = [5],\n",
    "#               subsample = [0.9],\n",
    "#               colsample_bytree = [0.9],\n",
    "#               gamma = [0, 0.5])\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# grid_search = GridSearchCV(xgb_model, param_grid=params, cv=3, fit_params=fit_params)\n",
    "# grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# d = grid_search.cv_results_\n",
    "# v = list(d.values())\n",
    "# k = list(d.keys())\n",
    "# pd.DataFrame(data=v, index=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ylog_pred = model.predict(X_test)\n",
    "y_pred = np.exp(ylog_pred) - 1\n",
    "\n",
    "df_sub = pd.DataFrame({'id': id_test, 'price_doc': y_pred})\n",
    "df_sub.to_csv('sub_xgb.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}