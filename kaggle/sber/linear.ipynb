{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "os.chdir(\"./sber/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From here: https://www.kaggle.com/robertoruiz/sberbank-russian-housing-market/dealing-with-multicollinearity/notebook\n",
    "macro_vif = [\"balance_trade\", \"balance_trade_growth\", \"eurrub\", \"average_provision_of_build_contract\",\n",
    "\"micex_rgbi_tr\", \"micex_cbi_tr\", \"deposits_rate\", \"mortgage_value\", \"mortgage_rate\",\n",
    "\"income_per_cap\", \"rent_price_4+room_bus\", \"museum_visitis_per_100_cap\", \"apartment_build\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load\n",
    "df_train = pd.read_csv(\"train.csv\", parse_dates=['timestamp'])\n",
    "df_test = pd.read_csv(\"test.csv\", parse_dates=['timestamp'])\n",
    "df_macro = pd.read_csv(\"macro.csv\", parse_dates=['timestamp'])\n",
    "df_fix = pd.read_csv(\"BAD_ADDRESS_FIX.csv\", sep=\",\")\n",
    "\n",
    "id_test = df_test['id']\n",
    "id_train = df_train['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix\n",
    "df_all = pd.concat([df_train, df_test])\n",
    "\n",
    "fix_cols = df_fix.columns[1:].values\n",
    "fix_ids = df_fix.iloc[:, 0]\n",
    "\n",
    "df_all.set_index('id', inplace=True)\n",
    "df_fix.set_index('id', inplace=True)\n",
    "\n",
    "def replace_col_value_by_ids(col, df_fix):\n",
    "    return df_fix.loc[:, col.name]\n",
    "\n",
    "df_all.loc[fix_ids, fix_cols] = df_all.loc[fix_ids, fix_cols].apply(replace_col_value_by_ids, df_fix=df_fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_train = len(df_train)\n",
    "y = np.log1p(df_train['price_doc'].values)  # log(y + 1)\n",
    "df_all.drop('price_doc', axis=1, inplace=True)\n",
    "df_all = pd.merge_ordered(df_all, df_macro, on='timestamp', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add month-year counts\n",
    "month_year = (df_all.timestamp.dt.month + df_all.timestamp.dt.year * 100)\n",
    "month_year_cnt_map = month_year.value_counts().to_dict()\n",
    "df_all['month_year_cnt'] = month_year.map(month_year_cnt_map)\n",
    "\n",
    "# Add week-year count\n",
    "week_year = (df_all.timestamp.dt.weekofyear + df_all.timestamp.dt.year * 100)\n",
    "week_year_cnt_map = week_year.value_counts().to_dict()\n",
    "df_all['week_year_cnt'] = week_year.map(week_year_cnt_map)\n",
    "\n",
    "# Add month and day-of-week\n",
    "df_all['month'] = df_all.timestamp.dt.month\n",
    "df_all['dow'] = df_all.timestamp.dt.dayofweek\n",
    "\n",
    "# Relative squares and floor\n",
    "df_all['rel_floor'] = df_all['floor'] / df_all['max_floor'].astype(float)\n",
    "df_all['rel_kitch_sq'] = df_all['kitch_sq'] / df_all['full_sq'].astype(float)\n",
    "\n",
    "# feature macro selection (VIF)\n",
    "s = set(df_macro.columns)\n",
    "macro_columns = list(s.difference(macro_vif))\n",
    "df_all.drop(macro_columns, axis=1, inplace=True)\n",
    "\n",
    "# df_all.drop(['timestamp'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "\n",
    "def make_dummies(df):\n",
    "    \n",
    "    \"\"\" make one hot encoding of object columns with pd dummies\n",
    "    + delete last column\n",
    "    df: pandas dataframe \n",
    "    \"\"\"\n",
    "\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    cat_vars = df.loc[:, df.dtypes == 'object'].columns\n",
    "    tmp = pd.DataFrame()\n",
    "    for var in cat_vars:\n",
    "        dummy = pd.get_dummies(df.loc[:, var], prefix=var, prefix_sep=\"_\").iloc[:, :-1]\n",
    "        if tmp.empty:\n",
    "            tmp = dummy\n",
    "        else:\n",
    "            tmp = pd.concat([tmp, dummy], axis=1)\n",
    "    df.drop(cat_vars, axis=1, inplace=True)\n",
    "    \n",
    "    return pd.concat([df, tmp], axis=1)\n",
    "\n",
    "df_all_dummy = make_dummies(df_all)\n",
    "df_all_dummy.shape\n",
    "\n",
    "df_all_dummy.loc[np.isinf(df_all_dummy.loc[:, 'rel_floor']), 'rel_floor' ] = np.nan # fix inf in rel floor\n",
    "df_all = df_all_dummy\n",
    "X_all = df_all.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split \n",
    "\n",
    "# Create a validation set, with last 20% of data\n",
    "num_val = int(num_train * 0.2)\n",
    "\n",
    "X_train_all = X_all[:num_train]\n",
    "X_train = X_all[:num_train-num_val]\n",
    "X_val = X_all[num_train-num_val:num_train]\n",
    "y_train = y[:-num_val]\n",
    "y_val = y[-num_val:]\n",
    "\n",
    "X_test = X_all[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # split\n",
    "# X, X_test = df_values.loc[id_train], df_values.loc[id_test]\n",
    "# # X, X_test = df_all_dummy.loc[id_train], df_all_dummy.loc[id_test]\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(strategy=\"median\")\n",
    "\n",
    "X_imp = imp.fit_transform(X_train_all)\n",
    "X_train_imp = imp.transform(X_train)\n",
    "X_val_imp = imp.transform(X_val)\n",
    "X_test_imp = imp.transform(X_test)\n",
    "\n",
    "# scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scl = StandardScaler()\n",
    "\n",
    "X_scl = scl.fit_transform(X_imp)\n",
    "X_train_scl = scl.transform(X_train_imp)\n",
    "X_val_scl = scl.transform(X_val_imp)\n",
    "X_test_scl = scl.transform(X_test_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import SelectKBest\n",
    "# from sklearn.feature_selection import f_regression\n",
    "# X_F = SelectKBest(f_regression, k=200).fit_transform(X_scl, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import Ridge\n",
    "# from sklearn.feature_selection import RFE\n",
    "# rfe = RFE(estimator=Ridge(), n_features_to_select=1, step=1)\n",
    "# rfe.fit(X_scl, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_rfe = X_scl[:, rfe.ranking_ < 101]\n",
    "# X_train_rfe = X_train_scl[:, rfe.ranking_ < 101]\n",
    "# X_val_rfe = X_val_scl[:, rfe.ranking_ < 101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "default_params = {\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'gamma': 0,\n",
    "    'objective': 'reg:linear',\n",
    "    'silent': 1,\n",
    "    #'updater': 'grow_gpu',\n",
    "    'n_estimators': 300\n",
    "}\n",
    "\n",
    "# get best n estimators  \n",
    "model = XGBRegressor(**default_params)\n",
    "# model.fit(X_train_rfe, y_train, eval_set=[(X_val_rfe, y_val)], early_stopping_rounds=20, verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA, KernelPCA\n",
    "# # kpca = KernelPCA(kernel=\"rbf\", fit_inverse_transform=True, gamma=10) n_components + n_jobs \n",
    "# # X_kpca = kpca.fit_transform(X_train_imp)\n",
    "\n",
    "# pca = PCA(n_components=150)\n",
    "# train_pca = pca.fit_transform(X_train_imp)\n",
    "# val_pca = pca.transform(X_val_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.01, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.linear_model import Ridge\n",
    "# ridge = Ridge(alpha=0.01)\n",
    "# ridge.fit(X_train_scl, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "# pipe = Pipeline([('pca', PCA()), ('ada', AdaBoostRegressor())])\n",
    "# params = dict(pca__n_components=[100, 150],\n",
    "#               ada__n_estimators=[20],\n",
    "#               ada__learning_rate=[0.5],\n",
    "#              )\n",
    "# grid_search = GridSearchCV(pipe, param_grid=params, cv=5, verbose=2)\n",
    "# grid_search.fit(X_train_imp, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_val' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-cc8b459569c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpca_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpca_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;31m# kpca = KernelPCA(kernel=\"rbf\", fit_inverse_transform=True, gamma=10)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_val' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# pca\n",
    "pca = PCA(n_components=20)\n",
    "pca_train = pca.fit(X_train_scl)\n",
    "pca_val = pca.transform(X_train_val)\n",
    "\n",
    "# kpca = KernelPCA(kernel=\"rbf\", fit_inverse_transform=True, gamma=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pca_train' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-330dbf300ace>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# poly feat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpoly2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPolynomialFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_train_poly2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoly2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpca_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mX_train_poly2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pca_train' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# poly feat\n",
    "poly2 = PolynomialFeatures(degree=2)\n",
    "X_train_poly2 = poly2.fit_transform(pca_train)\n",
    "X_train_poly2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "model = ElasticNet(alpha=0.01, l1_ratio=0.01, max_iter=2000)\n",
    "# model.fit(X_train_scl, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0056597256776318673"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = model.predict(X_val_scl)\n",
    "err = np.sqrt(mean_squared_error(y_val, y_pred) / y_val.shape[0])\n",
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aleksandr.Turutin\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "model = model.fit(X_scl, y)\n",
    "\n",
    "ylog_pred = model.predict(X_test_scl)\n",
    "y_pred = np.exp(ylog_pred) - 1\n",
    "\n",
    "df_sub = pd.DataFrame({'id': id_test, 'price_doc': y_pred})\n",
    "df_sub.to_csv('sub_elastic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ada</th>\n",
       "      <th>svr</th>\n",
       "      <th>xgb</th>\n",
       "      <th>rid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.135655e+06</td>\n",
       "      <td>6.090720e+06</td>\n",
       "      <td>4960626.00</td>\n",
       "      <td>5.178996e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.674368e+06</td>\n",
       "      <td>9.355186e+06</td>\n",
       "      <td>7137405.00</td>\n",
       "      <td>8.123915e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.135752e+06</td>\n",
       "      <td>5.537884e+06</td>\n",
       "      <td>5276688.00</td>\n",
       "      <td>5.941323e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.441998e+06</td>\n",
       "      <td>6.418087e+06</td>\n",
       "      <td>5018870.50</td>\n",
       "      <td>8.596488e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.135752e+06</td>\n",
       "      <td>5.622275e+06</td>\n",
       "      <td>4686823.00</td>\n",
       "      <td>5.478934e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.177093e+06</td>\n",
       "      <td>1.111516e+07</td>\n",
       "      <td>6251699.50</td>\n",
       "      <td>9.683693e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.767814e+06</td>\n",
       "      <td>4.650287e+06</td>\n",
       "      <td>4312354.00</td>\n",
       "      <td>5.338707e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.767814e+06</td>\n",
       "      <td>4.268967e+06</td>\n",
       "      <td>4252905.00</td>\n",
       "      <td>4.222250e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.778604e+06</td>\n",
       "      <td>5.711753e+06</td>\n",
       "      <td>4582966.50</td>\n",
       "      <td>5.799146e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.767814e+06</td>\n",
       "      <td>5.611669e+06</td>\n",
       "      <td>4193743.25</td>\n",
       "      <td>5.000234e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.133800e+06</td>\n",
       "      <td>6.631573e+06</td>\n",
       "      <td>5295299.50</td>\n",
       "      <td>7.172642e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.135655e+06</td>\n",
       "      <td>5.362380e+06</td>\n",
       "      <td>4629914.50</td>\n",
       "      <td>5.138206e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.762377e+06</td>\n",
       "      <td>4.664358e+06</td>\n",
       "      <td>3651469.50</td>\n",
       "      <td>4.407368e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.767814e+06</td>\n",
       "      <td>4.439524e+06</td>\n",
       "      <td>3863228.75</td>\n",
       "      <td>3.717606e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.359928e+06</td>\n",
       "      <td>6.085422e+06</td>\n",
       "      <td>5841084.50</td>\n",
       "      <td>4.898203e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6.390888e+06</td>\n",
       "      <td>5.879096e+06</td>\n",
       "      <td>6473672.50</td>\n",
       "      <td>5.738953e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.940615e+07</td>\n",
       "      <td>2.380829e+07</td>\n",
       "      <td>15182471.00</td>\n",
       "      <td>1.526900e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.123683e+07</td>\n",
       "      <td>1.794274e+07</td>\n",
       "      <td>15814275.00</td>\n",
       "      <td>1.434340e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.502913e+06</td>\n",
       "      <td>6.113915e+06</td>\n",
       "      <td>4293543.00</td>\n",
       "      <td>4.687509e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.085900e+07</td>\n",
       "      <td>1.394904e+07</td>\n",
       "      <td>13408556.00</td>\n",
       "      <td>1.189876e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.906436e+06</td>\n",
       "      <td>7.858946e+06</td>\n",
       "      <td>6372140.50</td>\n",
       "      <td>6.584531e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7.924606e+06</td>\n",
       "      <td>1.413261e+07</td>\n",
       "      <td>8780163.00</td>\n",
       "      <td>9.954357e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8.834574e+06</td>\n",
       "      <td>9.132266e+06</td>\n",
       "      <td>8447900.00</td>\n",
       "      <td>7.548631e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7.680131e+06</td>\n",
       "      <td>8.108433e+06</td>\n",
       "      <td>7208265.50</td>\n",
       "      <td>9.433425e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.115878e+06</td>\n",
       "      <td>4.859594e+06</td>\n",
       "      <td>4351364.50</td>\n",
       "      <td>4.295689e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7.438296e+06</td>\n",
       "      <td>9.841126e+06</td>\n",
       "      <td>7082354.00</td>\n",
       "      <td>7.383992e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.083766e+07</td>\n",
       "      <td>1.164420e+07</td>\n",
       "      <td>9791776.00</td>\n",
       "      <td>9.996492e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.175422e+06</td>\n",
       "      <td>7.695975e+06</td>\n",
       "      <td>6218098.50</td>\n",
       "      <td>7.855284e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.767814e+06</td>\n",
       "      <td>3.412389e+06</td>\n",
       "      <td>3466161.00</td>\n",
       "      <td>3.777666e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.134688e+06</td>\n",
       "      <td>7.963522e+06</td>\n",
       "      <td>5211792.00</td>\n",
       "      <td>6.994312e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7632</th>\n",
       "      <td>5.149924e+06</td>\n",
       "      <td>6.884115e+06</td>\n",
       "      <td>5601620.00</td>\n",
       "      <td>5.522084e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7633</th>\n",
       "      <td>3.767814e+06</td>\n",
       "      <td>3.676551e+06</td>\n",
       "      <td>3635395.75</td>\n",
       "      <td>3.578845e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7634</th>\n",
       "      <td>7.741999e+06</td>\n",
       "      <td>1.000221e+07</td>\n",
       "      <td>9164234.00</td>\n",
       "      <td>1.188813e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7635</th>\n",
       "      <td>5.137382e+06</td>\n",
       "      <td>5.854974e+06</td>\n",
       "      <td>4380606.00</td>\n",
       "      <td>7.081154e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7636</th>\n",
       "      <td>5.441998e+06</td>\n",
       "      <td>3.655448e+06</td>\n",
       "      <td>4060128.25</td>\n",
       "      <td>4.594643e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7637</th>\n",
       "      <td>5.441998e+06</td>\n",
       "      <td>5.685084e+06</td>\n",
       "      <td>4880520.00</td>\n",
       "      <td>5.353996e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7638</th>\n",
       "      <td>3.767814e+06</td>\n",
       "      <td>3.907020e+06</td>\n",
       "      <td>3888374.25</td>\n",
       "      <td>4.394783e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7639</th>\n",
       "      <td>6.646058e+06</td>\n",
       "      <td>7.579489e+06</td>\n",
       "      <td>6551344.00</td>\n",
       "      <td>6.780126e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7640</th>\n",
       "      <td>7.664700e+06</td>\n",
       "      <td>7.681534e+06</td>\n",
       "      <td>6184459.50</td>\n",
       "      <td>6.869802e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7641</th>\n",
       "      <td>3.767814e+06</td>\n",
       "      <td>3.860494e+06</td>\n",
       "      <td>3748632.25</td>\n",
       "      <td>4.091204e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7642</th>\n",
       "      <td>5.153708e+06</td>\n",
       "      <td>8.813478e+06</td>\n",
       "      <td>5668774.50</td>\n",
       "      <td>7.416886e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7643</th>\n",
       "      <td>5.895861e+06</td>\n",
       "      <td>7.763516e+06</td>\n",
       "      <td>6126672.00</td>\n",
       "      <td>4.788176e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7644</th>\n",
       "      <td>5.177093e+06</td>\n",
       "      <td>7.958014e+06</td>\n",
       "      <td>6238858.50</td>\n",
       "      <td>7.958996e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7645</th>\n",
       "      <td>3.767814e+06</td>\n",
       "      <td>3.876632e+06</td>\n",
       "      <td>3790592.50</td>\n",
       "      <td>4.040730e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7646</th>\n",
       "      <td>6.523941e+06</td>\n",
       "      <td>7.413362e+06</td>\n",
       "      <td>6681354.00</td>\n",
       "      <td>7.263407e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7647</th>\n",
       "      <td>5.136167e+06</td>\n",
       "      <td>6.942017e+06</td>\n",
       "      <td>5451004.00</td>\n",
       "      <td>7.140699e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7648</th>\n",
       "      <td>5.118501e+06</td>\n",
       "      <td>1.000481e+07</td>\n",
       "      <td>6277652.50</td>\n",
       "      <td>1.030929e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7649</th>\n",
       "      <td>5.115878e+06</td>\n",
       "      <td>6.253213e+06</td>\n",
       "      <td>5382424.00</td>\n",
       "      <td>8.113233e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7650</th>\n",
       "      <td>5.906436e+06</td>\n",
       "      <td>7.989524e+06</td>\n",
       "      <td>6479836.50</td>\n",
       "      <td>6.654556e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7651</th>\n",
       "      <td>6.919927e+06</td>\n",
       "      <td>8.390473e+06</td>\n",
       "      <td>7374146.50</td>\n",
       "      <td>8.161221e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7652</th>\n",
       "      <td>7.369049e+06</td>\n",
       "      <td>8.843120e+06</td>\n",
       "      <td>8423532.00</td>\n",
       "      <td>9.864015e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7653</th>\n",
       "      <td>5.115878e+06</td>\n",
       "      <td>9.830586e+06</td>\n",
       "      <td>5426512.00</td>\n",
       "      <td>1.088809e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7654</th>\n",
       "      <td>3.750079e+06</td>\n",
       "      <td>3.383535e+06</td>\n",
       "      <td>2435364.50</td>\n",
       "      <td>2.669280e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7655</th>\n",
       "      <td>3.762377e+06</td>\n",
       "      <td>3.608480e+06</td>\n",
       "      <td>3427720.00</td>\n",
       "      <td>3.421988e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7656</th>\n",
       "      <td>5.497751e+06</td>\n",
       "      <td>5.728886e+06</td>\n",
       "      <td>4969921.50</td>\n",
       "      <td>5.076376e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7657</th>\n",
       "      <td>7.164054e+06</td>\n",
       "      <td>9.084994e+06</td>\n",
       "      <td>7196094.50</td>\n",
       "      <td>8.161807e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7658</th>\n",
       "      <td>5.441998e+06</td>\n",
       "      <td>5.678949e+06</td>\n",
       "      <td>4971561.50</td>\n",
       "      <td>5.002894e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7659</th>\n",
       "      <td>5.136167e+06</td>\n",
       "      <td>5.955304e+06</td>\n",
       "      <td>4194519.00</td>\n",
       "      <td>4.825639e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7660</th>\n",
       "      <td>5.120458e+06</td>\n",
       "      <td>5.953996e+06</td>\n",
       "      <td>5131171.50</td>\n",
       "      <td>5.051037e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7661</th>\n",
       "      <td>7.194361e+06</td>\n",
       "      <td>8.725876e+06</td>\n",
       "      <td>7554644.00</td>\n",
       "      <td>9.047805e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7662 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ada           svr          xgb           rid\n",
       "0     5.135655e+06  6.090720e+06   4960626.00  5.178996e+06\n",
       "1     7.674368e+06  9.355186e+06   7137405.00  8.123915e+06\n",
       "2     5.135752e+06  5.537884e+06   5276688.00  5.941323e+06\n",
       "3     5.441998e+06  6.418087e+06   5018870.50  8.596488e+06\n",
       "4     5.135752e+06  5.622275e+06   4686823.00  5.478934e+06\n",
       "5     5.177093e+06  1.111516e+07   6251699.50  9.683693e+06\n",
       "6     3.767814e+06  4.650287e+06   4312354.00  5.338707e+06\n",
       "7     3.767814e+06  4.268967e+06   4252905.00  4.222250e+06\n",
       "8     3.778604e+06  5.711753e+06   4582966.50  5.799146e+06\n",
       "9     3.767814e+06  5.611669e+06   4193743.25  5.000234e+06\n",
       "10    5.133800e+06  6.631573e+06   5295299.50  7.172642e+06\n",
       "11    5.135655e+06  5.362380e+06   4629914.50  5.138206e+06\n",
       "12    3.762377e+06  4.664358e+06   3651469.50  4.407368e+06\n",
       "13    3.767814e+06  4.439524e+06   3863228.75  3.717606e+06\n",
       "14    6.359928e+06  6.085422e+06   5841084.50  4.898203e+06\n",
       "15    6.390888e+06  5.879096e+06   6473672.50  5.738953e+06\n",
       "16    1.940615e+07  2.380829e+07  15182471.00  1.526900e+07\n",
       "17    1.123683e+07  1.794274e+07  15814275.00  1.434340e+07\n",
       "18    5.502913e+06  6.113915e+06   4293543.00  4.687509e+06\n",
       "19    1.085900e+07  1.394904e+07  13408556.00  1.189876e+07\n",
       "20    5.906436e+06  7.858946e+06   6372140.50  6.584531e+06\n",
       "21    7.924606e+06  1.413261e+07   8780163.00  9.954357e+06\n",
       "22    8.834574e+06  9.132266e+06   8447900.00  7.548631e+06\n",
       "23    7.680131e+06  8.108433e+06   7208265.50  9.433425e+06\n",
       "24    5.115878e+06  4.859594e+06   4351364.50  4.295689e+06\n",
       "25    7.438296e+06  9.841126e+06   7082354.00  7.383992e+06\n",
       "26    1.083766e+07  1.164420e+07   9791776.00  9.996492e+06\n",
       "27    5.175422e+06  7.695975e+06   6218098.50  7.855284e+06\n",
       "28    3.767814e+06  3.412389e+06   3466161.00  3.777666e+06\n",
       "29    5.134688e+06  7.963522e+06   5211792.00  6.994312e+06\n",
       "...            ...           ...          ...           ...\n",
       "7632  5.149924e+06  6.884115e+06   5601620.00  5.522084e+06\n",
       "7633  3.767814e+06  3.676551e+06   3635395.75  3.578845e+06\n",
       "7634  7.741999e+06  1.000221e+07   9164234.00  1.188813e+07\n",
       "7635  5.137382e+06  5.854974e+06   4380606.00  7.081154e+06\n",
       "7636  5.441998e+06  3.655448e+06   4060128.25  4.594643e+06\n",
       "7637  5.441998e+06  5.685084e+06   4880520.00  5.353996e+06\n",
       "7638  3.767814e+06  3.907020e+06   3888374.25  4.394783e+06\n",
       "7639  6.646058e+06  7.579489e+06   6551344.00  6.780126e+06\n",
       "7640  7.664700e+06  7.681534e+06   6184459.50  6.869802e+06\n",
       "7641  3.767814e+06  3.860494e+06   3748632.25  4.091204e+06\n",
       "7642  5.153708e+06  8.813478e+06   5668774.50  7.416886e+06\n",
       "7643  5.895861e+06  7.763516e+06   6126672.00  4.788176e+06\n",
       "7644  5.177093e+06  7.958014e+06   6238858.50  7.958996e+06\n",
       "7645  3.767814e+06  3.876632e+06   3790592.50  4.040730e+06\n",
       "7646  6.523941e+06  7.413362e+06   6681354.00  7.263407e+06\n",
       "7647  5.136167e+06  6.942017e+06   5451004.00  7.140699e+06\n",
       "7648  5.118501e+06  1.000481e+07   6277652.50  1.030929e+07\n",
       "7649  5.115878e+06  6.253213e+06   5382424.00  8.113233e+06\n",
       "7650  5.906436e+06  7.989524e+06   6479836.50  6.654556e+06\n",
       "7651  6.919927e+06  8.390473e+06   7374146.50  8.161221e+06\n",
       "7652  7.369049e+06  8.843120e+06   8423532.00  9.864015e+06\n",
       "7653  5.115878e+06  9.830586e+06   5426512.00  1.088809e+07\n",
       "7654  3.750079e+06  3.383535e+06   2435364.50  2.669280e+06\n",
       "7655  3.762377e+06  3.608480e+06   3427720.00  3.421988e+06\n",
       "7656  5.497751e+06  5.728886e+06   4969921.50  5.076376e+06\n",
       "7657  7.164054e+06  9.084994e+06   7196094.50  8.161807e+06\n",
       "7658  5.441998e+06  5.678949e+06   4971561.50  5.002894e+06\n",
       "7659  5.136167e+06  5.955304e+06   4194519.00  4.825639e+06\n",
       "7660  5.120458e+06  5.953996e+06   5131171.50  5.051037e+06\n",
       "7661  7.194361e+06  8.725876e+06   7554644.00  9.047805e+06\n",
       "\n",
       "[7662 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensemble \n",
    "ada = pd.read_csv('sub_ada.csv', usecols=['price_doc'])\n",
    "svr = pd.read_csv('sub_svr_rbf.csv', usecols=['price_doc'])\n",
    "ela = pd.read_csv('sub_elastic.csv', usecols=['price_doc'])\n",
    "xgb = pd.read_csv('sub_xgb.csv', usecols=['price_doc'])\n",
    "rid = pd.read_csv('sub_ridge.csv', usecols=['price_doc'])\n",
    "las = pd.read_csv('sub_lasso.csv', usecols=['price_doc'])\n",
    "\n",
    "ens = pd.concat([ada, svr, ela, xgb, rid, las], axis=1)\n",
    "ens.columns = ['ada','svr','ela','xgb', 'rid', 'las']\n",
    "ens.corr()\n",
    "ens = ens.loc[:, ['ada','svr','xgb','rid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "default_params = {\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'gamma': 0,\n",
    "    'objective': 'reg:linear',\n",
    "    'silent': 1,\n",
    "    #'updater': 'grow_gpu',\n",
    "    'n_estimators': 400\n",
    "}\n",
    "\n",
    "xgb_reg = XGBRegressor(**default_params)\n",
    "ela_reg = ElasticNet(alpha=0.01, l1_ratio=0.01, max_iter=2000)\n",
    "svr_reg = SVR()\n",
    "ada_reg = AdaBoostRegressor(n_estimators=100, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aleksandr.Turutin\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=None, learning_rate=0.001, loss='linear',\n",
       "         n_estimators=100, random_state=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_reg.fit(X_train_scl, y_train)\n",
    "ela_reg.fit(X_train_scl, y_train)\n",
    "svr_reg.fit(X_train_scl, y_train)\n",
    "ada_reg.fit(X_train_scl, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_pred = xgb_reg.predict(X_train_scl)\n",
    "ela_pred = ela_reg.predict(X_train_scl)\n",
    "svr_pred = svr_reg.predict(X_train_scl)\n",
    "ada_pred = ada_reg.predict(X_train_scl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_ens = np.stack([xgb_pred, ela_pred, svr_pred, ada_pred], axis=1)\n",
    "\n",
    "default_params = {\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 2,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    'gamma': 0,\n",
    "    'objective': 'reg:linear',\n",
    "    'silent': 1,\n",
    "    #'updater': 'grow_gpu',\n",
    "    'n_estimators': 200\n",
    "}\n",
    "\n",
    "xgb_ens = XGBRegressor(**default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
       "       learning_rate=0.05, max_delta_step=0, max_depth=2,\n",
       "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
       "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=1, subsample=1)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb_ens\n",
    "model.fit(train_ens, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_val_pred = xgb_reg.predict(X_val_scl)\n",
    "ela_val_pred = ela_reg.predict(X_val_scl)\n",
    "svr_val_pred = svr_reg.predict(X_val_scl)\n",
    "ada_val_pred = ada_reg.predict(X_val_scl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0057221455222936099"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ens = np.stack([xgb_val_pred, ela_val_pred, svr_val_pred, ada_val_pred], axis=1)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = model.predict(val_ens)\n",
    "err = np.sqrt(mean_squared_error(y_val, y_pred) / y_val.shape[0])\n",
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_pred = xgb_reg.predict(X_scl)\n",
    "ela_pred = ela_reg.predict(X_scl)\n",
    "svr_pred = svr_reg.predict(X_scl)\n",
    "ada_pred = ada_reg.predict(X_scl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ens = np.stack([xgb_pred, ela_pred, svr_pred, ada_pred], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_test_pred = xgb_reg.predict(X_test_scl)\n",
    "ela_test_pred = ela_reg.predict(X_test_scl)\n",
    "svr_test_pred = svr_reg.predict(X_test_scl)\n",
    "ada_test_pred = ada_reg.predict(X_test_scl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ens_test = np.stack([xgb_test_pred, ela_test_pred, \n",
    "                     svr_test_pred, ada_test_pred], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = model.fit(ens, y)\n",
    "\n",
    "ylog_pred = model.predict(ens_test)\n",
    "y_pred = np.exp(ylog_pred) - 1\n",
    "\n",
    "df_sub = pd.DataFrame({'id': id_test, 'price_doc': y_pred})\n",
    "df_sub.to_csv('sub_ensemble.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}