{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\z_old_projects\\talking_data\\scripts\n"
     ]
    }
   ],
   "source": [
    "%cd D:\\z_old_projects\\talking_data\\scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is WD500\n",
      " Volume Serial Number is 3E8A-ADD9\n",
      "\n",
      " Directory of D:\\z_old_projects\\talking_data\\scripts\n",
      "\n",
      "05/09/2018  05:45 PM    <DIR>          .\n",
      "05/09/2018  05:45 PM    <DIR>          ..\n",
      "05/08/2018  02:15 AM             1,657 blend.ipynb\n",
      "05/10/2018  10:14 PM            72,310 FE.jpg\n",
      "05/12/2018  01:56 AM            19,002 lgbm.py\n",
      "04/24/2018  07:43 PM            51,853 xgb_9756.ipynb\n",
      "               4 File(s)        144,822 bytes\n",
      "               2 Dir(s)  181,189,406,720 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import gc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCHUNK = 35000000\n",
    "OFFSET = 78000000\n",
    "val_size= 5000000\n",
    "nrows=184903890\n",
    "nchunk=NCHUNK\n",
    "frm=nrows-OFFSET\n",
    "to=frm+nchunk\n",
    "\n",
    "dtypes = {\n",
    "        'ip'            : 'uint32',\n",
    "        'app'           : 'uint16',\n",
    "        'device'        : 'uint16',\n",
    "        'os'            : 'uint16',\n",
    "        'channel'       : 'uint16',\n",
    "        'is_attributed' : 'uint8',\n",
    "        }\n",
    "\n",
    "train_df = pd.read_csv(\"../input/train.csv\",\n",
    "                       skiprows=range(1,frm), nrows=to-frm, dtype=dtypes, \n",
    "                       usecols=['ip','app','device','os'])\n",
    "\n",
    "test_df = pd.read_csv(\"../input/test.csv\", dtype=dtypes, usecols=['ip','app','device','os'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53790469, 4)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.append(test_df)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hashing users \n",
    "train_df['user'] = np.dot(train_df[['os', 'device', 'ip']].values, [10**8, 10**6, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsvd = TruncatedSVD(3)\n",
    "cross1 = np.log1p(pd.crosstab(train_df['ip'], train_df['app']))\n",
    "cross2 = np.log1p(pd.crosstab(train_df['user'], train_df['app']))\n",
    "factors1 = tsvd.fit_transform(cross1)\n",
    "factors2 = tsvd.fit_transform(cross2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors1 = pd.DataFrame(np.hstack([cross1.index.values.reshape(-1,1), factors1]), \n",
    "                        columns=['ip', 'fac1_1', 'fac1_2', 'fac1_3'])\n",
    "factors2 = pd.DataFrame(np.hstack([cross2.index.values.reshape(-1,1), factors2]), \n",
    "                        columns=['user', 'fac2_1', 'fac2_2', 'fac2_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.merge(factors1, on=['ip'], how='left')\n",
    "train_df = train_df.merge(factors2, on=['user'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[['fac1_1', 'fac1_2', 'fac1_3']].to_feather('../dumps/factor1_SMALL.feather')\n",
    "train_df[['fac2_1', 'fac2_2', 'fac2_3']].to_feather('../dumps/factor2_SMALL.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53790469, 3)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_feather('../dumps/factor1_SMALL.feather').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load dumps...\n",
      "(30000000, 27)\n",
      "(5000000, 27)\n"
     ]
    }
   ],
   "source": [
    "dump_name = '_SMALL'\n",
    "print('Load dumps...')\n",
    "train_df = pd.read_feather('../dumps/kaggle_train' + dump_name + '.feather').set_index('index')\n",
    "print(train_df.shape)\n",
    "val_df = pd.read_feather('../dumps/kaggle_val' + dump_name + '.feather').set_index('index')\n",
    "print(val_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor1 = pd.read_feather('../dumps/factor1' + dump_name + '.feather')\n",
    "factor2 = pd.read_feather('../dumps/factor2' + dump_name + '.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors = pd.concat([factor1, factor2], axis=1)\n",
    "del factor1, factor2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = train_df.shape[0]\n",
    "nfull = train_df.shape[0] + val_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df, factors[:ntrain]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.concat([val_df, factors[ntrain:nfull]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors_test = factors[nfull:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del factors\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
