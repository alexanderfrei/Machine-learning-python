{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "import cv2\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from multiprocessing import Value, Pool\n",
    "import gzip\n",
    "from pathlib import PurePath\n",
    "from scipy import sparse\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "import gc\n",
    "\n",
    "fname = 'D:/dataset/avito/train_jpg.zip'\n",
    "pool = 'avg' # one of max of avg\n",
    "batch_size = 64\n",
    "im_dim = 96\n",
    "n_channels = 3\n",
    "limit = None # Limit number of images processed (useful for debug)\n",
    "resize_mode = 'fit' # One of fit or crop\n",
    "bar_iterval = 10 # in seconds\n",
    "empty_im = np.zeros((im_dim, im_dim, n_channels), dtype=np.uint8) # Used when no image is present\n",
    "\n",
    "def resize_fit(im, inter=cv2.INTER_AREA):\n",
    "    height, width, _ = im.shape\n",
    "    \n",
    "    if height > width:\n",
    "        new_dim = (width*im_dim//height, im_dim)\n",
    "    else:\n",
    "        new_dim = (im_dim, height*im_dim//width)\n",
    "        \n",
    "    imr = cv2.resize(im, new_dim, interpolation=inter)\n",
    "    \n",
    "    h, w = imr.shape[:2]\n",
    "\n",
    "    off_x = (im_dim-w)//2\n",
    "    off_y = (im_dim-h)//2\n",
    "    \n",
    "    im_out = np.zeros((im_dim, im_dim, n_channels), dtype=imr.dtype)\n",
    "\n",
    "    im_out[off_y:off_y+h, off_x:off_x+w] = imr\n",
    "    \n",
    "    del imr\n",
    "    \n",
    "    return im_out\n",
    "\n",
    "\n",
    "def resize_crop(im, inter=cv2.INTER_AREA):\n",
    "    height, width, _ = im.shape\n",
    "    \n",
    "    if height > width:\n",
    "        offy = (height-width) // 2\n",
    "        imc = im[offy:offy+width]\n",
    "    else:\n",
    "        offx = (width-height) // 2\n",
    "        imc = im[:, offx:offx+height]\n",
    "        \n",
    "    return cv2.resize(imc, (im_dim, im_dim), interpolation=inter)\n",
    "\n",
    "\n",
    "def resize(im, inter=cv2.INTER_AREA):\n",
    "    if resize_mode == 'fit':\n",
    "        return resize_fit(im, inter)\n",
    "    else:\n",
    "        return resize_crop(im, inter)\n",
    "\n",
    "\n",
    "def generate_files(n_items):\n",
    "    print(\"Starting generate_files...\")\n",
    "\n",
    "    # Open Zip file\n",
    "    train_zip = zipfile.ZipFile(fname)\n",
    "    \n",
    "    # Open train csv (get only images-ids)\n",
    "    ids = pd.read_csv('../input/avito-demand-prediction/train.csv', usecols=['image'], nrows=limit)['image'].tolist()\n",
    "    \n",
    "    n_items.value = len(ids)\n",
    "    print(\"Total items:\", n_items.value)\n",
    "\n",
    "    # Iterate over ids\n",
    "    for im_id in ids:\n",
    "        zfile = 'data/competition_files/train_jpg/{}.jpg'.format(im_id)\n",
    "        try:\n",
    "            zinfo = train_zip.getinfo(zfile)\n",
    "            zbuf = np.frombuffer(train_zip.read(zinfo), dtype='uint8')\n",
    "        except KeyError:\n",
    "            zbuf = None\n",
    "            \n",
    "        yield (im_id, zbuf)\n",
    "        \n",
    "    print(\"Finished generate_files\")\n",
    "    \n",
    "# Based on https://gist.github.com/everilae/9697228\n",
    "class ThreadedGenerator(object):\n",
    "    \"\"\"\n",
    "    Generator that runs on a separate thread, returning values to calling\n",
    "    thread. Care must be taken that the iterator does not mutate any shared\n",
    "    variables referenced in the calling thread.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, iterator, queue_maxsize):\n",
    "        self._iterator = iterator\n",
    "        self._sentinel = object()\n",
    "        self._queue = Queue(maxsize=queue_maxsize)\n",
    "        self._thread = Thread(\n",
    "            name=repr(iterator),\n",
    "            target=self._run\n",
    "        )\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'ThreadedGenerator({!r})'.format(self._iterator)\n",
    "\n",
    "    def _run(self):\n",
    "        try:\n",
    "            for value in self._iterator:\n",
    "                self._queue.put(value)\n",
    "\n",
    "        finally:\n",
    "            self._queue.put(self._sentinel)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self._thread.start()\n",
    "        for value in iter(self._queue.get, self._sentinel):\n",
    "            yield value\n",
    "\n",
    "        self._thread.join()\n",
    "        \n",
    "\n",
    "def im_decode_resize(params):\n",
    "    item_id, zbuf = params\n",
    "    \n",
    "    if zbuf is None:\n",
    "        return item_id, None\n",
    "    else:\n",
    "        try:\n",
    "            im = resize( cv2.imdecode(zbuf, cv2.IMREAD_COLOR) )\n",
    "        except Exception as e:\n",
    "            print('Error decoding item_id', item_id, e)\n",
    "            # Fallback to empty image\n",
    "            im = None\n",
    "        \n",
    "        return item_id, im\n",
    "\n",
    "def predict_batch(model, X_batch):\n",
    "    # Predict step\n",
    "    X_batch = preprocess_input(np.array(X_batch, dtype=np.float32))\n",
    "    features_batch = model.predict_on_batch(X_batch)\n",
    "    \n",
    "    # We will convert to sparse-float16 to save space in memory and disk.\n",
    "    # A subsample analysis results in 2/3 of the features being zero\n",
    "    return sparse.csr_matrix( features_batch.astype(np.float16) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "if __name__ == '__main__':\n",
    "    print(\"Loading model...\")\n",
    "    model = VGG16(weights=None, pooling=pool, include_top=False)\n",
    "    model.load_weights('../input/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "\n",
    "    n_items = Value('i', -1)  # Async number of items\n",
    "    sparse_features = []\n",
    "    # items_ids = []\n",
    "    pool = Pool(2)\n",
    "    bar = None\n",
    "    X_batch = []\n",
    "    try:\n",
    "        # Threaded generator is usful for both parallel blocking read and to limit\n",
    "        # items buffered by pool.imap (may cause OOM)\n",
    "        generator = ThreadedGenerator( generate_files(n_items), 50 )\n",
    "        for item_id, im in pool.imap(im_decode_resize, generator):\n",
    "            if bar is None:\n",
    "                bar = tqdm(total=n_items.value, mininterval=bar_iterval, unit_scale=True)\n",
    "                \n",
    "            # Replace None with empty image\n",
    "            if im is None:\n",
    "                im = empty_im\n",
    "                \n",
    "            X_batch.append(im)\n",
    "            # items_ids.append(item_id)\n",
    "            del im\n",
    "    \n",
    "            if len(X_batch) == batch_size:\n",
    "                sparse_features.append( predict_batch(model, X_batch) )\n",
    "                del X_batch\n",
    "                X_batch = []\n",
    "                bar.update(batch_size)\n",
    "    \n",
    "        # Predict last batch\n",
    "        if len(X_batch) > 0:\n",
    "            sparse_features.append( predict_batch(model, X_batch) )\n",
    "            bar.update(len(X_batch))\n",
    "    \n",
    "    finally:\n",
    "        pool.close()\n",
    "        del pool, model, X_batch\n",
    "    \n",
    "        if bar:\n",
    "            bar.close()\n",
    "    \n",
    "        gc.collect()\n",
    "    \n",
    "    print('Concating sparse matrix...')\n",
    "    features = sparse.vstack(sparse_features)\n",
    "    \n",
    "    print('Saving sparse matrix...')\n",
    "    sparse.save_npz('features.npz', features, compressed=True)\n",
    "\n",
    "    print('All done! Good luck')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
