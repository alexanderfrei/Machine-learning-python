{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multilayer perceptron dense(tanh)-dense(tanh)-dense(softmax)\n",
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frei/dev/anaconda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import keras\n",
    "import numpy  as np\n",
    "\n",
    "import os \n",
    "import urllib\n",
    "import struct\n",
    "# import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('./mnist'):\n",
    "    os.mkdir('./mnist')\n",
    "    \n",
    "train_images = urllib.request.urlopen(\"http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\")\n",
    "train_labels = urllib.request.urlopen(\"http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\")\n",
    "test_images = urllib.request.urlopen(\"http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\")\n",
    "test_labels = urllib.request.urlopen(\"http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\")\n",
    "\n",
    "paths = [\n",
    "    './mnist/train-images-idx3-ubyte.gz',\n",
    "    './mnist/train-labels-idx1-ubyte.gz',\n",
    "    './mnist/t10k-images-idx3-ubyte.gz',\n",
    "    './mnist/t10k-labels-idx1-ubyte.gz'\n",
    "]\n",
    "\n",
    "objs = [\n",
    "    train_images, train_labels, test_images, test_labels\n",
    "]\n",
    "\n",
    "for p,o in zip(paths, objs):\n",
    "    print(p, o)\n",
    "    with open(p, 'wb') as output:\n",
    "        output.write(o.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_mnist(path, kind='train'):\n",
    "    \n",
    "    labels_path = os.path.join(path, '%s-labels-idx1-ubyte' % kind)\n",
    "    images_path = os.path.join(path, '%s-images-idx3-ubyte' % kind)\n",
    "    \n",
    "    with open(labels_path, 'rb') as lb_path:\n",
    "        magic, n = struct.unpack('>II', lb_path.read(8))\n",
    "        labels = np.fromfile(lb_path, dtype=np.uint8)\n",
    "        \n",
    "    with open(images_path, 'rb') as img_path:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII', img_path.read(16))\n",
    "        images = np.fromfile(img_path, dtype=np.uint8).reshape(len(labels), 784)\n",
    "        images = ((images / 255) - 0.5) * 2\n",
    "        \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gzip: ./mnist/*.gz: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!gzip ./mnist/*.gz -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t10k-images-idx3-ubyte\ttrain-images-idx3-ubyte\r\n",
      "t10k-labels-idx1-ubyte\ttrain-labels-idx1-ubyte\r\n"
     ]
    }
   ],
   "source": [
    "!ls mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000,) (10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# data load\n",
    "\n",
    "X_train, y_train = load_mnist('./mnist/', kind='train')\n",
    "X_test, y_test = load_mnist('./mnist/', kind='t10k')\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standardization\n",
    "\n",
    "mean_vals = np.mean(X_train, axis=0)\n",
    "std_val = np.std(X_train)\n",
    "\n",
    "X_train_centered = (X_train - mean_vals) / std_val\n",
    "X_test_centered = (X_test - mean_vals) / std_val\n",
    "\n",
    "del X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_seed = 123\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_onehot = keras.utils.to_categorical(y_train)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Dense(\n",
    "    units=50, \n",
    "    input_dim=X_train_centered.shape[1], \n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    activation='tanh'\n",
    "))\n",
    "\n",
    "model.add(keras.layers.Dense(\n",
    "    units=50,\n",
    "    input_dim=50, \n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    activation='tanh'    \n",
    "))\n",
    "\n",
    "model.add(keras.layers.Dense(\n",
    "    units=y_train_onehot.shape[1],\n",
    "    input_dim=50,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    activation='softmax'\n",
    "))\n",
    "\n",
    "sgd_optimizer = keras.optimizers.SGD(lr=0.001, decay=1e-7, momentum=0.9)\n",
    "model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.6852\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.3429\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.2803\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2456\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.2213\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.2030\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.1881\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1757\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1651\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.1556\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1473\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1396\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.1330\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 0.1268\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.1213\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.1161\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 0.1112\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.1068\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1025\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.0987\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.0950\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.0916\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.0883\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0852\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0824\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.0796\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.0769\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.0745\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0722\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 0.0700\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0677\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.0657\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0637\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.0619\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.0601\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0584\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.0567\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0551\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0536\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.0520\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0507\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.0493\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0479\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0466\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.0455\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0442\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0430\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0419\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.0408\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.0397\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_centered, y_train_onehot, batch_size=64, epochs=50, verbose=1, validation_split=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4]\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict_classes(X_train_centered, verbose=0)\n",
    "print(y_train_pred[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.34\n"
     ]
    }
   ],
   "source": [
    "correct_preds = np.sum(y_train == y_train_pred, axis=0)\n",
    "print('{:.2f}%'.format(correct_preds / y_train.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.40%\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict_classes(X_test_centered, verbose=0)\n",
    "correct_preds = np.sum(y_test == y_test_pred, axis=0)\n",
    "print('{:.2f}%'.format(correct_preds / y_test.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
