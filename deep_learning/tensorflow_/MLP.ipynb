{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# multilayer perceptron \n",
    "# tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy  as np\n",
    "\n",
    "import os \n",
    "import urllib\n",
    "import struct\n",
    "# import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./mnist'):\n",
    "    os.mkdir('./mnist')\n",
    "    \n",
    "train_images = urllib.request.urlopen(\"http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\")\n",
    "train_labels = urllib.request.urlopen(\"http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\")\n",
    "test_images = urllib.request.urlopen(\"http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\")\n",
    "test_labels = urllib.request.urlopen(\"http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./mnist/train-images-idx3-ubyte.gz <http.client.HTTPResponse object at 0x7f72a4294550>\n",
      "./mnist/train-labels-idx1-ubyte.gz <http.client.HTTPResponse object at 0x7f72a42947b8>\n",
      "./mnist/t10k-images-idx3-ubyte.gz <http.client.HTTPResponse object at 0x7f72a4294cf8>\n",
      "./mnist/t10k-labels-idx1-ubyte.gz <http.client.HTTPResponse object at 0x7f72a4294668>\n"
     ]
    }
   ],
   "source": [
    "paths = [\n",
    "    './mnist/train-images-idx3-ubyte.gz',\n",
    "    './mnist/train-labels-idx1-ubyte.gz',\n",
    "    './mnist/t10k-images-idx3-ubyte.gz',\n",
    "    './mnist/t10k-labels-idx1-ubyte.gz'\n",
    "]\n",
    "\n",
    "objs = [\n",
    "    train_images, train_labels, test_images, test_labels\n",
    "]\n",
    "\n",
    "for p,o in zip(paths, objs):\n",
    "    print(p, o)\n",
    "    with open(p, 'wb') as output:\n",
    "        output.write(o.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_mnist(path, kind='train'):\n",
    "    \n",
    "    labels_path = os.path.join(path, '%s-labels-idx1-ubyte' % kind)\n",
    "    images_path = os.path.join(path, '%s-images-idx3-ubyte' % kind)\n",
    "    \n",
    "    with open(labels_path, 'rb') as lb_path:\n",
    "        magic, n = struct.unpack('>II', lb_path.read(8))\n",
    "        labels = np.fromfile(lb_path, dtype=np.uint8)\n",
    "        \n",
    "    with open(images_path, 'rb') as img_path:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII', img_path.read(16))\n",
    "        images = np.fromfile(img_path, dtype=np.uint8).reshape(len(labels), 784)\n",
    "        images = ((images / 255) - 0.5) * 2\n",
    "        \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gzip ./mnist/*.gz -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t10k-images-idx3-ubyte\ttrain-images-idx3-ubyte\r\n",
      "t10k-labels-idx1-ubyte\ttrain-labels-idx1-ubyte\r\n"
     ]
    }
   ],
   "source": [
    "!ls mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000,) (10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# data load\n",
    "\n",
    "X_train, y_train = load_mnist('./mnist/', kind='train')\n",
    "X_test, y_test = load_mnist('./mnist/', kind='t10k')\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standardization\n",
    "\n",
    "mean_vals = np.mean(X_train, axis=0)\n",
    "std_val = np.std(X_train)\n",
    "\n",
    "X_train_centered = (X_train - mean_vals) / std_val\n",
    "X_test_centered = (X_test - mean_vals) / std_val\n",
    "\n",
    "del X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_features = X_train_centered.shape[1]\n",
    "n_classes = 10\n",
    "random_seed = 123\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multilayer perceptron: dense-dense-logit\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    tf.set_random_seed(random_seed)\n",
    "    # input \n",
    "    tf_x = tf.placeholder(dtype=tf.float32, shape=(None, n_features), name='tf_x')\n",
    "    tf_y = tf.placeholder(dtype=tf.int32, shape=(None), name='tf_y')\n",
    "    # to categorical \n",
    "    y_onehot = tf.one_hot(indices=tf_y, depth=n_classes)\n",
    "    # dense layer 1\n",
    "    h1 = tf.layers.dense(inputs=tf_x, units=50, activation=tf.tanh, name='layer1')\n",
    "    # dense layer 2\n",
    "    h2 = tf.layers.dense(inputs=h1, units=50, activation=tf.tanh, name='layer2')\n",
    "    # activation\n",
    "    logits = tf.layers.dense(inputs=h2, units=10, activation=None, name='layer3')\n",
    "    # prediction\n",
    "    predictions = {\n",
    "        'classes' : tf.argmax(logits, axis=1, name='predicted_classes'), \n",
    "        'probabilities' : tf.nn.softmax(logits, name='softmax_tensor')\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function and optimizer \n",
    "\n",
    "with g.as_default():\n",
    "    # cost function : multiclass cross-entropy\n",
    "    cost = tf.losses.softmax_cross_entropy(onehot_labels=y_onehot, logits=logits)\n",
    "    # optimizer: gradient descent\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "\n",
    "    train_op = optimizer.minimize(loss=cost)\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minibatch generator \n",
    "\n",
    "def create_batch_generator(X, y, batch_size=128, shuffle=False):\n",
    "    X_copy = np.array(X)\n",
    "    y_copy = np.array(y)\n",
    "    \n",
    "    if shuffle:\n",
    "        data = np.column_stack((X_copy, y_copy))\n",
    "        np.random.shuffle(data)\n",
    "        X_copy = data[:, :-1]\n",
    "        y_copy = data[:, -1].astype(int)\n",
    "        \n",
    "    for i in range(0, X.shape[0], batch_size):\n",
    "        yield X_copy[i:i+batch_size, :], y_copy[i:i+batch_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 1.557\n",
      "Epoch 2, loss 0.949\n",
      "Epoch 3, loss 0.750\n",
      "Epoch 4, loss 0.639\n",
      "Epoch 5, loss 0.567\n",
      "Epoch 6, loss 0.516\n",
      "Epoch 7, loss 0.478\n",
      "Epoch 8, loss 0.449\n",
      "Epoch 9, loss 0.425\n",
      "Epoch 10, loss 0.405\n",
      "Epoch 11, loss 0.388\n",
      "Epoch 12, loss 0.374\n",
      "Epoch 13, loss 0.362\n",
      "Epoch 14, loss 0.351\n",
      "Epoch 15, loss 0.341\n",
      "Epoch 16, loss 0.332\n",
      "Epoch 17, loss 0.324\n",
      "Epoch 18, loss 0.317\n",
      "Epoch 19, loss 0.310\n",
      "Epoch 20, loss 0.303\n",
      "Epoch 21, loss 0.298\n",
      "Epoch 22, loss 0.292\n",
      "Epoch 23, loss 0.287\n",
      "Epoch 24, loss 0.282\n",
      "Epoch 25, loss 0.278\n",
      "Epoch 26, loss 0.273\n",
      "Epoch 27, loss 0.269\n",
      "Epoch 28, loss 0.265\n",
      "Epoch 29, loss 0.262\n",
      "Epoch 30, loss 0.258\n",
      "Epoch 31, loss 0.255\n",
      "Epoch 32, loss 0.251\n",
      "Epoch 33, loss 0.248\n",
      "Epoch 34, loss 0.245\n",
      "Epoch 35, loss 0.242\n",
      "Epoch 36, loss 0.240\n",
      "Epoch 37, loss 0.237\n",
      "Epoch 38, loss 0.234\n",
      "Epoch 39, loss 0.232\n",
      "Epoch 40, loss 0.229\n",
      "Epoch 41, loss 0.227\n",
      "Epoch 42, loss 0.225\n",
      "Epoch 43, loss 0.223\n",
      "Epoch 44, loss 0.220\n",
      "Epoch 45, loss 0.218\n",
      "Epoch 46, loss 0.216\n",
      "Epoch 47, loss 0.214\n",
      "Epoch 48, loss 0.212\n",
      "Epoch 49, loss 0.210\n",
      "Epoch 50, loss 0.209\n"
     ]
    }
   ],
   "source": [
    "# training \n",
    "sess = tf.Session(graph=g)\n",
    "sess.run(init_op)\n",
    "\n",
    "for epoch in range(50):\n",
    "    training_costs = []\n",
    "    batch_generator = create_batch_generator(X_train_centered, y_train, batch_size=64)\n",
    "    for batch_X, batch_y in batch_generator:\n",
    "        feed = {tf_x: batch_X, tf_y: batch_y}\n",
    "        _, batch_cost = sess.run([train_op, cost], feed_dict=feed)\n",
    "        training_costs.append(batch_cost)\n",
    "    print('Epoch {:d}, loss {:.3f}'.format(epoch+1, np.mean(training_costs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 93.89 %\n"
     ]
    }
   ],
   "source": [
    "# prediction \n",
    "feed = {tf_x: X_test_centered}\n",
    "y_pred = sess.run(predictions['classes'], feed_dict=feed)\n",
    "\n",
    "print('acc:', 100*np.sum(y_pred == y_test)/y_test.shape[0], '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
